---
title: 第二章·FAISS数据结构与索引类型 | EasyVectorDB
description: 通过本章学习，你将能够根据不同的业务场景和数据规模，选择合适的FAISS索引类型并完成检索任务。
pubDate: 2026 01 14 
categories: 
  - tech
tags:
  - rag
---

## IndexFlat系列

IndexFlat 系列是 FAISS 中最基础的索引类型，其核心特征是“精确检索”，即通过遍历数据库中所有向量，计算查询向量与每个数据库向量之间的距离，最终返回距离最近的 Top-K 结果，因此也被称为“暴力检索”索引。检索结果绝对精确。

- **IndexFlatL2**：基于欧氏距离度量两个向量的差异。公式为：
$$d(\mathbf{x},\mathbf{y}) = \sqrt{ \sum_{i=1}^{n}(x_{i}-y_{i})^2 }$$

适用于需要衡量向量空间中物理距离的场景，如计算机视觉中的图像特征匹配。

- **IndexFlatIP**：基于内积(Inner Product)度量。公式为：
$$\mathbf{x}\cdot \mathbf{y} = \sum_{i=1}^{n}x_{i}y_{i}$$

两个向量越接近，它们的内积就越大，所以FAISS用相反数来作为“距离”：
$$d(\mathbf{x},\mathbf{y}) = - \mathbf{x}\cdot \mathbf{y}$$
适用于向量已归一化或本身表示相似度空间的场景，如推荐系统中的用户-物品向量匹配。

- **IndexFlatCOSINE**：基于余弦相似度（Cosine Similarity）度量。余弦值越小，两个向量越接近。
$$\cos(\mathbf{x}, \mathbf{y}) = \frac{\sum_{i=1}^{n}x_{i}y_{i}}{\sqrt{ \sum_{i=1}^{n}x^{2} }\sqrt{ \sum_{i=1}^{n}y_{i}^{2} }}$$

用于衡量向量方向的一致性，与向量模长无关，因此适合文本嵌入、聚类、推荐等特征空间。

> 针对不同的领域和应用，如何选择不同的索引模型？

### API使用与参数说明

IndexFlat 系列是 FAISS 中最简单、最常用的精确向量检索索引，API 十分简洁。核心步骤包括：索引初始化、添加向量、执行检索。

**其他常用方法**：

`index.reset()`：清空索引中的所有向量；

`index.remove_ids(ids)`：根据向量ID删除指定向量（需配合IDMap使用）；

`index.save(filename)` / `faiss.read_index(filename)`：索引的保存与加载。

### 精确检索的性能瓶颈

精确检索的时间复杂度与数据库向量数量 N 成正比，即每一次查询都需要与 N 个向量进行距离计算。假设每个向量维度为 d，单次距离计算的时间复杂度为 O(d)，则单次查询的总时间复杂度为 O(N\*d)。

### 小结

不同距离度量会导致截然不同的检索结果**

从本次实验的重合度可以看到：

- L2 vs IP 几乎完全不同**
- IP vs COS 差别依旧巨大**
- L2 vs COS 部分一致，但差异仍明显**

这是因为不同距离度量衡量的是完全不同的“相似性”：

- **L2**：空间位置更近
- **IP**：模长大 + 方向一致
- **COS**：方向一致（不考虑模长）

**所以选错距离度量，会得到完全错误的检索结果。**

## IVF系列索引

在《向量基础》中，我已经学习了INF索引的原理。INF倒排文件索引系列索引是FAISS中用于解决大规模数据检索的核心索引类型，其核心思想是“先聚类分桶，再局部检索”，通过牺牲极小的精度来换取检索效率的大幅提升。

本节关注FAISS中的INF系列索引的API：`IndexINF_Flat` 以及引入PQ量化的 `IndexINF_PQ` 。

INF算法的两个核心参数： `nlist` 和 `nprobe`的影响：

`nlist` 主要与聚类阶段的效率有关。`nlist`通常设置为数据库向量数量N的平方根附近。

`nprobe` 主要与检索阶段的召回率有关。`nprobe`与召回率的关系是从“快速爬升”到“完全饱和”。查询时间随`nprobe` 的增加近似线性上升

## PQ量化索引

在《向量基础》中，我已经学习了PQ量化的原理。PQ量化索引的核心优势在于压缩存储，以距离最近的聚类中心索引代替原始子向量，最终整个高维向量被转化为 m 个码字组成的编码序列，实现大幅压缩。

本节关注FAISS 提供了两种核心 PQ 索引实现：`IndexPQ` 和结合INF的 `IndexINF_PQ`。进行 PQ 量化，核心参数包括向量维度（d）、子向量数量（m）和每个子量化器的位数（nbits）。将子空间划分为 $2^{nbits}$ 个聚类中心。

IndexIVF_PQ 采用“粗筛选+精检索”的两级架构：先通过 IVF 层将向量分到多个聚类分区，再在目标分区内用 PQ 进行精确匹配，大幅提升检索速度。

**压缩率计算**：

$$\text{压缩率} = \frac{\text{原始向量大小}}{\text{PQ编码大小}}=\frac{d\times{4}}{m\times \lceil nbits /8 \rceil }$$

其中$d$是向量维度，$m$是子向量数量，$nbits$是码本位数。在现代64位架构的计算机中，float32占用4字节，由于对齐（DWORD ALLIGN）的要求，$nbits / 8$也要向上取整。一般取8，那么整型索引需要1字节。

## HNSW索引

HNSW（Hierarchical Navigable Small World，分层可导航小世界）作为当前业界主流的 ANN 算法之一，借鉴了“小世界网络”特性。

`IndexHNSWFlat` 是 Faiss 中 HNSW 索引的基础实现，采用“扁平存储”方式（不压缩向量，保证检索精度），其性能完全依赖于三个核心参数的配置。

**核心参数与作用**

|参数名|核心作用|取值范围|性能权衡|
|---|---|---|---|
|M|定义图中每层节点的最大出度（第 0 层通常为 2*M），决定节点连接的密集程度|5-48（常用 8-32）|M 增大 → 导航路径更丰富、召回率更高，但索引构建时间更长、内存占用更大、查询延迟可能增加|
|efConstruction|索引构建时，动态筛选邻居的候选列表大小，决定邻居选择的充分性|几十到上千（通常远大于 M）|efConstruction 增大 → 构建的图结构更优、检索精度更高，但索引构建时间显著增加|
|efSearch|查询时，每层探索的候选邻居数量，直接控制查询精度与速度|不小于查询的近邻数 k（常用 10-200）|efSearch 增大 → 探索范围更广、召回率更高，但查询延迟增加；高质量索引（高 efConstruction）可降低对 efSearch 的依赖|

## LSH索引

传统哈希函数的设计目标是_最小化哈希冲突_，确保不同输入映射到不同哈希值；而LSH（局部敏感哈希）则反其道而行之，通过_最大化相似向量的哈希冲突_，将相似的高维向量映射到同一个哈希桶中，非相似向量映射到同一桶的概率极低。这种特性使LSH能在不遍历全量数据的情况下，快速筛选出潜在的相似向量，大幅提升近似检索效率。

FAISS中的 `IndexLSH` 采用_随机超平面哈希_（Random Hyperplanes）实现，核心流程我在《向量基础》中已经学习过了。

**核心API参数**：

n_bits（哈希码长度）是核心参数——n_bits越大，哈希码区分度越高，检索精度越高，但哈希桶数量呈2^n_bits增长，可能导致桶内向量数量过少，反而降低效率；n_bits越小则相反。d：向量维度；n_bits：哈希码长度（推荐16-64）。

**不适用场景**：

1. 高维向量检索（d>1024）：哈希码的区分能力不足，召回率会显著低于HNSW、IVF-PQ等索引；
2. 精确检索需求：LSH是近似检索算法，无法保证返回绝对最优的近邻结果；
3. 超大规模数据集（>1亿向量）：内存占用会随向量数量线性增长，不如IVF-PQ通过量化压缩内存的优势明显。

我的试验也表明，LSH的召回效果较差。
