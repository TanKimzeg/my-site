---
title: 第二部分 构建你的大语言模型智能体 | Hello-Agents
description: Hello-Agents第二部分 构建你的大语言模型智能体.包含三个章节:智能体经典范式构建、基于低代码平台的智能体搭建、框架开发实践、构建你的Agent框架.
pubDate: 2025 11 08 
categories: 
  - tech
tags:
  - llm
  - agent
---

## 智能体经典范式构建

一个现代的智能体，其核心能力在于能将大语言模型的推理能力与外部世界联通。它能够自主地理解用户意图、拆解复杂任务，并通过调用代码解释器、搜索引擎、API等一系列“工具”，来获取信息、执行操作，最终达成目标。 然而，智能体并非万能，它同样面临着来自大模型本身的“幻觉”问题、在复杂任务中可能陷入推理循环、以及对工具的错误使用等挑战，这些也构成了智能体的能力边界。

为了更好地组织智能体的“思考”与“行动”过程，业界涌现出了多种经典的架构范式。在本章中，我们将聚焦于其中最具代表性的三种，并一步步从零实现它们：

- **ReAct (Reasoning and Acting)：** 一种将“思考”和“行动”紧密结合的范式，让智能体边想边做，动态调整。
- **Plan-and-Solve：** 一种“三思而后行”的范式，智能体首先生成一个完整的行动计划，然后严格执行。
- **Reflection：** 一种赋予智能体“反思”能力的范式，通过自我批判和修正来优化结果。

### ReAct的工作流程

思考与行动是相辅相成的.思考指导行动，而行动的结果又反过来修正思考。为此，ReAct范式通过一种特殊的提示工程来引导模型，使其每一步的输出都遵循一个固定的轨迹：

- 思考: 这是智能体的内心独白.他会分析当前情况分解任务,制定下一步的计划或者反思上一步的结果.
- 行动: 这是智能体决定采取的具体动作.通常调用一个外部工具.
- 观察: 这是执行行动后从外部工具返回的结果.例如搜索结果的摘要或API返回值.

智能体将不断重复这个过程,产生不断增长的上下文,直到它在思考中认为已经找到答案,并输出该结果.推理使行动更具目的性,而行动则为推理提供了事实依据.
大语言模型$\pi$会根据初始问题$q$和之前所有步骤的行动-观察历史轨迹来生成当前的思考$th_{t}$和行动$a_{t}$:

$$(th_{a}, a_{t}) = \pi(q,(a_{1},o_{1}),\dots,(a_{t-1},o_{t-1}))$$

随后环境中的工具$T$会执行行动$a_{t}$,并返回一个新的观察结果$o_{t}$:

$$o_t=T(a_{t})$$

适用于以下场景：

- **需要外部知识的任务**：如查询实时信息（天气、新闻、股价）、搜索专业领域的知识等。
- **需要精确计算的任务**：将数学问题交给计算器工具，避免LLM的计算错误。
- **需要与API交互的任务**：如操作数据库、调用某个服务的API来完成特定功能。

一个良好定义的工具应该包含以下三个核心要素:

1. 名称: 一个简洁唯一的标识符.供智能体在行动中调用.
2. 描述: 一段清晰的自然语言描述,说明这个工具的用途,这个是整个机制中最关键的部分.
3. 执行逻辑: 真正执行任务的函数或方法.

#### 系统提示词的设计

提示词是整个 ReAct 机制的基石，它为大语言模型提供了行动的操作指令。我们需要精心设计一个模板，它将动态地插入可用工具、用户问题以及中间步骤的交互历史。

#### ReAct 的主要特点

1. **高可解释性**：ReAct 最大的优点之一就是透明。通过 `Thought` 链，我们可以清晰地看到智能体每一步的“心路历程”——它为什么会选择这个工具，下一步又打算做什么。这对于理解、信任和调试智能体的行为至关重要。
2. **动态规划与纠错能力**：与一次性生成完整计划的范式不同，ReAct 是“走一步，看一步”。它根据每一步从外部世界获得的 `Observation` 来动态调整后续的 `Thought` 和 `Action`。如果上一步的搜索结果不理想，它可以在下一步中修正搜索词，重新尝试。
3. **工具协同能力**：ReAct 范式天然地将大语言模型的推理能力与外部工具的执行能力结合起来。LLM 负责运筹帷幄（规划和推理），工具负责解决具体问题（搜索、计算），二者协同工作，突破了单一 LLM 在知识时效性、计算准确性等方面的固有局限。

### Plan and Solve

核心逻辑是: **先规划 (Plan)，后执行 (Solve)**

整个流程解耦为两个核心阶段:

1. **规划阶段 (Planning Phase)**： 首先，智能体会接收用户的完整问题。它的第一个任务不是直接去解决问题或调用工具，而是**将问题分解，并制定出一个清晰、分步骤的行动计划**。这个计划本身就是一次大语言模型的调用产物。
2. **执行阶段 (Solving Phase)**： 在获得完整的计划后，智能体进入执行阶段。它会**严格按照计划中的步骤，逐一执行**。每一步的执行都可能是一次独立的 LLM 调用，或者是对上一步结果的加工处理，直到计划中的所有步骤都完成，最终得出答案。

规划模型 $\pi_{plan}$ 根据原始问题 $q$ 生成一个包含 $n$ 个步骤的计划 $P=(p_{1},p_{2},…,p_{n})$:

$$P=\pi_{plan}(q)$$

随后在执行阶段,执行模型$\pi_{solve}$会逐一完成计划中的任务.对于第$i$个步骤,其解决方案$s_{i}$的生成会同时依赖于原始问题$q$,完整计划$P$以及之前所有步骤的执行结果$(s_{1},s_{2},\dots,s_{i-1})$:

$$s_{i}=\pi_{solve}(q,P,(s_{1},s_{2},\dots,s_{i-1}))$$

Plan-and-Solve 尤其适用于那些结构性强、可以被清晰分解的复杂任务，例如：

- **多步数学应用题**：需要先列出计算步骤，再逐一求解。
- **需要整合多个信息源的报告撰写**：需要先规划好报告结构（引言、数据来源A、数据来源B、总结），再逐一填充内容。
- **代码生成任务**：需要先构思好函数、类和模块的结构，再逐一实现。

提示词需要包含以下关键信息:原始问题,完整计划,历史步骤和结果,当前步骤.

### Reflection

为智能体引入一种事后矫正循环,审视自己的工作,发现不足,进行迭代优化.

1. 执行: 首先智能体使用我们舒徐的方法(如以上两种范式)尝试完成任务,生成一个初稿.
2. 反思: 接着进入反思阶段.调用一个"评审员从多个维度进行评估.例如:事实性错误,逻辑漏洞,效率问题,遗漏信息
3. 优化: 将初稿和反馈作为新的上下文,再次调用一个大语言模型,要求它根据反馈的内容对初稿进行修正,生成一个更完善的修订稿.
这个循环可以执行多次,这道不再发现新的问题.

反思模型$\pi_{reflect}$会针对第$i$次迭代产生的输出$O_{i}$生成针对性的反馈$F_{i}$:
$$F_{i}=\pi_{reflect}(Task,O_{i})$$

随后,优化模型会结合原始任务,上一版输出以及反馈,生成新一版输出$O_{i+1}$:

$$O_{i+1} = \pi_{refine}(Task, O_{i},F_{i})$$

跟之前的范式不同,Reflection机制需要多个不同的角色的提示词来协同工作.

1. 初始执行提示词:内容相对直接,只要求模型完成指定的任务
2. 反思提示词: 指示模型扮演评审员的角色,提供具体可操作的反馈
3. 优化提示词: 收到反馈后,这个提示词将引导模型修正优化.

它非常适合那些**对最终结果的质量、准确性和可靠性有极高要求，且对任务完成的实时性要求相对宽松**的场景。例如:

- 生成关键的业务代码或技术报告。
- 在科学研究中进行复杂的逻辑推演。
- 需要深度分析和规划的决策支持系统。

反之，如果应用场景需要快速响应，或者一个“大致正确”的答案就已经足够，那么使用更轻量的 ReAct 或 Plan-and-Solve 范式可能会是更具性价比的选择。

### 习题

- [ ] 本章的习题值得深入思考!

## 基于低代码平台的智能体搭建

在我实习的中厂,他们用于搭建智能体的平台是Dify.上周Unicom来做广告,他们也做了一个开源的[智能体搭建平台](https://github.com/UnicomAI/wanwu)

这一章我目前没有仔细实操,等需要的时候再实践.因为只需要选择其中一个平台学习,这里介绍的比较基础,要掌握还得看他们各自的官方文档.

## 框架开发实践

这一章具体介绍了各类智能体开发框架,就像langchain之于RAG.

如果说 LangChain 和 LlamaIndex 定义了第一代通用 LLM 应用框架的范式，那么新一代的框架则更加专注于解决特定领域的深层挑战.

这么多框架,用哪一种来开发呢?选择困难症了呀~

### AutoGen

### AgentScope

### CAMEL

### LangGraph

## 构建你的Agent框架
