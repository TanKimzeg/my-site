---
title: å‘é‡ANNæœç´¢ç®—æ³• | EasyVectorDB
description: ANNï¼ˆApproximate Nearest Neighborsï¼‰æœç´¢æ˜¯ä¸€ç§ç”¨äºåœ¨é«˜ç»´ç©ºé—´ä¸­å¿«é€ŸæŸ¥æ‰¾æœ€è¿‘é‚»çš„ç®—æ³•ã€‚ä¸æš´åŠ›æœç´¢ä¸åŒï¼ŒANNæœç´¢é€šè¿‡å¼•å…¥è¿‘ä¼¼è®¡ç®—ï¼Œåœ¨ä¿æŒè¾ƒé«˜å¬å›ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘äº†è®¡ç®—å¤æ‚åº¦ã€‚
pubDate: 2026 01 13 
categories: 
  - tech
tags:
  - rag
---

ANNï¼ˆApproximate Nearest Neighborsï¼‰æœç´¢æ˜¯ä¸€ç§ç”¨äºåœ¨é«˜ç»´ç©ºé—´ä¸­å¿«é€ŸæŸ¥æ‰¾æœ€è¿‘é‚»çš„ç®—æ³•ã€‚ä¸æš´åŠ›æœç´¢ä¸åŒï¼ŒANNæœç´¢é€šè¿‡å¼•å…¥è¿‘ä¼¼è®¡ç®—ï¼Œåœ¨ä¿æŒè¾ƒé«˜å¬å›ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘äº†è®¡ç®—å¤æ‚åº¦ã€‚

## INFç®—æ³•

å€’æ’æ–‡ä»¶ç´¢å¼•ã€‚ï¼ˆInverted File Indexï¼‰ï¼šä½¿ç”¨ K-Means å°†å‘é‡èšæˆå¤šä¸ªç°‡ï¼ˆClusterï¼‰ï¼Œæœç´¢æ—¶åªåœ¨æœ€ç›¸è¿‘çš„å‡ ä¸ªç°‡å†…æŸ¥æ‰¾ã€‚

### ç¬¬ä¸€é˜¶æ®µï¼šç´¢å¼•æ„å»º

1. èšç±»è®­ç»ƒ

 ä½¿ç”¨èšç±»ç®—æ³•ï¼ˆé€šå¸¸æ˜¯K-meanç®—æ³•ï¼‰å°†æ‰€æœ‰å‘é‡åˆ’åˆ†æˆnlistä¸ªç°‡ã€‚nlistæ˜¯ä¸€ä¸ªå…³é”®å‚æ•°ï¼Œå®ƒå†³å®šäº†ç©ºé—´åˆ’åˆ†çš„ç²’åº¦ã€‚æ¯ä¸ªç°‡éƒ½æœ‰ä¸€ä¸ªä¸­å¿ƒç‚¹ï¼Œç§°ä¸ºâ€‹â€‹è´¨å¿ƒï¼ˆcentroidï¼‰â€‹â€‹ã€‚æ‰€æœ‰è¿™äº›è´¨å¿ƒæ„æˆäº†ä¸€ä¸ªâ€œè´¨å¿ƒè¡¨â€ã€‚

2. å‘é‡åˆ†é…

 éå†æ•°æ®é›†ä¸­çš„æ¯ä¸€ä¸ªå‘é‡ï¼Œè®¡ç®—å®ƒä¸æ‰€æœ‰è´¨å¿ƒçš„è·ç¦»ï¼ˆå¦‚æ¬§æ°è·ç¦»ï¼‰ã€‚å°†æ¯ä¸ªå‘é‡åˆ†é…åˆ°â€‹â€‹è·ç¦»å®ƒæœ€è¿‘çš„é‚£ä¸ªè´¨å¿ƒâ€‹â€‹æ‰€å¯¹åº”çš„ç°‡ä¸­ã€‚

3. å½¢æˆå€’æ’è¡¨

 ä¸ºæ¯ä¸€ä¸ªç°‡å»ºç«‹ä¸€ä¸ªâ€‹â€‹å€’æ’åˆ—è¡¨â€‹â€‹ã€‚è¿™ä¸ªåˆ—è¡¨å°±åƒå›¾ä¹¦é¦†æ¯ä¸ªåˆ†ç±»ä¹¦æ¶ä¸Šçš„å›¾ä¹¦æ¸…å•ï¼Œå®ƒè®°å½•äº†æ‰€æœ‰å±äºè¿™ä¸ªç°‡çš„â€‹â€‹å‘é‡çš„IDä»¥åŠå‘é‡æœ¬èº«â€‹â€‹ï¼ˆæˆ–å®ƒçš„å‹ç¼©è¡¨ç¤ºï¼‰ã€‚è‡³æ­¤ï¼Œç´¢å¼•æ„å»ºå®Œæˆã€‚

```python
class SimpleKMeans:
Â  Â  """ç®€åŒ–çš„K-meanså®ç°ç”¨äºIVFèšç±»"""
Â  Â  def __init__(self, n_clusters=3, max_iters=100):
Â  Â  Â  Â  self.n_clusters = n_clusters
Â  Â  Â  Â  self.max_iters = max_iters
Â  Â  Â  Â  self.centroids = None
Â  Â  Â  Â  self.labels_ = None
Â  Â  def fit(self, X: np.ndarray):
Â  Â  Â  Â  n_samples, n_features = X.shape
Â  Â  Â  Â  # 1. éšæœºåˆå§‹åŒ–è´¨å¿ƒ
Â  Â  Â  Â  random_indices = np.random.choice(n_samples, self.n_clusters, replace=False)
Â  Â  Â  Â  self.centroids = X[random_indices]
Â  Â  Â  Â  for iteration in range(self.max_iters):
Â  Â  Â  Â  Â  Â  # 2. åˆ†é…æ¯ä¸ªç‚¹åˆ°æœ€è¿‘çš„è´¨å¿ƒ
Â  Â  Â  Â  Â  Â  distances = euclidean_distances(X, self.centroids)
Â  Â  Â  Â  Â  Â  labels = np.argmin(distances, axis=1)
Â  Â  Â  Â  Â  Â  # 3. æ›´æ–°è´¨å¿ƒä½ç½®
Â  Â  Â  Â  Â  Â  new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(self.n_clusters)])
Â  Â  Â  Â  Â  Â  # æ£€æŸ¥æ”¶æ•›
Â  Â  Â  Â  Â  Â  if np.allclose(self.centroids, new_centroids):
Â  Â  Â  Â  Â  Â  Â  Â  break
Â  Â  Â  Â  Â  Â  self.centroids = new_centroids
Â  Â  Â  Â  Â  Â  self.labels_ = labels
Â  Â  Â  Â  return self
```

### ç¬¬äºŒé˜¶æ®µï¼šæŸ¥è¯¢å¤„ç†

1. å®šä½æœ€è¿‘ç°‡ï¼šè®¡ç®—æŸ¥è¯¢å‘é‡ä¸è´¨å¿ƒè¡¨ä¸­æ‰€æœ‰nlistä¸ªç°‡çš„è·ç¦»
2. é€‰æ‹©å€™é€‰ç°‡ï¼šÂ æ ¹æ®ä¸Šä¸€æ­¥çš„è·ç¦»ç»“æœï¼Œé€‰æ‹©è·ç¦»æœ€è¿‘çš„ nprobeä¸ªç°‡ä½œä¸ºå€™é€‰ç°‡ã€‚â€‹â€‹nprobeæ˜¯IVFç®—æ³•ä¸­æœ€å…³é”®çš„è°ƒä¼˜å‚æ•°ä¹‹ä¸€â€‹â€‹ï¼š nprobeè¶Šå°ï¼Œæœç´¢èŒƒå›´è¶Šå°ï¼Œâ€‹â€‹é€Ÿåº¦è¶Šå¿«ï¼Œä½†å¯èƒ½æ¼æ‰ä¸€äº›çœŸæ­£è¿‘é‚»ï¼ˆå¬å›ç‡é™ä½ï¼‰â€‹â€‹ã€‚ nprobeè¶Šå¤§ï¼Œæœç´¢èŒƒå›´è¶Šå¤§ï¼Œâ€‹â€‹å¬å›ç‡è¶Šé«˜ï¼Œä½†è®¡ç®—é‡å¢å¤§ï¼Œé€Ÿåº¦å˜æ…¢â€‹â€‹ã€‚
3. ç°‡å†…ç²¾ç»†æ¯”è¾ƒï¼šåœ¨é€‰å®šçš„ nprobeä¸ªå€™é€‰ç°‡çš„å€’æ’åˆ—è¡¨ä¸­ï¼Œè¿›è¡Œç²¾ç»†çš„è·ç¦»è®¡ç®—ã€‚
 å…·ä½“æ–¹å¼å–å†³äºIVFçš„å˜ä½“ï¼š

- IVF-Flatï¼šç›´æ¥ä½¿ç”¨åŸå§‹çš„ã€æœªå‹ç¼©çš„å‘é‡ä¸æŸ¥è¯¢å‘é‡è¿›è¡Œç²¾ç¡®è·ç¦»è®¡ç®—ã€‚è¿™ç§æ–¹å¼ç²¾åº¦æœ€é«˜ï¼Œä½†å†…å­˜å ç”¨ä¹Ÿæœ€å¤§ã€‚
- IVF-PQï¼šä¸ºäº†è¿›ä¸€æ­¥èŠ‚çœå†…å­˜å’ŒåŠ é€Ÿè®¡ç®—ï¼Œä¼šå¯¹ç°‡å†…å‘é‡ä½¿ç”¨ä¹˜ç§¯é‡åŒ–ï¼ˆProduct Quantizationï¼‰ è¿›è¡Œå‹ç¼©ã€‚æœç´¢æ—¶ä½¿ç”¨è¿‘ä¼¼è·ç¦»è®¡ç®—ï¼Œè¿™æ˜¯ä¸€ç§ç”¨å°‘é‡ç²¾åº¦æ¢å–å·¨å¤§å­˜å‚¨å’Œè®¡ç®—æ•ˆç‡æå‡çš„ç­–ç•¥ã€‚

4. ç»“æœåˆå¹¶ä¸è¿”å›ï¼šå°†æ‰€æœ‰å€™é€‰ç°‡ä¸­çš„å‘é‡æ ¹æ®ä¸æŸ¥è¯¢å‘é‡çš„è·ç¦»è¿›è¡Œæ’åºï¼Œæœ€ç»ˆè¿”å› Top-K ä¸ªæœ€ç›¸ä¼¼çš„å‘é‡ä½œä¸ºç»“æœã€‚

```python
class SimpleIVF:
    """ç®€åŒ–çš„IVFå®ç°"""
    def __init__(self, n_clusters=3, n_probe=2):
        self.n_clusters = n_clusters
        self.n_probe = n_probe  # æœç´¢æ—¶æ¢æµ‹çš„ç°‡æ•°é‡
        self.kmeans = None
        self.inverted_lists = None  # å€’æ’åˆ—è¡¨
        self.centroids = None
        self.is_trained = False
        self.data = None
    
    def train(self, data):
        """è®­ç»ƒIVFç´¢å¼•ï¼šå¯¹æ•°æ®è¿›è¡Œèšç±»"""
        print("å¼€å§‹è®­ç»ƒIVFç´¢å¼•...")
        self.kmeans = SimpleKMeans(n_clusters=self.n_clusters)
        self.kmeans.fit(data)
        self.centroids = self.kmeans.centroids
        self.is_trained = True
        print(f"è®­ç»ƒå®Œæˆï¼Œå¾—åˆ°{self.n_clusters}ä¸ªç°‡")
    
    def build_index(self, data):
        """æ„å»ºå€’æ’ç´¢å¼•"""
        if not all([self.is_trained, self.data, self.centroids]):
            self.train(data)
        self.data = data
        
        # åˆå§‹åŒ–å€’æ’åˆ—è¡¨
        self.inverted_lists = defaultdict(list)
        
        # å°†æ¯ä¸ªå‘é‡åˆ†é…åˆ°æœ€è¿‘çš„ç°‡
        distances = euclidean_distances(data, self.centroids)
        labels = np.argmin(distances, axis=1)
        
        # æ„å»ºå€’æ’åˆ—è¡¨ï¼šç°‡ID -> è¯¥ç°‡ä¸­æ‰€æœ‰å‘é‡çš„ç´¢å¼•
        for idx, label in enumerate(labels):
            self.inverted_lists[label].append(idx)
        
        print("å€’æ’ç´¢å¼•æ„å»ºå®Œæˆ:")
        for cluster_id, items in self.inverted_lists.items():
            print(f"  ç°‡{cluster_id}: {len(items)}ä¸ªå‘é‡")

    def search(self, query: np.ndarray, k=5):
        """IVFæœç´¢ï¼šå…ˆæ‰¾æœ€è¿‘çš„ç°‡ï¼Œç„¶ååœ¨ç°‡å†…æœç´¢"""
            
        # 1. ç²—ç•¥æœç´¢ï¼šæ‰¾åˆ°æœ€è¿‘çš„n_probeä¸ªç°‡
        distances_to_centroids = euclidean_distances(query.reshape(1, -1), self.centroids)[0]
        nearest_cluster_indices = np.argsort(distances_to_centroids)[:self.n_probe]
        
        # 2. ç²¾ç»†æœç´¢ï¼šåœ¨é€‰ä¸­çš„ç°‡å†…è¿›è¡Œæš´åŠ›æœç´¢
        if self.inverted_lists is None or self.data is None:
            raise ValueError("å€’æ’åˆ—è¡¨æœªæ„å»ºï¼Œè¯·å…ˆè°ƒç”¨build_index()æ–¹æ³•ã€‚")
        candidate_indices = []
        for cluster_idx in nearest_cluster_indices:
            candidate_indices.extend(self.inverted_lists[cluster_idx])
        
        if not candidate_indices:
            return [], []
        
        # åœ¨å€™é€‰å‘é‡ä¸­è®¡ç®—è·ç¦»
        candidate_vectors = self.data[candidate_indices]
        distances = euclidean_distances(query.reshape(1, -1), candidate_vectors)[0]
        
        # è·å–æœ€è¿‘çš„kä¸ªç»“æœ
        if k > len(distances):
            k = len(distances)
            
        nearest_indices_within_candidates = np.argsort(distances)[:k]
        
        # æ˜ å°„å›åŸå§‹ç´¢å¼•
        final_indices = [candidate_indices[i] for i in nearest_indices_within_candidates]
        final_distances = distances[nearest_indices_within_candidates]
        
        return final_indices, final_distances
    
    def brute_force_search(self, query: np.ndarray, k=5):
        """æš´åŠ›æœç´¢ä½œä¸ºå¯¹æ¯”åŸºå‡†"""
        if self.data is None:
            raise ValueError("æ•°æ®æœªåŠ è½½ï¼Œè¯·å…ˆæ„å»ºç´¢å¼•æˆ–æä¾›æ•°æ®ã€‚")

        distances = euclidean_distances(query.reshape(1, -1), self.data)[0]
        nearest_indices = np.argsort(distances)[:k]
        return nearest_indices, distances[nearest_indices]
```

> ä»£ç ç»è¿‡æˆ‘çš„ä¼˜åŒ–å¯ç›´æ¥è¿è¡Œæ— ç±»å‹é”™è¯¯è­¦å‘Šã€‚

ä¸‹é¢ç›´è§‚å±•ç¤ºINFç®—æ³•çš„è®­ç»ƒã€æ„å»ºå’ŒæŸ¥è¯¢è¿‡ç¨‹ï¼š

![INFç®—æ³•è®­ç»ƒã€æ„å»ºå’ŒæŸ¥è¯¢è¿‡ç¨‹](https://datawhalechina.github.io/easy-vectordb/images/IVF%E7%AE%97%E6%B3%95%E7%BB%93%E6%9E%9C.png)

## PQç®—æ³•

PQï¼ˆ**Product Quantizationï¼Œä¹˜ç§¯é‡åŒ–**ï¼‰æ˜¯ä¸€ç§**é«˜æ•ˆçš„å‘é‡å‹ç¼©ä¸è¿‘ä¼¼è·ç¦»è®¡ç®—æ–¹æ³•**ï¼Œ  
ä¸»è¦åº”ç”¨äºå¤§è§„æ¨¡å‘é‡æ£€ç´¢ä¸­ï¼Œç”¨äºé™ä½**å­˜å‚¨æˆæœ¬**å’Œ**è®¡ç®—å¼€é”€**ï¼ŒåŒæ—¶ä¿æŒè¾ƒé«˜çš„è¿‘ä¼¼ç²¾åº¦ã€‚

PQ çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **å°†é«˜ç»´å‘é‡æ‹†åˆ†ä¸ºå¤šä¸ªå­å‘é‡ï¼Œåœ¨å­ç©ºé—´å†…è¿›è¡Œç‹¬ç«‹é‡åŒ–ï¼Œå†é€šè¿‡æŸ¥è¡¨æ³•å¿«é€Ÿè®¡ç®—è¿‘ä¼¼è·ç¦»ã€‚**

### å‘é‡åˆ†å—

å‡è®¾åŸå§‹å‘é‡$\mathbf{x}\in{\mathbb{R}^D}$,å°†å…¶åˆ’åˆ†ä¸º$m$ä¸ªå­ç©ºé—´ï¼š
$$\mathbf{x}=[\mathbf{x}_{1},\mathbf{x}_{2},\dots \mathbf{x}_{m}],\mathbf{x}_{i}\in \mathbb{R}^{D/m}$$,æ¯ä¸ªå­å‘é‡åœ¨å¯¹åº”çš„å­ç©ºé—´ç‹¬ç«‹å¤„ç†ï¼Œå‡å°‘ç»´åº¦å¯¹é‡åŒ–çš„å¤æ‚æ€§ã€‚

### å­ç©ºé—´é‡åŒ–

1. å¯¹æ¯ä¸ªå­ç©ºé—´Â $\mathbf{x}_{i}$Â æ„å»ºä¸€ä¸ª**å­ç æœ¬ï¼ˆCodebookï¼‰**ï¼š ä½¿ç”¨èšç±»ç®—æ³•ï¼ˆå¦‚ K-Meansï¼‰å°†è¯¥å­ç©ºé—´å‘é‡åˆ’åˆ†ä¸ºÂ $k$Â ä¸ªèšç±»ä¸­å¿ƒï¼š$$C_{i}={c_{i,1},c_{i,2},â€¦,c_{i,k}}$$
2. å°†æ¯ä¸ªå­å‘é‡Â $\mathbf{x}_{i}$Â æ›¿æ¢ä¸ºå…¶æœ€è¿‘çš„èšç±»ä¸­å¿ƒç¼–å·Â $q_{i}$ï¼š$qi=\text{arg min}_{j}\left \|  xiâˆ’c_{i,j} \right \|$
3. æœ€ç»ˆï¼Œä¸€ä¸ªé«˜ç»´å‘é‡è¢«è¡¨ç¤ºä¸ºä¸€ç»„æ•´æ•°ç´¢å¼•ï¼š$\mathbf{x}â‰ˆ[q1,q2,â€¦,qm]$

âœ… è¿™å°±æ˜¯ PQ çš„æ ¸å¿ƒå‹ç¼©æ–¹å¼ï¼Œå°†æµ®ç‚¹å‘é‡è½¬ä¸ºä½ä½æ•´æ•°ç´¢å¼•ï¼Œå¤§å¹…èŠ‚çœå­˜å‚¨ã€‚

### è¿‘ä¼¼è·ç¦»è®¡ç®—

å½“æœ‰æŸ¥è¯¢å‘é‡Â $\mathbf{y}$Â æ—¶ï¼š

1. å°†æŸ¥è¯¢å‘é‡åŒæ ·åˆ’åˆ†ä¸ºÂ $m$Â ä¸ªå­å‘é‡ï¼š$\mathbf{y}=[\mathbf{y}_{1},\mathbf{y}_{2},â€¦,\mathbf{y}_{m}]$
2. å¯¹æ¯ä¸ªå­å‘é‡Â $\mathbf{y}_{i}$Â ä¸å¯¹åº”å­ç æœ¬Â $C_{i}$Â è®¡ç®—**å­ç©ºé—´è·ç¦»è¡¨**ï¼š$D_{i}[j]=\left \| \mathbf{y}_{i}âˆ’c_{i,j} \right \| ^2,j=1,â€¦,k$
3. å‘é‡Â $\mathbf{x}$Â ä¸Â $\mathbf{y}$Â çš„è¿‘ä¼¼è·ç¦»å¯é€šè¿‡æŸ¥è¡¨æ³•å¿«é€Ÿè®¡ç®—ï¼š$\left \| \mathbf{y}âˆ’\mathbf{x} \right \|^2â‰ˆâˆ‘_{i=1}^mD_{i}[q_{i}]$

```python
class ProductQuantization:
    """ä¹˜ç§¯é‡åŒ–ç®—æ³•å®ç°"""
    
    def __init__(self, dim:int, M=8, K=256):
        """
        åˆå§‹åŒ–PQå‚æ•°
        
        å‚æ•°:
        - M: å­ç©ºé—´æ•°é‡ï¼ˆå°†å‘é‡åˆ†å‰²æˆå¤šå°‘æ®µï¼‰
        - K: æ¯ä¸ªå­ç©ºé—´çš„èšç±»ä¸­å¿ƒæ•°é‡ï¼ˆå¿…é¡»æ˜¯2çš„å¹‚æ¬¡ï¼Œå¦‚256=2^8ï¼‰
        """
        self.M = M
        self.K = K
        self.codebooks = None  # ç æœ¬ï¼šå­˜å‚¨æ¯ä¸ªå­ç©ºé—´çš„èšç±»ä¸­å¿ƒ
        self.sub_dim = dim // M  # æ¯ä¸ªå­ç©ºé—´çš„ç»´åº¦
        self.is_trained = False
    
    def train(self, vectors: np.ndarray, max_iter=100):
        """
        è®­ç»ƒPQç æœ¬
        
        å‚æ•°:
        - vectors: è®­ç»ƒæ•°æ®ï¼Œå½¢çŠ¶ä¸º (n_vectors, dim)
        - max_iter: K-meansæœ€å¤§è¿­ä»£æ¬¡æ•°
        """
        n_vectors, dim = vectors.shape
        
        # æ£€æŸ¥ç»´åº¦æ˜¯å¦å¯è¢«Mæ•´é™¤
        if dim % self.M != 0:
            raise ValueError(f"å‘é‡ç»´åº¦{dim}ä¸èƒ½è¢«M={self.M}æ•´é™¤")
        
        self.sub_dim = dim // self.M
        self.codebooks = np.zeros((self.M, self.K, self.sub_dim), dtype=np.float32)
        
        print(f"å¼€å§‹è®­ç»ƒPQç æœ¬: {dim}ç»´å‘é‡åˆ†å‰²ä¸º{self.M}ä¸ªå­ç©ºé—´ï¼Œæ¯ä¸ªå­ç©ºé—´{self.sub_dim}ç»´")
        print(f"æ¯ä¸ªå­ç©ºé—´ä½¿ç”¨K={self.K}ä¸ªèšç±»ä¸­å¿ƒ")
        
        # å¯¹æ¯ä¸ªå­ç©ºé—´åˆ†åˆ«è¿›è¡ŒK-meansèšç±»
        for m in range(self.M):
            print(f"è®­ç»ƒå­ç©ºé—´ {m+1}/{self.M}...")
            
            # æå–å½“å‰å­ç©ºé—´çš„æ•°æ®
            sub_vectors = vectors[:, m*self.sub_dim:(m+1)*self.sub_dim]
            
            # ä½¿ç”¨K-meansèšç±»
            # kmeans2è¿”å›èšç±»ä¸­å¿ƒå’Œæ¯ä¸ªç‚¹æ‰€å±çš„ç°‡æ ‡ç­¾
            centroids, labels = kmeans2(sub_vectors, self.K, iter=max_iter, minit='points')
            self.codebooks[m] = centroids.astype(np.float32)
        
        self.is_trained = True
        print("PQç æœ¬è®­ç»ƒå®Œæˆ!")
        return self.codebooks
    
    def encode(self, vectors: np.ndarray):
        """
        å°†å‘é‡ç¼–ç ä¸ºPQç 
        
        å‚æ•°:
        - vectors: å¾…ç¼–ç çš„å‘é‡ï¼Œå½¢çŠ¶ä¸º (n_vectors, dim)
        
        è¿”å›:
        - codes: PQç¼–ç ï¼Œå½¢çŠ¶ä¸º (n_vectors, M)ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯0åˆ°K-1çš„æ•´æ•°
        """
        if not self.is_trained or self.codebooks is None:
            raise ValueError("è¯·å…ˆè®­ç»ƒPQç æœ¬")
        
        n_vectors = vectors.shape[0]
        codes = np.zeros((n_vectors, self.M), dtype=np.uint8)
        
        for m in range(self.M):
            # æå–å½“å‰å­ç©ºé—´çš„å‘é‡
            sub_vectors = vectors[:, m*self.sub_dim:(m+1)*self.sub_dim]
            
            # ä¸ºæ¯ä¸ªå­å‘é‡æ‰¾åˆ°æœ€è¿‘çš„èšç±»ä¸­å¿ƒ
            labels, _ = vq(sub_vectors, self.codebooks[m])
            codes[:, m] = labels
        
        return codes
    
    def decode(self, codes: np.ndarray):
        """
        å°†PQç è§£ç ä¸ºè¿‘ä¼¼å‘é‡
        
        å‚æ•°:
        - codes: PQç¼–ç ï¼Œå½¢çŠ¶ä¸º (n_vectors, M)
        
        è¿”å›:
        - approx_vectors: è¿‘ä¼¼å‘é‡ï¼Œå½¢çŠ¶ä¸º (n_vectors, dim)
        """
        if not self.is_trained or self.codebooks is None:
            raise ValueError("è¯·å…ˆè®­ç»ƒPQç æœ¬")
        
        n_vectors = codes.shape[0]
        dim = self.M * self.sub_dim
        approx_vectors = np.zeros((n_vectors, dim), dtype=np.float32)
        
        for m in range(self.M):
            # ç”¨èšç±»ä¸­å¿ƒæ›¿æ¢ç¼–ç 
            approx_vectors[:, m*self.sub_dim:(m+1)*self.sub_dim] = \
                self.codebooks[m][codes[:, m]]
        
        return approx_vectors
    
    def build_distance_table(self, query):
        """
        æ„å»ºæŸ¥è¯¢å‘é‡çš„è·ç¦»è¡¨ï¼ˆADC: Asymmetric Distance Computationï¼‰
        
        å‚æ•°:
        - query: æŸ¥è¯¢å‘é‡ï¼Œå½¢çŠ¶ä¸º (dim,)
        
        è¿”å›:
        - dist_table: è·ç¦»è¡¨ï¼Œå½¢çŠ¶ä¸º (M, K)
        """
        if not self.is_trained or self.codebooks is None:
            raise ValueError("è¯·å…ˆè®­ç»ƒPQç æœ¬")
        
        dist_table = np.zeros((self.M, self.K), dtype=np.float32)
        
        for m in range(self.M):
            # æå–æŸ¥è¯¢å‘é‡çš„å­å‘é‡
            query_sub = query[m*self.sub_dim:(m+1)*self.sub_dim]
            
            # è®¡ç®—æŸ¥è¯¢å­å‘é‡åˆ°å½“å‰å­ç©ºé—´æ‰€æœ‰èšç±»ä¸­å¿ƒçš„è·ç¦»
            dist_table[m] = cdist([query_sub], self.codebooks[m], 'sqeuclidean')[0]
        
        return dist_table
    
    def search(self, query: np.ndarray, codes: np.ndarray, top_k=5):
        """
        ä½¿ç”¨PQè¿›è¡Œè¿‘ä¼¼æœ€è¿‘é‚»æœç´¢
        
        å‚æ•°:
        - query: æŸ¥è¯¢å‘é‡ï¼Œå½¢çŠ¶ä¸º (dim,)
        - codes: æ•°æ®åº“å‘é‡çš„PQç¼–ç ï¼Œå½¢çŠ¶ä¸º (n_vectors, M)
        - top_k: è¿”å›æœ€ç›¸ä¼¼çš„top_kä¸ªç»“æœ
        
        è¿”å›:
        - indices: æœ€è¿‘é‚»çš„ç´¢å¼•
        - distances: å¯¹åº”çš„è·ç¦»
        """
        if not self.is_trained:
            raise ValueError("è¯·å…ˆè®­ç»ƒPQç æœ¬")
        
        # æ„å»ºè·ç¦»è¡¨
        dist_table = self.build_distance_table(query)
        
        n_vectors = codes.shape[0]
        distances = np.zeros(n_vectors, dtype=np.float32)
        
        # è®¡ç®—æ¯ä¸ªæ•°æ®åº“å‘é‡ä¸æŸ¥è¯¢å‘é‡çš„è¿‘ä¼¼è·ç¦»
        for i in range(n_vectors):
            for m in range(self.M):
                # ç´¯åŠ æ¯ä¸ªå­ç©ºé—´çš„è·ç¦»
                distances[i] += dist_table[m, codes[i, m]]
        
        # è¿”å›è·ç¦»æœ€å°çš„top_kä¸ªç»“æœ
        indices = np.argsort(distances)[:top_k]
        return indices, distances[indices]

    def brute_force_search(self, query: np.ndarray, vectors: np.ndarray, top_k=5):
        """
        æš´åŠ›æœç´¢ä½œä¸ºåŸºå‡†å¯¹æ¯”
        """
        distances = cdist([query], vectors, 'sqeuclidean')[0]
        indices = np.argsort(distances)[:top_k]
        return indices, distances[indices]
```

### å°ç»“

**PQ çš„æ ¸å¿ƒä¼˜åŠ¿**ï¼š

- **é«˜å‹ç¼©ç‡**ï¼šå°†æµ®ç‚¹å‘é‡å‹ç¼©ä¸ºæ•´æ•°ç´¢å¼•ï¼Œå­˜å‚¨å ç”¨å¤§å¹…ä¸‹é™ï¼›
- **é«˜æ•ˆè·ç¦»è®¡ç®—**ï¼šé€šè¿‡æŸ¥è¡¨æ³•å¿«é€Ÿä¼°ç®—è·ç¦»ï¼Œé™ä½è®¡ç®—é‡ï¼›
- **å¯ç»„åˆæ€§å¼º**ï¼šå¯ä¸ IVFã€HNSW ç­‰ç´¢å¼•ç»“æ„ç»“åˆï¼Œå®ç°é«˜æ•ˆå¤§è§„æ¨¡æ£€ç´¢ï¼›
- **è¿‘ä¼¼ç²¾åº¦å¯è°ƒ**ï¼šé€šè¿‡è°ƒæ•´å­å‘é‡æ•°Â $m$Â å’Œèšç±»ä¸­å¿ƒæ•°Â $k$Â å¹³è¡¡ç²¾åº¦ä¸å­˜å‚¨ã€‚

ç»è¿‡æˆ‘çš„å®éªŒï¼Œå­ç©ºé—´æ•°é‡Måœ¨å¬å›ç‡ä¸Šèµ·çš„ä½œç”¨æ¯”Kå¤§ï¼Œè€Œä¸”åœ¨å®éªŒåœºæ™¯ä¸‹æ…¢äºæš´åŠ›æœç´¢ï¼Œè¯´æ˜è¿™æ®µPythonä»£ç çš„ç¼“å­˜ä¼˜åŒ–å¾ˆå·®ã€‚

```log
============================================================
PQç®—æ³•æ¼”ç¤º
ç”Ÿæˆè®­ç»ƒæ•°æ®...
è®­ç»ƒæ•°æ®: (5000, 128)
æ•°æ®åº“æ•°æ®: (10000, 128)
å¼€å§‹è®­ç»ƒPQç æœ¬: 128ç»´å‘é‡åˆ†å‰²ä¸º8ä¸ªå­ç©ºé—´ï¼Œæ¯ä¸ªå­ç©ºé—´16ç»´
æ¯ä¸ªå­ç©ºé—´ä½¿ç”¨K=256ä¸ªèšç±»ä¸­å¿ƒ
è®­ç»ƒå­ç©ºé—´ 1/8...
è®­ç»ƒå­ç©ºé—´ 2/8...
è®­ç»ƒå­ç©ºé—´ 3/8...
è®­ç»ƒå­ç©ºé—´ 4/8...
è®­ç»ƒå­ç©ºé—´ 5/8...
è®­ç»ƒå­ç©ºé—´ 6/8...
è®­ç»ƒå­ç©ºé—´ 7/8...
è®­ç»ƒå­ç©ºé—´ 8/8...
PQç æœ¬è®­ç»ƒå®Œæˆ!
è®­ç»ƒè€—æ—¶: 2.2187ç§’
ç¼–ç è€—æ—¶: 0.0486ç§’
å‹ç¼©æ¯”: 24.26x
åŸå§‹å¤§å°: 5000.00 KB
å‹ç¼©å: 206.12 KB

æœç´¢ç»“æœå¯¹æ¯”:
PQæœç´¢    - æ‰¾åˆ°5ä¸ªæœ€è¿‘é‚», è€—æ—¶: 0.023889ç§’
æš´åŠ›æœç´¢ - æ‰¾åˆ°5ä¸ªæœ€è¿‘é‚», è€—æ—¶: 0.008069ç§’
é€Ÿåº¦æå‡: 0.34å€

PQç»“æœç´¢å¼•: [   0 1000 4472  512 4080]
PQç»“æœè·ç¦»: [ 6.1899347 11.832801  12.133605  12.273722  12.286916 ]
æš´åŠ›æœç´¢ç»“æœç´¢å¼•: [   0 5260 9000 2456 5820]
æš´åŠ›æœç´¢ç»“æœè·ç¦»: [ 0.         15.6129819  16.08607458 16.3027682  16.46445402]
Top-5å¬å›ç‡: 20.00% (1/5)
============================================================
PQç®—æ³•æ¼”ç¤º
============================================================
ç”Ÿæˆè®­ç»ƒæ•°æ®...
è®­ç»ƒæ•°æ®: (5000, 128)
æ•°æ®åº“æ•°æ®: (10000, 128)
å¼€å§‹è®­ç»ƒPQç æœ¬: 128ç»´å‘é‡åˆ†å‰²ä¸º8ä¸ªå­ç©ºé—´ï¼Œæ¯ä¸ªå­ç©ºé—´16ç»´
æ¯ä¸ªå­ç©ºé—´ä½¿ç”¨K=512ä¸ªèšç±»ä¸­å¿ƒ
è®­ç»ƒå­ç©ºé—´ 1/8...
è®­ç»ƒå­ç©ºé—´ 2/8...
è®­ç»ƒå­ç©ºé—´ 3/8...
è®­ç»ƒå­ç©ºé—´ 4/8...
è®­ç»ƒå­ç©ºé—´ 5/8...
è®­ç»ƒå­ç©ºé—´ 6/8...
è®­ç»ƒå­ç©ºé—´ 7/8...
è®­ç»ƒå­ç©ºé—´ 8/8...
PQç æœ¬è®­ç»ƒå®Œæˆ!
è®­ç»ƒè€—æ—¶: 3.4817ç§’
ç¼–ç è€—æ—¶: 0.0739ç§’
å‹ç¼©æ¯”: 14.96x
åŸå§‹å¤§å°: 5000.00 KB
å‹ç¼©å: 334.12 KB

æœç´¢ç»“æœå¯¹æ¯”:
PQæœç´¢    - æ‰¾åˆ°5ä¸ªæœ€è¿‘é‚», è€—æ—¶: 0.022838ç§’
æš´åŠ›æœç´¢ - æ‰¾åˆ°5ä¸ªæœ€è¿‘é‚», è€—æ—¶: 0.005850ç§’
é€Ÿåº¦æå‡: 0.26å€

PQç»“æœç´¢å¼•: [ 716 1980 9648 8016 6556]
PQç»“æœè·ç¦»: [13.538303 14.167534 14.455566 14.779416 14.861414]
æš´åŠ›æœç´¢ç»“æœç´¢å¼•: [   0 5260 9000 2456 5820]
æš´åŠ›æœç´¢ç»“æœè·ç¦»: [ 0.         15.6129819  16.08607458 16.3027682  16.46445402]
Top-5å¬å›ç‡: 0.00% (0/5)
============================================================
PQç®—æ³•æ¼”ç¤º
============================================================
ç”Ÿæˆè®­ç»ƒæ•°æ®...
è®­ç»ƒæ•°æ®: (5000, 128)
æ•°æ®åº“æ•°æ®: (10000, 128)
å¼€å§‹è®­ç»ƒPQç æœ¬: 128ç»´å‘é‡åˆ†å‰²ä¸º16ä¸ªå­ç©ºé—´ï¼Œæ¯ä¸ªå­ç©ºé—´8ç»´
æ¯ä¸ªå­ç©ºé—´ä½¿ç”¨K=256ä¸ªèšç±»ä¸­å¿ƒ
è®­ç»ƒå­ç©ºé—´ 1/16...
è®­ç»ƒå­ç©ºé—´ 2/16...
è®­ç»ƒå­ç©ºé—´ 3/16...
è®­ç»ƒå­ç©ºé—´ 4/16...
è®­ç»ƒå­ç©ºé—´ 5/16...
è®­ç»ƒå­ç©ºé—´ 6/16...
è®­ç»ƒå­ç©ºé—´ 7/16...
è®­ç»ƒå­ç©ºé—´ 8/16...
è®­ç»ƒå­ç©ºé—´ 9/16...
è®­ç»ƒå­ç©ºé—´ 10/16...
è®­ç»ƒå­ç©ºé—´ 11/16...
è®­ç»ƒå­ç©ºé—´ 12/16...
è®­ç»ƒå­ç©ºé—´ 13/16...
è®­ç»ƒå­ç©ºé—´ 14/16...
è®­ç»ƒå­ç©ºé—´ 15/16...
è®­ç»ƒå­ç©ºé—´ 16/16...
PQç æœ¬è®­ç»ƒå®Œæˆ!
è®­ç»ƒè€—æ—¶: 4.5288ç§’
ç¼–ç è€—æ—¶: 0.0869ç§’
å‹ç¼©æ¯”: 17.59x
åŸå§‹å¤§å°: 5000.00 KB
å‹ç¼©å: 284.25 KB

æœç´¢ç»“æœå¯¹æ¯”:
PQæœç´¢    - æ‰¾åˆ°5ä¸ªæœ€è¿‘é‚», è€—æ—¶: 0.045630ç§’
æš´åŠ›æœç´¢ - æ‰¾åˆ°5ä¸ªæœ€è¿‘é‚», è€—æ—¶: 0.004990ç§’
é€Ÿåº¦æå‡: 0.11å€

PQç»“æœç´¢å¼•: [   0 7760 3736  652 8548]
PQç»“æœè·ç¦»: [ 4.175756 13.200957 13.299522 13.447816 13.517618]
æš´åŠ›æœç´¢ç»“æœç´¢å¼•: [   0 5260 9000 2456 5820]
æš´åŠ›æœç´¢ç»“æœè·ç¦»: [ 0.         15.6129819  16.08607458 16.3027682  16.46445402]
Top-5å¬å›ç‡: 20.00% (1/5)
============================================================
PQç®—æ³•æ¼”ç¤º
============================================================
ç”Ÿæˆè®­ç»ƒæ•°æ®...
è®­ç»ƒæ•°æ®: (5000, 128)
æ•°æ®åº“æ•°æ®: (10000, 128)
å¼€å§‹è®­ç»ƒPQç æœ¬: 128ç»´å‘é‡åˆ†å‰²ä¸º32ä¸ªå­ç©ºé—´ï¼Œæ¯ä¸ªå­ç©ºé—´4ç»´
æ¯ä¸ªå­ç©ºé—´ä½¿ç”¨K=256ä¸ªèšç±»ä¸­å¿ƒ
è®­ç»ƒå­ç©ºé—´ 1/32...
è®­ç»ƒå­ç©ºé—´ 2/32...
è®­ç»ƒå­ç©ºé—´ 3/32...
è®­ç»ƒå­ç©ºé—´ 4/32...
è®­ç»ƒå­ç©ºé—´ 5/32...
è®­ç»ƒå­ç©ºé—´ 6/32...
è®­ç»ƒå­ç©ºé—´ 7/32...
è®­ç»ƒå­ç©ºé—´ 8/32...
è®­ç»ƒå­ç©ºé—´ 9/32...
è®­ç»ƒå­ç©ºé—´ 10/32...
è®­ç»ƒå­ç©ºé—´ 11/32...
è®­ç»ƒå­ç©ºé—´ 12/32...
è®­ç»ƒå­ç©ºé—´ 13/32...
è®­ç»ƒå­ç©ºé—´ 14/32...
è®­ç»ƒå­ç©ºé—´ 15/32...
è®­ç»ƒå­ç©ºé—´ 16/32...
è®­ç»ƒå­ç©ºé—´ 17/32...
è®­ç»ƒå­ç©ºé—´ 18/32...
è®­ç»ƒå­ç©ºé—´ 19/32...
è®­ç»ƒå­ç©ºé—´ 20/32...
è®­ç»ƒå­ç©ºé—´ 21/32...
è®­ç»ƒå­ç©ºé—´ 22/32...
è®­ç»ƒå­ç©ºé—´ 23/32...
è®­ç»ƒå­ç©ºé—´ 24/32...
è®­ç»ƒå­ç©ºé—´ 25/32...
è®­ç»ƒå­ç©ºé—´ 26/32...
è®­ç»ƒå­ç©ºé—´ 27/32...
è®­ç»ƒå­ç©ºé—´ 28/32...
è®­ç»ƒå­ç©ºé—´ 29/32...
è®­ç»ƒå­ç©ºé—´ 30/32...
è®­ç»ƒå­ç©ºé—´ 31/32...
è®­ç»ƒå­ç©ºé—´ 32/32...
PQç æœ¬è®­ç»ƒå®Œæˆ!
è®­ç»ƒè€—æ—¶: 5.6275ç§’
ç¼–ç è€—æ—¶: 0.1133ç§’
å‹ç¼©æ¯”: 11.35x
åŸå§‹å¤§å°: 5000.00 KB
å‹ç¼©å: 440.50 KB

æœç´¢ç»“æœå¯¹æ¯”:
PQæœç´¢    - æ‰¾åˆ°5ä¸ªæœ€è¿‘é‚», è€—æ—¶: 0.088496ç§’
æš´åŠ›æœç´¢ - æ‰¾åˆ°5ä¸ªæœ€è¿‘é‚», è€—æ—¶: 0.003024ç§’
é€Ÿåº¦æå‡: 0.03å€

PQç»“æœç´¢å¼•: [   0 9000 5820 9200 5564]
PQç»“æœè·ç¦»: [ 1.4812891 14.158425  14.903692  15.362539  15.634869 ]
æš´åŠ›æœç´¢ç»“æœç´¢å¼•: [   0 5260 9000 2456 5820]
æš´åŠ›æœç´¢ç»“æœè·ç¦»: [ 0.         15.6129819  16.08607458 16.3027682  16.46445402]
Top-5å¬å›ç‡: 60.00% (3/5)
```

## HNSWç®—æ³•

HNSWï¼ˆ**Hierarchical Navigable Small World**ï¼Œåˆ†å±‚å¯å¯¼èˆªå°ä¸–ç•Œå›¾ï¼‰æ˜¯ä¸€ç§åŸºäºå›¾ç»“æ„çš„**è¿‘ä¼¼æœ€è¿‘é‚»ï¼ˆANNï¼‰æœç´¢ç®—æ³•**ã€‚

### å›¾ç»“æ„çš„æ„å»º

1. éšæœºåˆ†é…å±‚çº§
 æ¯ä¸ªå‘é‡è¢«éšæœºåˆ†é…åˆ°æŸä¸€å±‚ï¼Œå±‚æ•°è¶Šé«˜ï¼ŒèŠ‚ç‚¹è¶Šå°‘ï¼Œæ•°é‡åˆ†å¸ƒéµå¾ªæŒ‡æ•°è¡°å‡è§„å¾‹ã€‚

2. é€å±‚æ’å…¥æ–°èŠ‚ç‚¹
 å½“æ–°å‘é‡$\mathbf{v}$è¿›å…¥ç³»ç»Ÿæ—¶ï¼Œä»ç»™å®ƒåˆ†é…çš„é‚£ä¸€å±‚å¼€å§‹å¾€ä¸‹é€å±‚æ’å…¥æ–°èŠ‚ç‚¹ã€‚åœ¨å½“å‰å±‚ï¼Œä»å…¥å£ç‚¹å¼€å§‹ï¼Œè¿ç”¨BFSç®—æ³•æ‰¾åˆ°ä¸$\mathbf{v}$æœ€æ¥è¿‘çš„ä¸€ç³»åˆ—èŠ‚ç‚¹ã€‚è¿™ä¸€ç³»åˆ—èŠ‚ç‚¹æ›´æ–°å®ƒä»¬çš„é‚»å±…é›†åˆï¼ŒæŠŠæ–°èŠ‚ç‚¹åŠ è¿›é‚»å±…é›†åˆé‡Œé¢ï¼ˆé‚»å±…é›†åˆæœ‰ä¿®å‰ªï¼‰ã€‚å…¶ä¸­æœ€è¿‘çš„é‚£ä¸ªèŠ‚ç‚¹ä½œä¸ºä¸‹ä¸€å±‚çš„å…¥å£ç‚¹ã€‚åŒæ—¶ï¼Œåœ¨ä¸‹ä¸€å±‚ï¼ŒåŠ å…¥æ–°èŠ‚ç‚¹åŠå…¶åˆšåˆšæœç´¢åˆ°çš„é‚»å±…é›†åˆã€‚

 ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸Šä¸€å±‚æœ‰çš„èŠ‚ç‚¹ï¼Œä¸€å®šå­˜åœ¨äºä¸‹ä¸€å±‚ä¸­ã€‚

3. æŸ¥è¯¢é˜¶æ®µ
 ä»æœ€é«˜å±‚çš„å…¥å£èŠ‚ç‚¹å¼€å§‹ï¼Œè¿ç”¨BFSç®—æ³•æ‰¾åˆ°ä¸æŸ¥è¯¢å‘é‡$\mathbf{q}$æœ€æ¥è¿‘çš„ä¸€ä¸ªèŠ‚ç‚¹ï¼Œä½œä¸ºä¸‹ä¸€å±‚çš„å…¥å£èŠ‚ç‚¹ã€‚
 é€æ­¥å‘ä¸‹ï¼Œç›´åˆ°æœ€åº•å±‚é€æ­¥ç¼©å°æœç´¢èŒƒå›´ï¼ŒèŠ‚ç‚¹å¯†åº¦é€æ¸å¢å¤§ï¼Œè¿”å›æœ€è¿‘é‚»å±…ä¸­å‰kä¸ªç»“æœã€‚

ç»è¿‡æˆ‘çš„å®éªŒï¼Œåœ¨å›ºå®š`np.random.seed(41)`çš„æƒ…å†µä¸‹ï¼Œå¬å›ç‡æœ‰æ—¶ä¸º0%ï¼Œæœ‰æ—¶ä¸º100%ï¼Œè¿™å¾ˆè¯¡å¼‚ä½ çŸ¥é“å—â€¦â€¦

ç„¶åæˆ‘å‘ç°ä»£ç é‡Œé¢æœ‰`random.random()` é—®é¢˜å¯èƒ½å‡ºåœ¨è¿™é‡Œã€‚`np.random.seed()`ä¸ç³»ç»Ÿçš„ `random.seed()` å¹¶ä¸ä¸€è‡´ã€‚æœç„¶ï¼Œå½“æˆ‘æŠŠ`random_level()`å‡½æ•°é‡Œé¢çš„`random.random`æ”¹ç”¨ `np`é‡Œé¢çš„randomï¼Œå¹¶ä¸”è®¾ç½® `np.random.seed(42)` åï¼Œå°±å¯ä»¥ç¨³å®š100%äº†ï¼›è€Œè®¾ç½® `random.seed(41)`åï¼Œå°±æ•ˆæœç¨³å®š0%ï¼Œå¬å›çš„æ ·æœ¬ä¹Ÿéƒ½ä¸€æ‘¸ä¸€æ ·ã€‚è¿™å¯ç¤ºæˆ‘ä»¬å¯ä»¥é€šè¿‡ç²¾å¿ƒé€‰æ‹©seedæ¥è¾¾åˆ°SOTAğŸ˜†ã€‚

```python
import numpy as np
from collections import defaultdict
from sklearn.metrics.pairwise import euclidean_distances


class SimpleHNSW:
    """ç®€åŒ–çš„HNSWå®ç°ï¼Œç”¨äºå­¦ä¹ æ¼”ç¤º"""
    
    def __init__(
            self, 
            max_elements=1000, 
            M: int=10, 
            ef_construction: int=50, 
            max_layers: int=6
        ) -> None:
        """
        åˆå§‹åŒ–HNSWç´¢å¼•
        
        å‚æ•°:
        - max_elements: æœ€å¤§å…ƒç´ æ•°é‡
        - M: æ¯ä¸ªèŠ‚ç‚¹çš„æœ€å¤§è¿æ¥æ•°
        - ef_construction: æ„å»ºæ—¶çš„æœç´¢èŒƒå›´
        - max_layers: æœ€å¤§å±‚æ•°
        """
        self.max_elements = max_elements
        self.M = M  # æ¯ä¸ªèŠ‚ç‚¹çš„æœ€å¤§è¿æ¥æ•°
        self.ef_construction = ef_construction  # æ„å»ºæ—¶çš„æœç´¢èŒƒå›´
        self.max_layers = max_layers  # æœ€å¤§å±‚æ•°
        
        # å­˜å‚¨æ‰€æœ‰æ•°æ®ç‚¹
        self.data_points = []
        # æ¯å±‚çš„å›¾ç»“æ„ï¼ˆé‚»æ¥è¡¨ï¼‰ï¼Œæ¯å±‚æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œkeyæ˜¯èŠ‚ç‚¹IDï¼Œvalueæ˜¯é‚»å±…åˆ—è¡¨
        self.layers = [defaultdict(list) for _ in range(max_layers)]
        # å…¨å±€å…¥å£ç‚¹ï¼ˆæœ€é«˜å±‚çš„èŠ‚ç‚¹ï¼‰
        self.entry_point = None
        self.entry_level = -1  # å…¥å£ç‚¹æ‰€åœ¨çš„æœ€é«˜å±‚çº§
        
    def _random_level(self) -> int:
        """éšæœºç”ŸæˆèŠ‚ç‚¹çš„å±‚çº§ï¼ˆæŒ‡æ•°åˆ†å¸ƒï¼‰"""
        level = 0
        while np.random.random() < 0.5 and level < self.max_layers - 1:
            level += 1
        return level
    
    def _euclidean_distance(
            self, a: np.ndarray, b: np.ndarray
        ) -> np.float64:
        """è®¡ç®—æ¬§æ°è·ç¦»"""
        return np.sqrt(np.sum((a - b) ** 2))
    
    def _search_layer(
            self, query: np.ndarray, entry_point: int, ef: int, layer: int
        ) -> list[tuple[np.float64, int]]:
        """
        åœ¨æŒ‡å®šå±‚æœç´¢æœ€è¿‘é‚»
        
        å‚æ•°:
        - query: æŸ¥è¯¢å‘é‡
        - entry_point: æœç´¢èµ·å§‹ç‚¹
        - ef: æœç´¢èŒƒå›´ï¼ˆè¿”å›çš„å€™é€‰ç‚¹æ•°é‡ï¼‰
        - layer: æœç´¢çš„å±‚çº§
        """
        if entry_point is None or entry_point not in self.layers[layer]:
            return []
            
        visited = set([entry_point])
        # å€™é€‰é›†ï¼šå­˜å‚¨(è·ç¦», èŠ‚ç‚¹ID)å…ƒç»„ï¼Œä»å…¥å£ç‚¹å¼€å§‹
        candidates: list[tuple[float, int]] = [(self._euclidean_distance(query, self.data_points[entry_point]), entry_point)]
        # ä½¿ç”¨å †æ¥ç»´æŠ¤å€™é€‰é›†ï¼ˆè¿™é‡Œç®€åŒ–ä¸ºåˆ—è¡¨æ’åºï¼‰
        results = []
        
        while candidates and len(results) < ef:
            # è·å–è·ç¦»æœ€è¿‘çš„å€™é€‰ç‚¹
            candidates.sort(key=lambda x: x[0])
            current_dist, current_point = candidates.pop(0)
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥å°†å½“å‰ç‚¹åŠ å…¥ç»“æœ
            if (not results or current_dist < results[-1][0]) and len(results) < ef:
                results.append((current_dist, current_point))
                results.sort(key=lambda x: x[0])  # ä¿æŒç»“æœæŒ‰è·ç¦»æ’åº
            
            # æ¢ç´¢å½“å‰ç‚¹çš„æ‰€æœ‰é‚»å±…èŠ‚ç‚¹
            for neighbor in self.layers[layer][current_point]:
                if neighbor not in visited:
                    visited.add(neighbor)
                    dist = self._euclidean_distance(query, self.data_points[neighbor])
                    candidates.append((dist, neighbor))
        
        return results

    def add_point(self, point: np.ndarray) -> None:
        """
        å‘HNSWä¸­æ·»åŠ æ–°ç‚¹
        
        å‚æ•°:
        - point: è¦æ·»åŠ çš„æ•°æ®ç‚¹å‘é‡
        """
        if len(self.data_points) >= self.max_elements:
            raise ValueError("è¾¾åˆ°æœ€å¤§å®¹é‡")
        
        point_id = len(self.data_points)  # æ–°ç‚¹åœ¨data_pointsä¸­çš„idç´¢å¼•
        self.data_points.append(point)
        
        # ç¡®å®šæ–°ç‚¹çš„å±‚çº§
        level = self._random_level()
        
        # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªç‚¹ï¼Œè®¾ä¸ºå…¥å£ç‚¹
        if self.entry_point is None:
            self.entry_point = point_id
            self.entry_level = level
            for l in range(level + 1):
                self.layers[l][point_id] = []  # åœ¨æ–°ç‚¹çš„æ¯ä¸€å±‚åˆ›å»ºç©ºé‚»å±…åˆ—è¡¨
            return
        
        # ä»æœ€é«˜å±‚å¼€å§‹æœç´¢ï¼Œæ‰¾åˆ°æ¯å±‚çš„æœ€è¿‘é‚»
        current_point = self.entry_point
        current_max_level = self.entry_level
        
        # ä»é¡¶å±‚å¼€å§‹æœç´¢ï¼Œæ‰¾åˆ°æ¯å±‚çš„å…¥å£ç‚¹
        for l in range(current_max_level, level, -1):
            if l < len(self.layers):
                results = self._search_layer(point, current_point, 1, l)
                if results:
                    current_point = results[0][1]  # æ›´æ–°ä¸ºæœ€è¿‘çš„ç‚¹
        
        # ä»æ–°ç‚¹çš„æœ€é«˜å±‚å¼€å§‹ï¼Œé€å±‚å‘ä¸‹æ’å…¥å¹¶å»ºç«‹è¿æ¥
        for l in range(min(level, current_max_level), -1, -1):
            # åœ¨å½“å‰å±‚æœç´¢ef_constructionä¸ªæœ€è¿‘é‚»
            results = self._search_layer(point, current_point, self.ef_construction, l)
            
            # é€‰æ‹©å‰Mä¸ªæœ€è¿‘é‚»ä½œä¸ºè¿æ¥
            neighbors = [idx for _, idx in results[:self.M]]
            
            # åœ¨æ–°ç‚¹çš„å½“å‰å±‚åˆ›å»ºè¿æ¥
            self.layers[l][point_id] = neighbors.copy()
            
            # åŒå‘è¿æ¥ï¼šé‚»å±…ä¹Ÿè¿æ¥åˆ°æ–°ç‚¹
            for neighbor in neighbors:
                if len(self.layers[l][neighbor]) < self.M:
                    # é‚»å±…è¿æ¥æ•°æœªæ»¡ï¼Œç›´æ¥æ·»åŠ 
                    self.layers[l][neighbor].append(point_id)
                else:
                    # å¦‚æœé‚»å±…è¿æ¥æ•°å·²æ»¡ï¼Œæ›¿æ¢æœ€è¿œçš„è¿æ¥
                    neighbor_neighbors = self.layers[l][neighbor]
                    distances = [self._euclidean_distance(self.data_points[neighbor], 
                                                         self.data_points[n]) for n in neighbor_neighbors]
                    max_idx = np.argmax(distances)  # æ‰¾åˆ°æœ€è¿œçš„é‚»å±…
                    # å¦‚æœæ–°ç‚¹æ›´è¿‘ï¼Œåˆ™æ›¿æ¢æœ€è¿œçš„é‚»å±…
                    if self._euclidean_distance(self.data_points[neighbor], point) < distances[max_idx]:
                        neighbor_neighbors[max_idx] = point_id
            
            # æ›´æ–°å½“å‰ç‚¹ç”¨äºä¸‹ä¸€å±‚çš„æœç´¢
            if results:
                current_point = results[0][1]
        
        # å¦‚æœæ–°ç‚¹çš„å±‚çº§æ¯”å½“å‰å…¥å£ç‚¹é«˜ï¼Œæ›´æ–°å…¥å£ç‚¹
        if level > self.entry_level:
            self.entry_point = point_id
            self.entry_level = level
    
    def search(
            self, query: np.ndarray, k: int=5, ef_search: int=50
        ) -> list[tuple[int, np.float64]]:
        """
        åœ¨HNSWä¸­æœç´¢æœ€è¿‘é‚»
        
        å‚æ•°:
        - query: æŸ¥è¯¢å‘é‡
        - k: è¿”å›çš„æœ€è¿‘é‚»æ•°é‡
        - ef_search: æœç´¢æ—¶çš„å€™é€‰é›†å¤§å°ï¼ˆè¶Šå¤§ç²¾åº¦è¶Šé«˜ä½†é€Ÿåº¦è¶Šæ…¢ï¼‰
        
        è¿”å›:
        - åŒ…å«(èŠ‚ç‚¹ID, è·ç¦»)çš„åˆ—è¡¨ï¼ŒæŒ‰è·ç¦»å‡åºæ’åˆ—
        """
        if self.entry_point is None:
            return []
        
        current_point = self.entry_point
        current_level = self.entry_level
        
        # ä»é¡¶å±‚å¼€å§‹æœç´¢
        for l in range(current_level, 0, -1):
            results = self._search_layer(query, current_point, 1, l)
            if results:
                current_point = results[0][1]  # æ›´æ–°ä¸ºæ¯å±‚çš„å…¥å£ç‚¹
        
        # åœ¨æœ€åº•å±‚è¿›è¡Œç²¾ç»†æœç´¢
        results = self._search_layer(query, current_point, ef_search, 0)
        
        # è¿”å›å‰kä¸ªç»“æœ
        return [(idx, dist) for dist, idx in results[:k]]

if __name__ == "__main__":
    # --- 1. æ•°æ®ç”Ÿæˆ ---

    def generate_sample_data(n_samples: int=200, dim: int=2):
        """ç”Ÿæˆç¤ºä¾‹æ•°æ®ï¼šå››ä¸ªåˆ†ç¦»çš„é«˜æ–¯åˆ†å¸ƒç°‡"""
        # åˆ›å»ºå››ä¸ªç°‡
        cluster1 = np.random.normal(loc=[2, 2], scale=0.3, size=(n_samples//4, dim))
        cluster2 = np.random.normal(loc=[8, 3], scale=0.4, size=(n_samples//4, dim))  
        cluster3 = np.random.normal(loc=[5, 8], scale=0.35, size=(n_samples//4, dim))
        cluster4 = np.random.normal(loc=[3, 6], scale=0.4, size=(n_samples - 3*(n_samples//4), dim))
        
        data = np.vstack([cluster1, cluster2, cluster3, cluster4])
        return data

    # --- 3. æ€§èƒ½æ¼”ç¤º ---

    def demonstrate_hnsw_performance():
        """æ¼”ç¤ºHNSWæ€§èƒ½å¯¹æ¯”"""
        import time
        print("=" * 60)
        print("HNSWç®—æ³•æ€§èƒ½æ¼”ç¤º")
        print("=" * 60)
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        data = generate_sample_data(500, 2)
        print(f"ç”Ÿæˆ{len(data)}ä¸ªäºŒç»´æ•°æ®ç‚¹")
        
        # åˆ›å»ºHNSWç´¢å¼•
        hnsw = SimpleHNSW(max_elements=1000, M=9, ef_construction=50, max_layers=5)
        
        # æ‰¹é‡æ·»åŠ æ•°æ®
        print("æ„å»ºHNSWç´¢å¼•...")
        start_time = time.time()
        for i, point in enumerate(data):
            hnsw.add_point(point)
            if (i + 1) % 100 == 0:
                print(f"å·²æ·»åŠ {i + 1}ä¸ªç‚¹")
        
        construction_time = time.time() - start_time
        print(f"HNSWç´¢å¼•æ„å»ºå®Œæˆï¼Œè€—æ—¶: {construction_time:.4f}ç§’")
        
        # é€‰æ‹©æŸ¥è¯¢ç‚¹
        query_point = np.array([5.0, 5.0])
        print(f"\næŸ¥è¯¢ç‚¹: {query_point}")
        
        # ä½¿ç”¨HNSWæœç´¢
        start_time = time.time()
        # hnsw_results, search_path = hnsw.search_with_path(query_point, k=5, ef_search=30)
        hnsw_results = hnsw.search(query_point, k=5, ef_search=30)
        hnsw_time = time.time() - start_time
        
        # æš´åŠ›æœç´¢ä½œä¸ºåŸºå‡†
        start_time = time.time()
        distances = euclidean_distances(query_point.reshape(1, -1), data)[0]
        bf_indices = np.argsort(distances)[:5]
        bf_distances = distances[bf_indices]
        bf_time = time.time() - start_time
        
        # æ˜¾ç¤ºç»“æœå¯¹æ¯”
        print(f"\næœç´¢ç»“æœå¯¹æ¯”:")
        print(f"HNSWæœç´¢ - æ‰¾åˆ°{len(hnsw_results)}ä¸ªæœ€è¿‘é‚», è€—æ—¶: {hnsw_time:.6f}ç§’")
        print(f"æš´åŠ›æœç´¢ - æ‰¾åˆ°{len(bf_indices)}ä¸ªæœ€è¿‘é‚», è€—æ—¶: {bf_time:.6f}ç§’")
        
        print(f"\né€Ÿåº¦æå‡: {bf_time/hnsw_time:.2f}å€")
        
        print(f"\nHNSWç»“æœç´¢å¼•: {[idx for idx, _ in hnsw_results]}")
        print(f"HNSWç»“æœè·ç¦»: {[dist for _, dist in hnsw_results]}")
        print(f"æš´åŠ›æœç´¢ç»“æœç´¢å¼•: {bf_indices}")
        print(f"æš´åŠ›æœç´¢ç»“æœè·ç¦»: {bf_distances}")
        
        # æ£€æŸ¥å¬å›ç‡
        hnsw_indices_set = set(idx for idx, _ in hnsw_results)
        bf_indices_set = set(bf_indices)
        intersection = hnsw_indices_set & bf_indices_set
        recall = len(intersection) / len(bf_indices_set)
        print(f"å¬å›ç‡: {recall:.2%} ({len(intersection)}/{len(bf_indices_set)})")
        
        return hnsw, data, query_point, hnsw_results, bf_indices, None

    # 1. è¿è¡Œæ ‡å‡†æ¼”ç¤º
    np.random.seed(42)
    hnsw, data, query, hnsw_results, bf_results, search_path = demonstrate_hnsw_performance()

```

> åœ¨ `np.random.seed(41)` ä¸‹è¦è®© `M=34`åˆšå¥½100%ï¼Œå°äº34éƒ½æ˜¯0ã€‚è€Œåœ¨`np.random.seed(42)` ä¸‹ `M`å¤§äº8å³å¯å®ç°100%ã€‚æ°´å¹³ä¹‹å·®ï¼Œä»¤äººæ±—é¢œï¼ï¼ˆYauè¯­ï¼‰å¥½å¤šåœ°æ–¹éƒ½ç”¨42ï¼Œ42çœŸçš„æ˜¯ä¸€ä¸ªå¹¸è¿ç§å­å—ï¼Ÿ

> åœ¨è¿™ç§éšæ—¶è¦æ±‚æ•°ç»„æœ‰åºçš„åœºæ™¯ä¸‹ï¼Œå¯ä»¥ä½¿ç”¨å †æ’åºæ¥ä¼˜åŒ–ã€‚ï¼ˆå›æƒ³èµ·åšç®—æ³•é¢˜çš„æ—¶å…‰ï¼‰

```python
============================================================
HNSWç®—æ³•æ€§èƒ½æ¼”ç¤º
============================================================
ç”Ÿæˆ500ä¸ªäºŒç»´æ•°æ®ç‚¹
æ„å»ºHNSWç´¢å¼•...
å·²æ·»åŠ 100ä¸ªç‚¹
å·²æ·»åŠ 200ä¸ªç‚¹
å·²æ·»åŠ 300ä¸ªç‚¹
å·²æ·»åŠ 400ä¸ªç‚¹
å·²æ·»åŠ 500ä¸ªç‚¹
HNSWç´¢å¼•æ„å»ºå®Œæˆï¼Œè€—æ—¶: 0.5738ç§’

æŸ¥è¯¢ç‚¹: [5. 5.]

æœç´¢ç»“æœå¯¹æ¯”:
HNSWæœç´¢ - æ‰¾åˆ°5ä¸ªæœ€è¿‘é‚», è€—æ—¶: 0.000388ç§’
æš´åŠ›æœç´¢ - æ‰¾åˆ°5ä¸ªæœ€è¿‘é‚», è€—æ—¶: 0.000408ç§’

é€Ÿåº¦æå‡: 1.05å€

HNSWç»“æœç´¢å¼•: [440, 381, 411, 472, 418]
HNSWç»“æœè·ç¦»: [np.float64(1.2645024960453435), np.float64(1.3700870317527636), np.float64(1.3777320706338358), np.float64(1.3849682052776706), np.float64(1.5048714197321411)]
æš´åŠ›æœç´¢ç»“æœç´¢å¼•: [440 381 411 472 418]
æš´åŠ›æœç´¢ç»“æœè·ç¦»: [1.2645025  1.37008703 1.37773207 1.38496821 1.50487142]
å¬å›ç‡: 100.00% (5/5)
```

ä½†æ˜¯å½“æˆ‘æ”¹ç”¨æ ‡å‡†åº“çš„ `heapq` åï¼Œé€Ÿåº¦åè€Œå¤§å¹…é™ä½ï¼š

```python
    def _search_layer(self, query, entry_point, ef, layer):
        """
        åœ¨æŒ‡å®šå±‚æœç´¢æœ€è¿‘é‚»
        
        å‚æ•°:
        - query: æŸ¥è¯¢å‘é‡
        - entry_point: æœç´¢èµ·å§‹ç‚¹
        - ef: æœç´¢èŒƒå›´ï¼ˆè¿”å›çš„å€™é€‰ç‚¹æ•°é‡ï¼‰
        - layer: æœç´¢çš„å±‚çº§
        """
        if entry_point is None or entry_point not in self.layers[layer]:
            return []
            
        visited = set([entry_point])
        # å€™é€‰é›†ï¼šå­˜å‚¨(è·ç¦», èŠ‚ç‚¹ID)å…ƒç»„ï¼Œä»å…¥å£ç‚¹å¼€å§‹
        candidates = []
        heapq.heappush(candidates, (self._euclidean_distance(query, self.data_points[entry_point]), entry_point))
        # ä½¿ç”¨å †æ¥ç»´æŠ¤å€™é€‰é›†ï¼ˆè¿™é‡Œç®€åŒ–ä¸ºåˆ—è¡¨æ’åºï¼‰
        results = []
        
        while candidates and len(results) < ef:
            # è·å–è·ç¦»æœ€è¿‘çš„å€™é€‰ç‚¹
            current_dist, current_point = heapq.heappop(candidates)
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥å°†å½“å‰ç‚¹åŠ å…¥ç»“æœ
            if not results or current_dist < results[-1][0]:
                heapq.heappush(results, (current_dist, current_point))
            
            # æ¢ç´¢å½“å‰ç‚¹çš„æ‰€æœ‰é‚»å±…èŠ‚ç‚¹
            for neighbor in self.layers[layer][current_point]:
                if neighbor not in visited:
                    visited.add(neighbor)
                    dist = self._euclidean_distance(query, self.data_points[neighbor])
                    heapq.heappush(candidates, (dist, neighbor))

        return heapq.nsmallest(ef, results, key=lambda x: x[0])
    
```

æœ‰äººçŸ¥é“æ˜¯æ€ä¹ˆå›äº‹å—ï¼Ÿæˆ‘è®°å¾—æˆ‘åšç®—æ³•é¢˜çš„æ—¶å€™è¿™ä¸ªheapqæ•ˆæœä¹Ÿä¸ä½³ï¼Œåˆ—è¡¨å†…ç½®çš„ `sort` æ–¹æ³•å·²ç»ä¼˜åŒ–å®Œäº†â€¦â€¦

```python
============================================================
HNSWç®—æ³•æ€§èƒ½æ¼”ç¤º
============================================================
ç”Ÿæˆ500ä¸ªäºŒç»´æ•°æ®ç‚¹
æ„å»ºHNSWç´¢å¼•...
å·²æ·»åŠ 100ä¸ªç‚¹
å·²æ·»åŠ 200ä¸ªç‚¹
å·²æ·»åŠ 300ä¸ªç‚¹
å·²æ·»åŠ 400ä¸ªç‚¹
å·²æ·»åŠ 500ä¸ªç‚¹
HNSWç´¢å¼•æ„å»ºå®Œæˆï¼Œè€—æ—¶: 0.6132ç§’

æŸ¥è¯¢ç‚¹: [5. 5.]

æœç´¢ç»“æœå¯¹æ¯”:
HNSWæœç´¢ - æ‰¾åˆ°5ä¸ªæœ€è¿‘é‚», è€—æ—¶: 0.001595ç§’
æš´åŠ›æœç´¢ - æ‰¾åˆ°5ä¸ªæœ€è¿‘é‚», è€—æ—¶: 0.000447ç§’

é€Ÿåº¦æå‡: 0.28å€

HNSWç»“æœç´¢å¼•: [440, 381, 411, 472, 418]
HNSWç»“æœè·ç¦»: [np.float64(1.2645024960453435), np.float64(1.3700870317527636), np.float64(1.3777320706338358), np.float64(1.3849682052776706), np.float64(1.5048714197321411)]
æš´åŠ›æœç´¢ç»“æœç´¢å¼•: [440 381 411 472 418]
æš´åŠ›æœç´¢ç»“æœè·ç¦»: [1.2645025  1.37008703 1.37773207 1.38496821 1.50487142]
å¬å›ç‡: 100.00% (5/5)
```

> åŸå› æ¦‚æ‹¬ï¼ˆç®€çŸ­ï¼‰ï¼š
>
> - heapq çš„ push/pop æ˜¯é€æ¬¡æ“ä½œï¼Œæ¯æ¬¡éƒ½æ˜¯ O(log n) çš„å¼€é”€ï¼›è€Œ list.sort æ˜¯ä¸€æ¬¡æ€§åœ¨ C å±‚æ‰§è¡Œçš„ timsortï¼Œå¤„ç†å¤§é‡å…ƒç´ æ—¶é€šå¸¸æ¯”åœ¨ Python å¾ªç¯é‡Œåå¤ç»´æŠ¤å †æ›´å¿«ã€‚
> - ä½ ç°åœ¨åœ¨å¾ªç¯é‡Œé¢‘ç¹å¯¹ results åš push/heap æ“ä½œï¼ˆç”šè‡³å¾ªç¯å†…æ’åºï¼‰ï¼Œå¯¼è‡´å¤§é‡ Python å±‚çš„å¼€é”€ï¼Œå› è€Œæ¯”ä¸€æ¬¡æ€§æ”¶é›†ç„¶å sort è¦æ…¢ã€‚
> - heapq åˆé€‚çš„åœºæ™¯æ˜¯éœ€è¦æµå¼ã€é€æ¬¡å–æœ€å°/æœ€å¤§å€¼æˆ–ç»´æŠ¤å›ºå®šå¤§å° top-kï¼›è‹¥èƒ½å…ˆæ”¶é›†å†æ’åºï¼Œlist.sort é€šå¸¸æ›´å¿«ã€‚

## LSHç®—æ³•

LSH ç®—æ³•åŸç†ï¼ˆLocality-Sensitive Hashinï¼‰æ˜¯è¿™äº›ç®—æ³•é‡Œé¢æœ€ç®€å•çš„ã€‚æˆ‘ä»¬é«˜ä¸­å­¦è¿‡è§£æå‡ ä½•ï¼Œéƒ½çŸ¥é“å¯¹äºç›´çº¿
$$l:Ax+By+C=0$$

ä¸€ä¸ªç‚¹$(x_{0},y_{0})$å¸¦è¿›å»$Ax_{0}+By_{0}+C$çš„ç¬¦å·å†³å®šäº†è¿™ä¸ªç‚¹æ˜¯åœ¨ç›´çº¿çš„â€œä¸Šæ–¹â€è¿˜æ˜¯â€œä¸‹æ–¹â€ã€‚æ€»ä¹‹ç¬¦å·ç›¸åŒçš„ç‚¹åœ¨åŒä¸€ä¾§ã€‚æ¨å¹¿åˆ°é«˜ç»´ç©ºé—´ä¹Ÿå¦‚æ­¤ã€‚å› æ­¤è¿™å°±è¯ç”Ÿäº†ä¸€ç§èšç±»ç®—æ³•ï¼Œå³ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦å¾ˆé«˜ï¼Œé‚£ä¹ˆå¤§æ¦‚ç‡ä¼šè¢«è¶…å¹³é¢åˆ’åˆ†åˆ°åŒä¸€ä¾§ã€‚ä¸ºäº†æå‡å‡†ç¡®æ€§ï¼Œè¿™æ ·çš„å¹³é¢è¶Šå¤šè¶Šå¯é ã€‚

### ç¬¬ä¸€æ­¥ï¼šæ„å»ºéšæœºè¶…å¹³é¢

- åœ¨$d$ç»´åº¦ç©ºé—´ç”Ÿæˆ `hash_size` ä¸ªå‘é‡ï¼š

$$
\begin{pmatrix}
\mathbf{r_{1}} \\ \mathbf{r_{2}}
 \\ \dots
 \\ \mathbf{r_{k}}
\end{pmatrix}
$$

- æ¯ä¸ªå‘é‡çš„åˆ†é‡æœä»æ ‡å‡†æ­£æ€åˆ†å¸ƒ

    $N(0,1)$
- æ¯ä¸ªè¶…å¹³é¢ä»£è¡¨ä¸€ä¸ªéšæœºæ–¹å‘ã€‚

> æ—¢ç„¶éšæœºæ–¹å‘ï¼Œä¸ºä»€ä¹ˆä¸æ˜¯$[-1,1]$ä¹‹é—´éšæœºæ•°å°±è¡Œäº†å‘¢ï¼Ÿä¸ºä»€ä¹ˆè¿˜è¦ç¬¦åˆæ­£æ€åˆ†å¸ƒï¼Ÿ

### ç¬¬äºŒæ­¥ï¼šè®¡ç®—å“ˆå¸Œç­¾å

å¯¹äºå‘é‡$\mathbf{x}$ï¼Œé€šè¿‡è®¡ç®—

$$
h_i(\mathbf{x}) = \begin{cases}
 1, & \text{ if } \mathbf{r_{i}} \cdot \mathbf{x} \ge 0 \\
 0, & \text{ otherwise }
\end{cases}
$$

å°†æ¯ä¸ªè¶…å¹³é¢çš„ç‚¹ç§¯ç»“æœæ‹¼æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼š
$\overline{h_{1}(\mathbf{x})h_{2}(\mathbf{x})\dots h_{k}(\mathbf{x})}$

è¿™å°±æ˜¯è¯¥å‘é‡çš„Â **å“ˆå¸Œç­¾å**ã€‚ä¸¤ä¸ªè§’åº¦ç›¸ä¼¼çš„å‘é‡ï¼Œæ›´å¯èƒ½è¢«è¶…å¹³é¢åˆ’åˆ†åˆ°ç›¸åŒä¾§ï¼Œå› æ­¤å“ˆå¸Œç­¾åç›¸ä¼¼ã€‚

$$
\begin{bmatrix}
 h_{1}(\mathbf{x}) & h_{2}(\mathbf{x}) & \dots & h_{k}(\mathbf{x})
\end{bmatrix}
=
\mathbf{x} \cdot
\begin{bmatrix}
\mathbf{r_{1}} \\ \mathbf{r_{2}}
 \\ \dots
 \\ \mathbf{r_{k}}
\end{bmatrix}^{T}
$$

### ç¬¬ä¸‰æ­¥ï¼šæ„å»ºå¤šä¸ªå“ˆå¸Œè¡¨ï¼ˆMulti-Table Strategyï¼‰

- ä¸ºäº†å‡å°‘ç¢°æ’é”™è¯¯ï¼ˆä¸åŒå‘é‡å“ˆå¸Œç›¸åŒï¼‰ï¼Œæˆ‘ä»¬ä½¿ç”¨å¤šç»„ç‹¬ç«‹å“ˆå¸Œå‡½æ•°ã€‚
- å‡è®¾æœ‰ï¼š
  - æ¯ç»„ k ä¸ªå“ˆå¸Œå‡½æ•°ç»„æˆä¸€ä¸ªÂ **å“ˆå¸Œè¡¨ï¼ˆhash tableï¼‰**
  - å…± L ä¸ªè¿™æ ·çš„è¡¨ã€‚

æ¯ä¸ªæ ·æœ¬è¢«æ’å…¥åˆ° L ä¸ªä¸åŒè¡¨ä¸­ï¼Œä»è€Œæå‡å¬å›ç‡ã€‚

### ç¬¬ 4 æ­¥ï¼šæŸ¥è¯¢ï¼ˆQueryï¼‰

ç»™å®šæŸ¥è¯¢å‘é‡ ( q )ï¼š

1. è®¡ç®—å…¶åœ¨æ¯ä¸ªå“ˆå¸Œè¡¨ä¸­çš„ç­¾åï¼›
2. æ‰¾å‡ºæ‰€æœ‰æ¡¶ä¸­ä¸å…¶å“ˆå¸Œç›¸åŒçš„å€™é€‰æ ·æœ¬ï¼›
3. å¯¹å€™é€‰æ ·æœ¬è®¡ç®—çœŸå®ç›¸ä¼¼åº¦ï¼ˆå¦‚ä½™å¼¦æˆ–æ¬§å¼è·ç¦»ï¼‰ï¼›
4. è¿”å›æœ€ç›¸ä¼¼çš„ Top-Kã€‚

### å°ç»“

è¯•éªŒè¡¨æ˜LSHçš„å¬å›æ•ˆæœä¸æ˜¯å¾ˆå¥½ã€‚

- hash_sizeï¼ˆå“ˆå¸Œå¤§å°ï¼‰ï¼š

> ä½œç”¨ï¼šå†³å®šæ¯ä¸ªå“ˆå¸Œè¡¨çš„å“ˆå¸Œç é•¿åº¦ï¼ˆä½æ•°ï¼‰ å½±å“ï¼šå€¼è¶Šå¤§ï¼Œå“ˆå¸Œæ¡¶åˆ’åˆ†è¶Šç²¾ç»†ï¼Œç›¸ä¼¼åº¦åˆ¤æ–­è¶Šå‡†ç¡®ï¼Œä½†æ¯ä¸ªæ¡¶å†…çš„å‘é‡å¯èƒ½è¶Šå°‘

- num_tablesï¼ˆå“ˆå¸Œè¡¨æ•°é‡ï¼‰ï¼š

> ä½œç”¨ï¼šæ§åˆ¶ä½¿ç”¨çš„ç‹¬ç«‹å“ˆå¸Œè¡¨æ•°é‡ å½±å“ï¼šå€¼è¶Šå¤§ï¼Œæ‰¾åˆ°çœŸæ­£è¿‘é‚»çš„æ¦‚ç‡è¶Šé«˜ï¼Œä½†å†…å­˜æ¶ˆè€—ä¹Ÿä¼šå¢åŠ 
