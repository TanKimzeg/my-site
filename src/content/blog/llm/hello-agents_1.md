---
title: 第一部分 智能体与语言模型基础 | Hello-Agents
description:  Hello-Agents第一部分 智能体与语言模型基础.包含三个章节:初识智能体、智能体发展史、大语言模型基础.
pubDate: 2025 11 07 
categories: 
  - tech
tags:
  - llm
  - agent
---

在我上高中的时候,ChatGPT对话火爆,LLM进入了我的视野.在我军训和各种无意义的浪费掉的时间里,各种AI应用逐步落地,比如越来越好用的VSCode Copilot.从在网页端找镜像的ChatGPT3.5,把代码反复复制粘贴,到现在Vibe Coding越来越普遍,这都得益于AI应用的落地.在这些时光里,我自学了许多计科知识,兴趣也越来越明确:相比于想方设法灌水掺数据集带来0.01%提升的新"SOTA",我觉得做出有意思的工程项目更有意义.

学习完LLM架构,RAG系统之后,我更进一步开始了解Agent.我经常使用VSCode中的Copilot,却还未完全了解过.在学习RAG的时候,我发现了DataWhale发布了很多开源教程,Hello-Agents教程也来源于Datawhale.我非常感激这些免费高质量教程,给我的学习带来很大便利!

[Hello-Agents在线教程](https://datawhalechina.github.io/hello-agents/#)

我向来反感急功近利的风格.大一的时候有几个赚到信息差的学长想拉拢我给他打工当免费劳动力,上来就让我把Transformer架构讲给他听.即使他听完赞不绝口,称我大有可为,但我至今依然十分厌恶那种高压氛围,因为我知道我根本就不理解.反而是在我学完编译原理之后,我恍然大悟,理解了早期NLP研究者面临了什么问题,因为我跟他们想到一块去了.随后迅速重新入门了LLM,在实习中厂听说了RAG和Agent,又马上做出了RAG检索系统,现在正朝着Agent领域学习,都没有遇到理解不了的问题.颇有"一日看尽长安花"的势头.

悟已往之不鉴,知来者之可追!我是幸运的,在鱼目混珠的简中互联网能找到正确的学习资料和方向.我也是天才的,在没有人指引的情况下能无师自通这么多计科专业知识.

话说回来,我非常认可教程的内容设计:只有了解前人研究中出现的问题,才能跟现在基于LLM架构的各种AI应用的产生背景一脉相承.教程的第一部分:智能体与语言模型基础,都介绍了传统模型.

其实关于LLM是否真的"智能",很多大牛都持异议.我也认为LLM只是大量参数对现实世界语言的拟合,本质上是概率模型.但目前没有更好的方案了.现在的智能体,可以理解为暂时由LLM充当大脑,我们给他装上手脚.LLM不是智能体的终点,希望学界不要因此荒废了对真正智能的开发.

具体来说要求智能体输出结构化的文本,解析输出文本去执行函数.因此,范式,工具和提示词决定了生成质量.

原理不过如此,但 "Talk is cheap, show me the code."

## 第一章 初识智能体

这篇笔记写于我看完了前六章.回过头来,我认为除了1.3的体验智能体之外,另一个值得注意的部分是1.4的智能体应用协作模式.在教程后面的部分,设计的智能体涵盖了这些模式.

1. 单智能体自主循环.其核心是一个通用智能体通过“思考-规划-执行-反思”的闭环，不断进行自我提示和迭代，以完成一个开放式的高层级目标。
2. 多智能体协作.这是当前最主流的探索方向，旨在通过模拟人类团队的协作模式来解决复杂问题。它又可细分为不同模式： **角色扮演式对话**：如 **CAMEL** 框架，通过为两个智能体（例如，“程序员”和“产品经理”）设定明确的角色和沟通协议，让它们在一个结构化的对话中协同完成任务。 **组织化工作流**：如 **MetaGPT** 和 **CrewAI**，它们模拟一个分工明确的“虚拟团队”（如软件公司或咨询小组）。每个智能体都有预设的职责和工作流程（SOP），通过层级化或顺序化的方式协作，产出高质量的复杂成果（如完整的代码库或研究报告）。**AutoGen** 和 **AgentScope** 则提供了更灵活的对话模式，允许开发者自定义智能体间的复杂交互网络。
3. **高级控制流架构**：诸如 **LangGraph** 等框架，则更侧重于为智能体提供更强大的底层工程基础。它将智能体的执行过程建模为状态图（State Graph），从而能更灵活、更可靠地实现循环、分支、回溯以及人工介入等复杂流程。

因为后面第二部分讲的低代码平台涉及到工作流的概念,这里也对工作流和Agent的差异进行了对比.
**Workflow 是让 AI 按部就班地执行指令，而 Agent 则是赋予 AI 自由度去自主达成目标。**

## 第二章 智能体发展史

了解一下符号主义的尝试也挺有意思的,因为我在学完编译原理之后首先想到的NLP灵感就近似历史上的符号主义尝试.古怪的架构,复杂的机制,晦涩的名词,即使暂时失败了,但他们在漫长尝试中表现的毅力也是浪漫的.

## 第三章 大语言模型基础

学完LLM from Scratch,这一章当然不成问题.这一章对NLP的阐述非常连贯,不是一上来就搬出Transformer.这是对的,只有了解其他模型的思想和难题,才能理解Transformer.Transformer也不是凭空产生的,吸取了很多正确思想(比如词嵌入,上下文窗口).只有这些铺垫才促成了Tansformer的诞生.

语言模型是自然语言处理的核心,其根本任务是计算一个词序列(即一个句子)出现的概率.一个好的语言模型能够高所我们什么样的句子是通顺的,自然的.在多智能体系统中,语言模型是智能体能理解人类指令,生成回应的基础.本节将回顾从经典的统计方法到现代深度学习模型的演进历程,为理解后续的Transformer架构打下坚实基础.

N-gram模型基于统计方法预测下一个词汇,虽然简单有效,但有两个致命缺陷:

1. 数据稀疏性: 如果一个词从未在语料库中出现,其估计概率就为0
2. 泛化能力差: 模型无法理解词与词之间的语义相似性

N-gram模型的根本缺陷在于她将词视为孤立离散的符号.为了克服这个问题,研究者提出了一种思想: 用连续的向量来表示词.

前馈神经网络语言模型其核心思想可分为两步:

1. 构建一个语义空间
2. 学习上下文到下一个词的映射

神经网络语言模型虽然引入词嵌入解决了泛化问题,但它跟N-gram模型一样,上下文窗口是固定大小的.循环神经网络引入了一个隐藏状态向量,将其理解为一个网络的短期记忆.在处理序列的第一步,网络都会读取当前的输入词并结合上一个时间步的记忆传递给下一刻.

然而,标准的RNN在实践中存在一个严重的问题: 长期依赖问题.当序列很长时,梯度在从后向前传播的过程中会经过多次连乘,这会导致梯度消失或梯度爆炸.

长短时记忆网络被设计出来.引入细胞状态和一套精密设计的门控机制,允许消息在时间步之间更流畅传递.

Transformer架构完全抛弃了循环结构,转而完全依赖一种名为注意力的机制来捕捉序列内的依赖关系.从而实现了真正意义上的并行计算.
它在宏观上遵循了一个经典的编码器-解码器架构.

1. 编码器: 任务是理解输入的整个句子
2. 解码器: 任务是生成目标的句子

自注意力机制为每个输入的词元向量引入了三个可学习的角色:

1. 查询: 代表当前词元正在主动地查询其它词元以获取信息
2. 键: 代表句子中可悲查询地词元标签或索引
3. 值: 代表词元本身所携带的内容或信息

这三个向量都是由原始的词嵌入向量乘以三个不同的可学习的权重矩阵得到的.

$$Attention(Q,K,V) = softmax(\frac{QK^T}{\sqrt{ d_{k} } })V$$

Transformer的设计哲学时先理解,在生成.GPT做了大胆简化,它完全抛弃了编码器,只保留解码器.这就是Decoder-Only架构的由来.工作模式被称为自回归: 不断回顾已经写下的内容.

### 提示词工程

如果我们把大语言模型比作一个能力极强的“大脑”，那么**提示 (Prompt)** 就是我们与这个“大脑”沟通的语言。提示工程，就是研究如何设计出精准的提示，从而引导模型产生我们期望输出的回复。

四个常用的提示词框架:

- ICIO框架主要关注任务的明确性和输出的格式.它特别适用于那些需要明确指导AI完成特定任务的场景.
- CRISPE框架专门用于设计和优化提示的框架.它更注重AI的角色和背景.特别适用于那些需要AI 扮演或在特定任务下完成任务的场景.通过CRISPE框架,用户可以更精确地指导AI的行为,从而获得更加个性化和满足特定需求地互动体验.
- BROKE框架: 结构化地AI交互方法.它引入了OKR地思想,旨在提升用户与AI之间地沟通地效率和精确度.帮助用户清晰传达指令并获得满足太空需求地输出.
- RASCEF框架用于构建AI角色扮演和任务执行系统化方法.它通过明确定义这些要素,帮助用户更精确地指导AI地行为,从而获得更加个性化和满足特定需求地结果.这个框架特别适合于需要AI扮演特定角色并完成复杂任务地场景.
