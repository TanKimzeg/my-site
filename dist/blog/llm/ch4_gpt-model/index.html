<!DOCTYPE html><html class=bg-base-300 data-theme=winter data-theme-type=light lang=en><head><meta content=true name=astro-view-transitions-enabled><meta content=animate name=astro-view-transitions-fallback><script type=module src=/_astro/ClientRouter.astro_astro_type_script_index_0_lang.waUwC-PJ.js></script><script src=/_astro/vanilla.ChgcMPTJ.js data-astro-rerun></script><script type=module src=/_astro/PointerOnNavigation.astro_astro_type_script_index_0_lang.Dwfd1XXs.js></script><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><link href=/favicon.svg rel=icon type=image><meta content="Astro v5.13.7" name=generator><meta content=从零构建大语言模型第4章:本章实现了Transformer模块,进一步实现了GPT模型 name=description><meta content="从零开始实现一个用于文本生成的GPT模型 | LLM" property=og:title><meta content=从零构建大语言模型第4章:本章实现了Transformer模块,进一步实现了GPT模型 property=og:description><meta content=https://tankimzeg.top/og/llm/ch4_gpt-model.png property=og:image><link href=https://tankimzeg.top/blog/llm/ch4_gpt-model/ rel=canonical><title>从零开始实现一个用于文本生成的GPT模型 | LLM - TanKimzeg</title><script>!function(){const e="winter",t="dracula";!function(){const a=localStorage.getItem("theme"),m=window.matchMedia("(prefers-color-scheme: dark)").matches;let c;a?c=a:(c=m?t:e,localStorage.setItem("theme",c)),document.documentElement.setAttribute("data-theme",c);const o=c===t?"dark":"light";document.documentElement.setAttribute("data-theme-type",o),window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",(a=>{if(!localStorage.getItem("theme")){const m=a.matches?t:e;document.documentElement.setAttribute("data-theme",m);const c=a.matches?"dark":"light";document.documentElement.setAttribute("data-theme-type",c),localStorage.setItem("theme",m)}}))}()}()</script><link href=/_astro/about.BB1pbI9A.css rel=stylesheet><style>.modal-backdrop[data-astro-cid-zux26muy] button[data-astro-cid-zux26muy]{cursor:default;width:100%;height:100%;opacity:0}.card-body .btn-category,.card-body .btn-tag{text-decoration:none}</style></head><body class="flex flex-col min-h-screen" data-pagefind-body=true><nav class="w-full bg-base-100 shadow-lg ease-in-out transform transition-transform delay-300 duration-500 fixed md:hidden navbar px-2 text-center z-50" id=navbar><div class=navbar-start><label class="btn btn-circle bg-base-100 btn-md swap swap-rotate"><span class=sr-only>Toggle menu</span> <input type=checkbox id=menu-toggle> <svg height=1em width=1em data-icon=lucide:menu class="h-5 w-5 swap-off"><symbol id=ai:lucide:menu viewBox="0 0 24 24"><path d="M4 5h16M4 12h16M4 19h16" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 /></symbol><use href=#ai:lucide:menu></use></svg> <svg height=1em width=1em data-icon=lucide:x class="h-5 w-5 swap-on"><symbol id=ai:lucide:x viewBox="0 0 24 24"><path d="M18 6L6 18M6 6l12 12" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 /></symbol><use href=#ai:lucide:x></use></svg></label></div><div class=navbar-center><a href=/ class="btn btn-ghost hover:scale-105 transition-transform duration-300 text-xl">TanKimzeg&#39;s Blog</a></div><div class=navbar-end><button title="Theme Toggle" aria-label="Toggle theme" class="btn btn-circle hover:scale-110 bg-base-100 btn-md shadow-sm md:border-base-content/20 navbar-theme" data-astro-cid-mjqc4hpp data-theme-toggle id=theme-toggle-mv6379gb3><svg height=1em width=1em data-icon=lucide:sun class="h-5 w-5 theme-toggle-icon sun-icon" data-astro-cid-mjqc4hpp=true><symbol id=ai:lucide:sun viewBox="0 0 24 24"><g fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2><circle cx=12 cy=12 r=4 /><path d="M12 2v2m0 16v2M4.93 4.93l1.41 1.41m11.32 11.32l1.41 1.41M2 12h2m16 0h2M6.34 17.66l-1.41 1.41M19.07 4.93l-1.41 1.41"/></g></symbol><use href=#ai:lucide:sun></use></svg> <svg height=1em width=1em data-icon=lucide:moon class="h-5 w-5 theme-toggle-icon hidden moon-icon" data-astro-cid-mjqc4hpp=true><symbol id=ai:lucide:moon viewBox="0 0 24 24"><path d="M20.985 12.486a9 9 0 1 1-9.473-9.472c.405-.022.617.46.402.803a6 6 0 0 0 8.268 8.268c.344-.215.825-.004.803.401" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 /></symbol><use href=#ai:lucide:moon></use></svg></button><script>!function(){const e="winter",t="dracula",n=(e,t)=>{if(!e)return;const n=e.querySelector(".sun-icon"),d=e.querySelector(".moon-icon");n&&d&&(t?(n.classList.remove("hidden"),d.classList.add("hidden")):(n.classList.add("hidden"),d.classList.remove("hidden")))};document.addEventListener("astro:page-load",(()=>{const d=document.getElementById("theme-toggle-mv6379gb3");if(!d)return;const o=document.documentElement.getAttribute("data-theme");n(d,o===t),d.addEventListener("click",(()=>{const o=document.documentElement.getAttribute("data-theme")===e?t:e;d.classList.add("animate-spin-once"),document.documentElement.setAttribute("data-theme",o);const c=o===t?"dark":"light";document.documentElement.setAttribute("data-theme-type",c),localStorage.setItem("theme",o);document.querySelectorAll("[data-theme-toggle]").forEach((e=>{n(e,o===t)})),setTimeout((()=>{d.classList.remove("animate-spin-once")}),300)}))}))}()</script></div><div class="w-full bg-base-100 shadow-lg ease-in-out transform transition-transform -translate-x-full absolute duration-300 left-0 top-full" id=header-menu><ul class="w-full bg-transparent menu p-2"><li class="relative w-full group"><a href=/ class="flex items-center rounded-lg hover:bg-base-200 font-bold p-3 text-lg" target=_self><svg height=1em width=1em data-icon=material-symbols:home-outline-rounded class="h-5 w-5 mr-2"><symbol id=ai:material-symbols:home-outline-rounded viewBox="0 0 24 24"><path d="M6 19h3v-5q0-.425.288-.712T10 13h4q.425 0 .713.288T15 14v5h3v-9l-6-4.5L6 10zm-2 0v-9q0-.475.213-.9t.587-.7l6-4.5q.525-.4 1.2-.4t1.2.4l6 4.5q.375.275.588.7T20 10v9q0 .825-.588 1.413T18 21h-4q-.425 0-.712-.288T13 20v-5h-2v5q0 .425-.288.713T10 21H6q-.825 0-1.412-.587T4 19m8-6.75" fill=currentColor /></symbol><use href=#ai:material-symbols:home-outline-rounded></use></svg> <span>Home</span></a></li><li class="relative w-full group"><a href=/about class="flex items-center rounded-lg hover:bg-base-200 font-bold p-3 text-lg" target=_self><svg height=1em width=1em data-icon=material-symbols:info-outline-rounded class="h-5 w-5 mr-2"><symbol id=ai:material-symbols:info-outline-rounded viewBox="0 0 24 24"><path d="M12 17q.425 0 .713-.288T13 16v-4q0-.425-.288-.712T12 11t-.712.288T11 12v4q0 .425.288.713T12 17m0-8q.425 0 .713-.288T13 8t-.288-.712T12 7t-.712.288T11 8t.288.713T12 9m0 13q-2.075 0-3.9-.788t-3.175-2.137T2.788 15.9T2 12t.788-3.9t2.137-3.175T8.1 2.788T12 2t3.9.788t3.175 2.137T21.213 8.1T22 12t-.788 3.9t-2.137 3.175t-3.175 2.138T12 22m0-2q3.35 0 5.675-2.325T20 12t-2.325-5.675T12 4T6.325 6.325T4 12t2.325 5.675T12 20m0-8" fill=currentColor /></symbol><use href=#ai:material-symbols:info-outline-rounded></use></svg> <span>About</span></a></li><li class="relative w-full group"><details open><summary class="flex items-center rounded-lg hover:bg-base-200 font-bold p-3 text-lg"><svg height=1em width=1em data-icon=material-symbols:book-2-outline-rounded class="h-5 w-5 mr-2"><symbol id=ai:material-symbols:book-2-outline-rounded viewBox="0 0 24 24"><path d="M6 15.325q.35-.175.725-.25T7.5 15H8V4h-.5q-.625 0-1.062.438T6 5.5zM10 15h8V4h-8zm-4 .325V4zM7.5 22q-1.45 0-2.475-1.025T4 18.5v-13q0-1.45 1.025-2.475T7.5 2H18q.825 0 1.413.587T20 4v12.525q0 .2-.162.363t-.588.362q-.35.175-.55.5t-.2.75t.2.763t.55.487t.55.413t.2.562v.25q0 .425-.288.725T19 22zm0-2h9.325q-.15-.35-.237-.712T16.5 18.5q0-.4.075-.775t.25-.725H7.5q-.65 0-1.075.438T6 18.5q0 .65.425 1.075T7.5 20" fill=currentColor /></symbol><use href=#ai:material-symbols:book-2-outline-rounded></use></svg> <span>Blogs</span></summary><ul class=pl-4><li><a href=/blog class="flex items-center rounded-lg hover:bg-base-200 p-2" target=_self><svg height=1em width=1em data-icon=material-symbols:ink-pen-outline-rounded class="h-4 w-4 mr-2"><symbol id=ai:material-symbols:ink-pen-outline-rounded viewBox="0 0 24 24"><path d="m12.25 10.825l.925.925L18.6 6.325l-.925-.925zM5 19h.925l5.825-5.825l-.925-.925L5 18.075zm8.875-5.125l-3.75-3.75L14.3 5.95l-.725-.725L8.8 10q-.3.3-.7.3t-.7-.3t-.3-.712t.3-.713l4.75-4.75q.6-.6 1.413-.6t1.412.6l.725.725l1.25-1.25q.3-.3.713-.3t.712.3L20.7 5.625q.3.3.3.712t-.3.713zM4 21q-.425 0-.712-.288T3 20v-1.925q0-.4.15-.763t.425-.637l6.55-6.55l3.75 3.75l-6.55 6.55q-.275.275-.638.425t-.762.15z" fill=currentColor /></symbol><use href=#ai:material-symbols:ink-pen-outline-rounded></use></svg> <span>All blogs</span></a></li><li><a href=/blog/category/tech class="flex items-center rounded-lg hover:bg-base-200 p-2" target=_self><svg height=1em width=1em data-icon=material-symbols:deployed-code-outline class="h-4 w-4 mr-2"><symbol id=ai:material-symbols:deployed-code-outline viewBox="0 0 24 24"><path d="M11 19.425v-6.85L5 9.1v6.85zm2 0l6-3.475V9.1l-6 3.475zm-1-8.575l5.925-3.425L12 4L6.075 7.425zM4 17.7q-.475-.275-.737-.725t-.263-1v-7.95q0-.55.263-1T4 6.3l7-4.025Q11.475 2 12 2t1 .275L20 6.3q.475.275.738.725t.262 1v7.95q0 .55-.262 1T20 17.7l-7 4.025Q12.525 22 12 22t-1-.275zm8-5.7" fill=currentColor /></symbol><use href=#ai:material-symbols:deployed-code-outline></use></svg> <span>Tech Blogs</span></a></li><li><a href=/blog/category/life class="flex items-center rounded-lg hover:bg-base-200 p-2" target=_self><svg height=1em width=1em data-icon=material-symbols:earthquake-rounded class="h-4 w-4 mr-2"><symbol id=ai:material-symbols:earthquake-rounded viewBox="0 0 24 24"><path d="M9.025 22q-.35 0-.612-.187T8.05 21.3L5.5 13H3q-.425 0-.712-.288T2 12t.288-.712T3 11h3.25q.325 0 .588.188t.362.512l1.65 5.375L12.025 2.8q.075-.35.35-.575T13 2t.625.213t.35.562l2.175 9.4l1.4-4.475q.1-.325.362-.512T18.5 7t.575.175t.375.475L20.7 11h.3q.425 0 .713.288T22 12t-.288.713T21 13h-1q-.325 0-.575-.175t-.375-.475l-.475-1.275L16.95 16.3q-.1.325-.375.525T15.95 17t-.6-.238t-.325-.537L13 7.525l-3.025 13.7q-.075.35-.337.55T9.025 22" fill=currentColor /></symbol><use href=#ai:material-symbols:earthquake-rounded></use></svg> <span>Life Blogs</span></a></li></ul></details></li><li class="relative w-full group"><a href=/project class="flex items-center rounded-lg hover:bg-base-200 font-bold p-3 text-lg" target=_self><svg height=1em width=1em data-icon=material-symbols:code-blocks-outline class="h-5 w-5 mr-2"><symbol id=ai:material-symbols:code-blocks-outline viewBox="0 0 24 24"><path d="m9.6 15.6l1.4-1.425L8.825 12L11 9.825L9.6 8.4L6 12zm4.8 0L18 12l-3.6-3.6L13 9.825L15.175 12L13 14.175zM5 21q-.825 0-1.412-.587T3 19V5q0-.825.588-1.412T5 3h14q.825 0 1.413.588T21 5v14q0 .825-.587 1.413T19 21zm0-2h14V5H5zM5 5v14z" fill=currentColor /></symbol><use href=#ai:material-symbols:code-blocks-outline></use></svg> <span>Project</span></a></li><li class="relative w-full group"><a href=/friend class="flex items-center rounded-lg hover:bg-base-200 font-bold p-3 text-lg" target=_self><svg height=1em width=1em data-icon=material-symbols:supervisor-account-outline-rounded class="h-5 w-5 mr-2"><symbol id=ai:material-symbols:supervisor-account-outline-rounded viewBox="0 0 24 24"><path d="M17 15q-1.05 0-1.775-.725T14.5 12.5t.725-1.775T17 10t1.775.725t.725 1.775t-.725 1.775T17 15m-5 4v-.4q0-.6.313-1.112t.887-.738q.9-.375 1.863-.562T17 16t1.938.188t1.862.562q.575.225.888.738T22 18.6v.4q0 .425-.288.713T21 20h-8q-.425 0-.712-.288T12 19m-2-7q-1.65 0-2.825-1.175T6 8t1.175-2.825T10 4t2.825 1.175T14 8t-1.175 2.825T10 12m-8 5.2q0-.85.425-1.562T3.6 14.55q1.5-.75 3.113-1.15T10 13q.875 0 1.75.15t1.75.35l-.85.85l-.85.85q-.45-.125-.9-.162T10 15q-1.45 0-2.838.35t-2.662 1q-.25.125-.375.35T4 17.2v.8h6v.975q0 .325.125.588t.35.437H4q-.825 0-1.412-.587T2 18zm8-7.2q.825 0 1.413-.587T12 8t-.587-1.412T10 6t-1.412.588T8 8t.588 1.413T10 10" fill=currentColor /></symbol><use href=#ai:material-symbols:supervisor-account-outline-rounded></use></svg> <span>Friend</span></a></li></ul></div></nav><script type=module>document.addEventListener("astro:page-load",(()=>{let e=window.scrollY;const t=document.getElementById("navbar"),s=document.getElementById("header-menu"),a=document.getElementById("menu-toggle");if(!t||!s||!a)return;a.addEventListener("change",(()=>{a.checked?(s.classList.remove("-translate-x-full"),s.classList.add("translate-x-0")):(s.classList.add("-translate-x-full"),s.classList.remove("translate-x-0"))}));let l=!1;window.addEventListener("scroll",(()=>{l||(window.requestAnimationFrame((()=>{!t||!s||!a||(window.scrollY>e&&window.scrollY>50?(t.classList.add("-translate-y-full","duration-500"),t.classList.remove("translate-y-0"),a.checked&&(a.checked=!1,s.classList.add("-translate-x-full"),s.classList.remove("translate-x-0"))):window.scrollY<e&&(t.classList.remove("-translate-y-full"),t.classList.add("translate-y-0","duration-300")),e=window.scrollY),l=!1})),l=!0)})),document.addEventListener("click",(e=>{if(!t||!s||!a)return;const l=e.target;!t.contains(l)&&s.classList.contains("translate-x-0")&&(a.checked=!1,s.classList.add("-translate-x-full"),s.classList.remove("translate-x-0"))})),document.querySelectorAll("#header-menu a").forEach((e=>{e.addEventListener("click",(()=>{!s||!a||a.checked&&(a.checked=!1,s.classList.add("-translate-x-full"),s.classList.remove("translate-x-0"))}))}))}))</script><div class="w-full flex-grow max-w-6xl mx-auto"><div class="gap-4 grid lg:grid-cols-4 grid-cols-1 h-full md:grid-cols-5 p-4"><main class="flex flex-col gap-4 bg-transparent col-span-1 lg:col-span-3 md:col-span-4 md:mt-0 md:order-2 mt-16 order-1"><div class="flex flex-col gap-4 flex-grow"><div class="w-full bg-base-100 shadow-lg rounded-xl overflow-hidden"><div class="pt-6 px-6"><h1 class="text-xl font-bold lg:text-4xl sm:text-2xl">从零开始实现一个用于文本生成的GPT模型 | LLM</h1><p class="text-sm mt-2 text-base-content/80">从零构建大语言模型第4章:本章实现了Transformer模块,进一步实现了GPT模型</p></div><div class="sm:p-6 p-4"><div class="flex flex-col gap-y-2 mb-4 opacity-75 sm:flex-row sm:justify-between sm:text-sm text-xs"><div class="flex items-center flex-wrap gap-x-4 gap-y-2"><span class="flex items-center gap-1"><svg height=1em width=1em data-icon=lucide:calendar class="h-4 w-4 flex-shrink-0"><symbol id=ai:lucide:calendar viewBox="0 0 24 24"><g fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2><path d="M8 2v4m8-4v4"/><rect height=18 rx=2 width=18 x=3 y=4 /><path d="M3 10h18"/></g></symbol><use href=#ai:lucide:calendar></use></svg> <span class=truncate>Wed Sep 24 2025</span></span></div><div class="flex items-center gap-1 flex-wrap"><svg height=1em width=1em data-icon=lucide:book-open class="h-4 w-4 flex-shrink-0"><symbol id=ai:lucide:book-open viewBox="0 0 24 24"><path d="M12 7v14m-9-3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4a4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3a3 3 0 0 0-3-3z" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 /></symbol><use href=#ai:lucide:book-open></use></svg> <span class=truncate>1690 words · 7 minutes</span></div></div><div class=mb-6><div class="flex items-center flex-wrap gap-2"><a href=/blog/category/tech class="btn btn-xs btn-category"><svg height=1em width=1em data-icon=lucide:folder class="h-4 w-4" viewBox="0 0 24 24"><use href=#ai:lucide:folder></use></svg> <span>tech</span> </a><a href=/blog/tag/llm class="btn btn-xs btn-tag"><svg height=1em width=1em data-icon=lucide:tag class="h-4 w-4" viewBox="0 0 24 24"><use href=#ai:lucide:tag></use></svg> <span>llm</span></a></div></div><div class=mt-8><div class="max-w-none prose prose-headings:scroll-mt-20 prose-img:mx-auto prose-img:rounded-xl" id=content><p><img alt="" src=https://skindhu.github.io/Build-A-Large-Language-Model-CN/Image/chapter4/figure4.1.png></p><h2 id=实现llm的架构>实现LLM的架构</h2><p><img alt="" src=https://skindhu.github.io/Build-A-Large-Language-Model-CN/Image/chapter4/figure4.2.png></p><div class=expressive-code><link href=/_astro/ec.oj3b7.css rel=stylesheet><script type=module src=/_astro/ec.p1z7b.js></script><figure class=frame><figcaption class=header></figcaption><pre data-language=python><code><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>1</div></div><div class=code><span style=--0:#E1E4E8>torch.manual_seed(</span><span style=--0:#79B8FF>123</span><span style=--0:#E1E4E8>)</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>2</div></div><div class=code><span style=--0:#E1E4E8>model </span><span style=--0:#F97583>=</span><span style=--0:#E1E4E8> DummyGPTModel(</span><span style=--0:#79B8FF>GPT_CONFIG_124M</span><span style=--0:#E1E4E8>)</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>3</div></div><div class=code><span style=--0:#E1E4E8>logits </span><span style=--0:#F97583>=</span><span style=--0:#E1E4E8> model(batch)</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>4</div></div><div class=code><span style=--0:#79B8FF>print</span><span style=--0:#E1E4E8>(</span><span style=--0:#9ECBFF>"Output shape:"</span><span style=--0:#E1E4E8>, logits.shape)</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>5</div></div><div class=code><span style=--0:#79B8FF>print</span><span style=--0:#E1E4E8>(logits)</span></div></div></code></pre><div class=copy><button title="Copy to clipboard" data-code="torch.manual_seed(123)model = DummyGPTModel(GPT_CONFIG_124M)logits = model(batch)print(&#x22;Output shape:&#x22;, logits.shape)print(logits)" data-copied=Copied!><div></div></button></div></figure></div><p>模型的输出通常被称为logits,它的形状是[batch,text_len,vocab_size].嵌入层的维度为 50,257，因为每个维度对应词汇表中的一个唯一 token。在之后的处理中，我们会将这些 50,257 维向量转换回 token ID，然后再解码成单词。</p><h2 id=使用layernorm对激活值进行标准化>使用LayerNorm对激活值进行标准化</h2><p>本节中，我们将实现层归一化，以提高神经网络训练的稳定性和效率。</p><h3 id=layernorm的工作原理>LayerNorm的工作原理</h3><p><img alt="" src=https://skindhu.github.io/Build-A-Large-Language-Model-CN/Image/chapter4/figure4.5.png></p><p>神经网络层包含一个线性层，后接一个非线性激活函数 ReLU，这是神经网络中的标准激活函数。</p><div class=expressive-code><figure class=frame><figcaption class=header></figcaption><pre data-language=python><code><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>1</div></div><div class=code><span style=--0:#E1E4E8>torch.manual_seed(</span><span style=--0:#79B8FF>123</span><span style=--0:#E1E4E8>)</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>2</div></div><div class=code><span style=--0:#E1E4E8>batch_example </span><span style=--0:#F97583>=</span><span style=--0:#E1E4E8> torch.randn(</span><span style=--0:#79B8FF>2</span><span style=--0:#E1E4E8>, </span><span style=--0:#79B8FF>5</span><span style=--0:#E1E4E8>)          </span><span style=--0:#99A0A6>#A</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>3</div></div><div class=code><span style=--0:#E1E4E8>layer </span><span style=--0:#F97583>=</span><span style=--0:#E1E4E8> nn.Sequential(nn.Linear(</span><span style=--0:#79B8FF>5</span><span style=--0:#E1E4E8>, </span><span style=--0:#79B8FF>6</span><span style=--0:#E1E4E8>), nn.ReLU())</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>4</div></div><div class=code><span style=--0:#E1E4E8>out </span><span style=--0:#F97583>=</span><span style=--0:#E1E4E8> layer(batch_example)</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>5</div></div><div class=code><span style=--0:#79B8FF>print</span><span style=--0:#E1E4E8>(out)</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>6</div></div><div class=code>
</div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>7</div></div><div class=code><span style=--0:#99A0A6>#A 创建2个训练样本，每个样本有5个维度（特征）</span></div></div></code></pre><div class=copy><button title="Copy to clipboard" data-code="torch.manual_seed(123)batch_example = torch.randn(2, 5)          #Alayer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())out = layer(batch_example)print(out)#A 创建2个训练样本，每个样本有5个维度（特征）" data-copied=Copied!><div></div></button></div></figure></div><p>实现层归一化，以提高神经网络训练的稳定性和效率。改操作包括减去均值,并除以标准差.</p><p>现在将这个过程封装到一个Pytorch模块中,以便后续使用:</p><div class=expressive-code><figure class=frame><figcaption class=header></figcaption><pre data-language=python><code><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>1</div></div><div class=code><span style=--0:#99A0A6># Listing 4.2 A layer normalization class</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>2</div></div><div class=code><span style=--0:#F97583>class</span><span style=--0:#E1E4E8> </span><span style=--0:#B392F0>LayerNorm</span><span style=--0:#E1E4E8>(</span><span style=--0:#B392F0>nn</span><span style=--0:#E1E4E8>.</span><span style=--0:#B392F0>Module</span><span style=--0:#E1E4E8>):</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>3</div></div><div class=code><span class=indent>    </span><span style=--0:#F97583>def</span><span style=--0:#E1E4E8> </span><span style=--0:#79B8FF>__init__</span><span style=--0:#E1E4E8>(self, emb_dim):</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>4</div></div><div class=code><span class=indent>        </span><span style=--0:#79B8FF>super</span><span style=--0:#E1E4E8>().</span><span style=--0:#79B8FF>__init__</span><span style=--0:#E1E4E8>()</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>5</div></div><div class=code><span class=indent>        </span><span style=--0:#79B8FF>self</span><span style=--0:#E1E4E8>.eps </span><span style=--0:#F97583>=</span><span style=--0:#E1E4E8> </span><span style=--0:#79B8FF>1e-5</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>6</div></div><div class=code><span class=indent>        </span><span style=--0:#79B8FF>self</span><span style=--0:#E1E4E8>.scale </span><span style=--0:#F97583>=</span><span style=--0:#E1E4E8> nn.Parameter(torch.ones(emb_dim))</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>7</div></div><div class=code><span class=indent>        </span><span style=--0:#79B8FF>self</span><span style=--0:#E1E4E8>.shift </span><span style=--0:#F97583>=</span><span style=--0:#E1E4E8> nn.Parameter(torch.zeros(emb_dim))</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>8</div></div><div class=code>
</div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>9</div></div><div class=code><span class=indent>    </span><span style=--0:#F97583>def</span><span style=--0:#E1E4E8> </span><span style=--0:#B392F0>forward</span><span style=--0:#E1E4E8>(self, x):</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>10</div></div><div class=code><span class=indent><span style=--0:#E1E4E8>        </span></span><span style=--0:#E1E4E8>mean </span><span style=--0:#F97583>=</span><span style=--0:#E1E4E8> x.mean(</span><span style=--0:#FFAB70>dim</span><span style=--0:#F97583>=-</span><span style=--0:#79B8FF>1</span><span style=--0:#E1E4E8>, </span><span style=--0:#FFAB70>keepdim</span><span style=--0:#F97583>=</span><span style=--0:#79B8FF>True</span><span style=--0:#E1E4E8>)</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>11</div></div><div class=code><span class=indent><span style=--0:#E1E4E8>        </span></span><span style=--0:#E1E4E8>var </span><span style=--0:#F97583>=</span><span style=--0:#E1E4E8> x.var(</span><span style=--0:#FFAB70>dim</span><span style=--0:#F97583>=-</span><span style=--0:#79B8FF>1</span><span style=--0:#E1E4E8>, </span><span style=--0:#FFAB70>keepdim</span><span style=--0:#F97583>=</span><span style=--0:#79B8FF>True</span><span style=--0:#E1E4E8>, </span><span style=--0:#FFAB70>unbiased</span><span style=--0:#F97583>=</span><span style=--0:#79B8FF>False</span><span style=--0:#E1E4E8>)</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>12</div></div><div class=code><span class=indent><span style=--0:#E1E4E8>        </span></span><span style=--0:#E1E4E8>norm_x </span><span style=--0:#F97583>=</span><span style=--0:#E1E4E8> (x </span><span style=--0:#F97583>-</span><span style=--0:#E1E4E8> mean) </span><span style=--0:#F97583>/</span><span style=--0:#E1E4E8> torch.sqrt(var </span><span style=--0:#F97583>+</span><span style=--0:#E1E4E8> </span><span style=--0:#79B8FF>self</span><span style=--0:#E1E4E8>.eps)</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>13</div></div><div class=code><span class=indent>        </span><span style=--0:#F97583>return</span><span style=--0:#E1E4E8> </span><span style=--0:#79B8FF>self</span><span style=--0:#E1E4E8>.scale </span><span style=--0:#F97583>*</span><span style=--0:#E1E4E8> norm_x </span><span style=--0:#F97583>+</span><span style=--0:#E1E4E8> </span><span style=--0:#79B8FF>self</span><span style=--0:#E1E4E8>.shift</span></div></div></code></pre><div class=copy><button title="Copy to clipboard" data-code="# Listing 4.2 A layer normalization classclass LayerNorm(nn.Module):    def __init__(self, emb_dim):        super().__init__()        self.eps = 1e-5        self.scale = nn.Parameter(torch.ones(emb_dim))        self.shift = nn.Parameter(torch.zeros(emb_dim))    def forward(self, x):        mean = x.mean(dim=-1, keepdim=True)        var = x.var(dim=-1, keepdim=True, unbiased=False)        norm_x = (x - mean) / torch.sqrt(var + self.eps)        return self.scale * norm_x + self.shift" data-copied=Copied!><div></div></button></div></figure></div><h2 id=实现带有gelu激活函数的前馈神经网络>实现带有GELU激活函数的前馈神经网络</h2><p>实现一个小型神经网络子模块</p><p> <code>GELU(x) = x ⋅ Φ(x)</code>，其中 Φ(x) 是标准正态分布的原函数。计算开销更低的近似实现:</p><p><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>G</mi><mi>E</mi><mi>L</mi><mi>U</mi><mo stretchy=false>(</mo><mi>x</mi><mo stretchy=false>)</mo><mo>≈</mo><mn>0.5</mn><mo>⋅</mo><mi>x</mi><mo>⋅</mo><mo stretchy=false>(</mo><mn>1</mn><mo>+</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy=false>[</mo><mo stretchy=false>(</mo><mn>2</mn><mi mathvariant=normal>/</mi><mi>π</mi><mo stretchy=false>)</mo><mtext>​</mtext><mo>⋅</mo><mo stretchy=false>(</mo><mi>x</mi><mo>+</mo><mn>0.044715</mn><mo>⋅</mo><mi>x</mi><mn>3</mn><mo stretchy=false>]</mo><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>GELU(x)≈0.5⋅x⋅(1+tanh[(2/π)​⋅(x+0.044715⋅x3])</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span style=height:1em;vertical-align:-.25em class=strut></span><span style=margin-right:.05764em class="mord mathnormal">GE</span><span style=margin-right:.10903em class="mord mathnormal">LU</span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mclose>)</span><span style=margin-right:.2778em class=mspace></span><span class=mrel>≈</span><span style=margin-right:.2778em class=mspace></span></span><span class=base><span style=height:.6444em class=strut></span><span class=mord>0.5</span><span style=margin-right:.2222em class=mspace></span><span class=mbin>⋅</span><span style=margin-right:.2222em class=mspace></span></span><span class=base><span style=height:.4445em class=strut></span><span class="mord mathnormal">x</span><span style=margin-right:.2222em class=mspace></span><span class=mbin>⋅</span><span style=margin-right:.2222em class=mspace></span></span><span class=base><span style=height:1em;vertical-align:-.25em class=strut></span><span class=mopen>(</span><span class=mord>1</span><span style=margin-right:.2222em class=mspace></span><span class=mbin>+</span><span style=margin-right:.2222em class=mspace></span></span><span class=base><span style=height:1em;vertical-align:-.25em class=strut></span><span class="mord mathnormal">t</span><span class="mord mathnormal">anh</span><span class=mopen>[(</span><span class=mord>2/</span><span style=margin-right:.03588em class="mord mathnormal">π</span><span class=mclose>)</span><span class=mord>​</span><span style=margin-right:.2222em class=mspace></span><span class=mbin>⋅</span><span style=margin-right:.2222em class=mspace></span></span><span class=base><span style=height:1em;vertical-align:-.25em class=strut></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span style=margin-right:.2222em class=mspace></span><span class=mbin>+</span><span style=margin-right:.2222em class=mspace></span></span><span class=base><span style=height:.6444em class=strut></span><span class=mord>0.044715</span><span style=margin-right:.2222em class=mspace></span><span class=mbin>⋅</span><span style=margin-right:.2222em class=mspace></span></span><span class=base><span style=height:1em;vertical-align:-.25em class=strut></span><span class="mord mathnormal">x</span><span class=mord>3</span><span class=mclose>])</span></span></span></span></p><p>使用 GELU 激活函数实现一个小型的神经网络模块 FeedForward:</p><div class=expressive-code><figure class=frame><figcaption class=header></figcaption><pre data-language=python><code><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>1</div></div><div class=code><span style=--0:#99A0A6># Listing 4.4 A feed forward neural network module</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>2</div></div><div class=code><span style=--0:#F97583>class</span><span style=--0:#E1E4E8> </span><span style=--0:#B392F0>FeedForward</span><span style=--0:#E1E4E8>(</span><span style=--0:#B392F0>nn</span><span style=--0:#E1E4E8>.</span><span style=--0:#B392F0>Module</span><span style=--0:#E1E4E8>):</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>3</div></div><div class=code><span class=indent>    </span><span style=--0:#F97583>def</span><span style=--0:#E1E4E8> </span><span style=--0:#79B8FF>__init__</span><span style=--0:#E1E4E8>(self, cfg):</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>4</div></div><div class=code><span class=indent>        </span><span style=--0:#79B8FF>super</span><span style=--0:#E1E4E8>().</span><span style=--0:#79B8FF>__init__</span><span style=--0:#E1E4E8>()</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>5</div></div><div class=code><span class=indent>        </span><span style=--0:#79B8FF>self</span><span style=--0:#E1E4E8>.layers </span><span style=--0:#F97583>=</span><span style=--0:#E1E4E8> nn.Sequential(</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>6</div></div><div class=code><span class=indent><span style=--0:#E1E4E8>            </span></span><span style=--0:#E1E4E8>nn.Linear(cfg[</span><span style=--0:#9ECBFF>"emb_dim"</span><span style=--0:#E1E4E8>], </span><span style=--0:#79B8FF>4</span><span style=--0:#E1E4E8> </span><span style=--0:#F97583>*</span><span style=--0:#E1E4E8> cfg[</span><span style=--0:#9ECBFF>"emb_dim"</span><span style=--0:#E1E4E8>]),</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>7</div></div><div class=code><span class=indent><span style=--0:#E1E4E8>            </span></span><span style=--0:#E1E4E8>GELU(),</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>8</div></div><div class=code><span class=indent><span style=--0:#E1E4E8>            </span></span><span style=--0:#E1E4E8>nn.Linear(</span><span style=--0:#79B8FF>4</span><span style=--0:#E1E4E8> </span><span style=--0:#F97583>*</span><span style=--0:#E1E4E8> cfg[</span><span style=--0:#9ECBFF>"emb_dim"</span><span style=--0:#E1E4E8>], cfg[</span><span style=--0:#9ECBFF>"emb_dim"</span><span style=--0:#E1E4E8>]),</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>9</div></div><div class=code><span class=indent><span style=--0:#E1E4E8>        </span></span><span style=--0:#E1E4E8>)</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>10</div></div><div class=code>
</div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>11</div></div><div class=code><span style=--0:#F97583>def</span><span style=--0:#E1E4E8> </span><span style=--0:#B392F0>forward</span><span style=--0:#E1E4E8>(self, x):</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>12</div></div><div class=code><span class=indent>    </span><span style=--0:#F97583>return</span><span style=--0:#E1E4E8> </span><span style=--0:#79B8FF>self</span><span style=--0:#E1E4E8>.layers(x)</span></div></div></code></pre><div class=copy><button title="Copy to clipboard" data-code="# Listing 4.4 A feed forward neural network moduleclass FeedForward(nn.Module):    def __init__(self, cfg):        super().__init__()        self.layers = nn.Sequential(            nn.Linear(cfg[&#x22;emb_dim&#x22;], 4 * cfg[&#x22;emb_dim&#x22;]),            GELU(),            nn.Linear(4 * cfg[&#x22;emb_dim&#x22;], cfg[&#x22;emb_dim&#x22;]),        )def forward(self, x):    return self.layers(x)" data-copied=Copied!><div></div></button></div></figure></div><p><img alt="" src=https://skindhu.github.io/Build-A-Large-Language-Model-CN/Image/chapter4/figure4.9.png></p><p>输出的张量形状与输入张量形状相同.</p><p>FeedForward模块对模型的泛化能力起到了关键作用.</p><blockquote><p>尽管该模块的输入和输出维度相同，但在内部，它首先通过第一个线性层将嵌入维度扩展到一个更高维度的空间。之后再接入非线性 GELU 激活，最后再通过第二个线性层变换回原始维度。这样的设计能够探索更丰富的表示空间。扩展后的高维空间可以让模型“看到”输入数据中更多的隐藏特征，提取出更丰富的信息。然后在收缩回低维度时，这些丰富的特征被整合到了输入的原始维度表示中，使模型最终的输出包含更多的上下文和信息。</p></blockquote><blockquote><p>[!note] 主观设计的产物.</p></blockquote><h2 id=添加残差连接>添加残差连接</h2><p>快捷连接最初是在计算机视觉中的深度网络（尤其是残差网络）提出的，用于缓解梯度消失问题。梯度消失是指在训练中指导权重更新的梯度在反向传播过程中逐渐减小，导致早期层（靠近输入端的网络层）难以有效训练</p><p><img alt="" src=https://skindhu.github.io/Build-A-Large-Language-Model-CN/Image/chapter4/figure4.12.png></p><blockquote><p>[!note] 如何理解梯度消失现象?为什么有这种问题?</p></blockquote><p>快捷连接可以通过将某一层的输出直接传递给更深层来跳过==<strong>一个或多个</strong>==层，有助于缓解深度神经网络训练中的梯度消失问题。</p><h2 id=连接注意力层与线性层transformer模块>连接注意力层与线性层(Transformer模块)</h2><p><img alt="" src=https://skindhu.github.io/Build-A-Large-Language-Model-CN/Image/chapter4/figure4.13.png></p><p>Transformer 模块的输出维度与输入维度保持一致.</p><h2 id=实现gpt模型>实现GPT模型</h2><p><img alt="" src=https://skindhu.github.io/Build-A-Large-Language-Model-CN/Image/chapter4/figure4.15.png></p><p>在参数量为 1.24 亿的 GPT-2 模型中，该模块重复了 12 次，这一数量通过 <code>GPT_CONFIG_124M</code> 配置字典中的<code>n_layers</code>参数指定。在 GPT-2 最大的 15.42 亿参数模型中，Transformer 模块重复了 36 次。</p><p>最后一个 Transformer 模块的输出会经过一个最终的LayerNorm步骤，然后进入线性输出层。该层将 Transformer 的输出映射到一个高维空间（在本例中为 50,257 维，对应于模型的词汇表大小），以预测序列中的下一个词。</p><h3 id=分析模型规模>分析模型规模</h3><h4 id=参数数量>参数数量</h4><p>统计模型中参数张量的总参数量:</p><div class=expressive-code><figure class=frame><figcaption class=header></figcaption><pre data-language=python><code><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>1</div></div><div class=code><span style=--0:#E1E4E8>total_params </span><span style=--0:#F97583>=</span><span style=--0:#E1E4E8> </span><span style=--0:#79B8FF>sum</span><span style=--0:#E1E4E8>(p.numel() </span><span style=--0:#F97583>for</span><span style=--0:#E1E4E8> p </span><span style=--0:#F97583>in</span><span style=--0:#E1E4E8> model.parameters())</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>2</div></div><div class=code><span style=--0:#79B8FF>print</span><span style=--0:#E1E4E8>(</span><span style=--0:#F97583>f</span><span style=--0:#9ECBFF>"Total number of parameters: </span><span style=--0:#79B8FF>{</span><span style=--0:#E1E4E8>total_params</span><span style=--0:#F97583>:,</span><span style=--0:#79B8FF>}</span><span style=--0:#9ECBFF>"</span><span style=--0:#E1E4E8>)</span></div></div></code></pre><div class=copy><button title="Copy to clipboard" data-code="total_params = sum(p.numel() for p in model.parameters())print(f&#x22;Total number of parameters: {total_params:,}&#x22;)" data-copied=Copied!><div></div></button></div></figure></div><p>输出如下:</p><div class=expressive-code><figure class=frame><figcaption class=header></figcaption><pre data-language=plaintext><code><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>1</div></div><div class=code><span style=--0:#e1e4e8>Total number of parameters: 163,009,536</span></div></div></code></pre><div class=copy><button title="Copy to clipboard" data-code="Total number of parameters: 163,009,536" data-copied=Copied!><div></div></button></div></figure></div><p>GPT 模型的参数量为 1.24 亿，但代码输出的实际参数量却是 1.63 亿，这是为什么呢？</p><p>原因在于 GPT-2 架构中使用了一种称为‘权重共享’的概念，这意味着 GPT-2 架构将 token 嵌入层的权重复用于输出层。为了更好地理解这一点，我们可以来看一下在模型中初始化的 token 嵌入层和线性输出层的形状：</p><div class=expressive-code><figure class=frame><figcaption class=header></figcaption><pre data-language=plaintext><code><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>1</div></div><div class=code><span style=--0:#e1e4e8>print("Token embedding layer shape:", model.tok_emb.weight.shape)</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>2</div></div><div class=code><span style=--0:#e1e4e8>print("Output layer shape:", model.out_head.weight.shape)</span></div></div></code></pre><div class=copy><button title="Copy to clipboard" data-code="print(&#x22;Token embedding layer shape:&#x22;, model.tok_emb.weight.shape)print(&#x22;Output layer shape:&#x22;, model.out_head.weight.shape)" data-copied=Copied!><div></div></button></div></figure></div><p>从打印结果可以看到，这两层的权重形状相同：</p><div class=expressive-code><figure class=frame><figcaption class=header></figcaption><pre data-language=plaintext><code><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>1</div></div><div class=code><span style=--0:#e1e4e8>Token embedding layer shape: torch.Size([50257, 768])</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>2</div></div><div class=code><span style=--0:#e1e4e8>Output layer shape: torch.Size([50257, 768])</span></div></div></code></pre><div class=copy><button title="Copy to clipboard" data-code="Token embedding layer shape: torch.Size([50257, 768])Output layer shape: torch.Size([50257, 768])" data-copied=Copied!><div></div></button></div></figure></div><p>token 嵌入层和输出层的参数量很大，因为分词器词汇表中包含 50,257 个 token。这两层的作用都是在嵌入维度和词汇表大小之间映射.根据权重共享原则，我们可以从 GPT-2 模型的总参数量中去除输出层的参数量。</p><div class=expressive-code><figure class=frame><figcaption class=header></figcaption><pre data-language=python><code><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>1</div></div><div class=code><span style=--0:#E1E4E8>total_params_gpt2 </span><span style=--0:#F97583>=</span><span style=--0:#E1E4E8> total_params </span><span style=--0:#F97583>-</span><span style=--0:#E1E4E8> </span><span style=--0:#79B8FF>sum</span><span style=--0:#E1E4E8>(p.numel() </span><span style=--0:#F97583>for</span><span style=--0:#E1E4E8> p </span><span style=--0:#F97583>in</span><span style=--0:#E1E4E8> model.out_head.parameters())</span></div></div><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>2</div></div><div class=code><span style=--0:#79B8FF>print</span><span style=--0:#E1E4E8>(</span><span style=--0:#F97583>f</span><span style=--0:#9ECBFF>"Number of trainable parameters considering weight tying: </span><span style=--0:#79B8FF>{</span><span style=--0:#E1E4E8>total_params_gpt2</span><span style=--0:#F97583>:,</span><span style=--0:#79B8FF>}</span><span style=--0:#9ECBFF>"</span><span style=--0:#E1E4E8>)</span></div></div></code></pre><div class=copy><button title="Copy to clipboard" data-code="total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())print(f&#x22;Number of trainable parameters considering weight tying: {total_params_gpt2:,}&#x22;)" data-copied=Copied!><div></div></button></div></figure></div><p>输出如下：</p><div class=expressive-code><figure class=frame><figcaption class=header></figcaption><pre data-language=plaintext><code><div class=ec-line><div class=gutter><div class=ln aria-hidden=true>1</div></div><div class=code><span style=--0:#e1e4e8>Number of trainable parameters considering weight tying: 124,412,160</span></div></div></code></pre><div class=copy><button title="Copy to clipboard" data-code="Number of trainable parameters considering weight tying: 124,412,160" data-copied=Copied!><div></div></button></div></figure></div><p>如我们所见，模型现在的参数量为 1.24 亿，与 GPT-2 原始模型的规模一致。</p><p>权重共享能够减少模型的整体内存占用和计算复杂度。然而，根据我的经验，==分别使用独立的 token 嵌入层和输出层会使训练效果和模型性能更佳，因此在我们的 GPT 模型实现中，我们使用了独立的嵌入层和输出层。==现代大语言模型也是如此。</p><h4 id=参数所需内存>参数所需内存</h4><p>假设每个参数为32位浮点数,占用4字节,我们得出模型总大小位621.83MB.</p><h2 id=生成文本>生成文本</h2><p><img alt="" src=https://skindhu.github.io/Build-A-Large-Language-Model-CN/Image/chapter4/figure4.16.png></p><p>给定输入上下文后,逐步生成文本.每次迭代中,输入上下文会不断拓展,是模型能够生成连贯且符合上下文的内容.</p><p>模型每一步输出与词汇表大小相同的张量[context_size, vocab_size],表示下一个潜在的token.取出最后一个(即预测,形状为[1,vocab_size]),通过<code>softmax</code>转换为概率分布.找到最高概率对应的索引,取得token ID.将token ID 解码回文本,从而得到下个token.这样就达到了目的.</p><p>在实践中,我们会多次迭代这一过程,直到生成的token数量达到要求.</p><p><code>ch04/01_main-chapter-code/gpt.py</code>的<code>generate_text_simple</code>就是这一过程.</p><blockquote><p>其实<code>softmax</code>函数和取最大值是重复的,因为<code>softmax</code>单调.</p></blockquote><p><code>model.eval()</code>方法会自动禁用训练时使用的随机组件<code>dropout()</code>.</p><p>目前的模型生成的是一些随机的内容,因为模型还没经过训 练,使用随机权重.</p><hr data-astro-cid-zux26muy><div class="container p-0" data-astro-cid-zux26muy><div class="text-sm italic mb-2 text-base-content/60 text-right" data-astro-cid-zux26muy><svg height=1em width=1em data-icon=ri:heart-line class="h-4 w-4 align-text-bottom inline-block text-error" data-astro-cid-zux26muy=true><symbol id=ai:ri:heart-line viewBox="0 0 24 24"><path d="M12.001 4.529a6 6 0 0 1 8.242.228a6 6 0 0 1 .236 8.236l-8.48 8.492l-8.478-8.492a6 6 0 0 1 8.48-8.464m6.826 1.641a4 4 0 0 0-5.49-.153l-1.335 1.198l-1.336-1.197a4 4 0 0 0-5.686 5.605L12 18.654l7.02-7.03a4 4 0 0 0-.193-5.454" fill=currentColor /></symbol><use href=#ai:ri:heart-line></use></svg> Thanks for reading!</div><div class="bg-base-200 card overflow-visible" data-astro-cid-zux26muy><div class="relative p-4 card-body lg:p-8 sm:p-6" data-astro-cid-zux26muy><div class="-top-8 absolute left-8" data-astro-cid-zux26muy><div class="flex items-center justify-center bg-primary h-16 rounded-full shadow-lg w-16" data-astro-cid-zux26muy><svg height=1em width=1em data-icon=ri:creative-commons-line class="h-10 text-primary-content w-10" data-astro-cid-zux26muy=true><symbol id=ai:ri:creative-commons-line viewBox="0 0 24 24"><path d="M9 8c1.104 0 2.105.448 2.829 1.173l-1.414 1.413a2 2 0 1 0 0 2.828l1.413 1.414A4.001 4.001 0 0 1 5 12c0-2.208 1.792-4 4-4m9.829 1.173A4.001 4.001 0 0 0 12 12a4.001 4.001 0 0 0 6.828 2.828l-1.414-1.414a2 2 0 1 1 0-2.828zM2 12C2 6.477 6.477 2 12 2s10 4.477 10 10s-4.477 10-10 10S2 17.523 2 12m10-8a8 8 0 1 0 0 16a8 8 0 0 0 0-16" fill=currentColor /></symbol><use href=#ai:ri:creative-commons-line></use></svg></div></div><div class=space-y-4 data-astro-cid-zux26muy><h3 class="sm:text-xl font-bold text-lg lg:text-2xl" data-astro-cid-zux26muy>从零开始实现一个用于文本生成的GPT模型 | LLM</h3><div class="flex flex-wrap gap-2 opacity-75 sm:gap-4 sm:text-sm text-xs" data-astro-cid-zux26muy><span class="flex items-center gap-1" data-astro-cid-zux26muy><svg height=1em width=1em data-icon=lucide:calendar class="h-4 w-4" viewBox="0 0 24 24" data-astro-cid-zux26muy=true><use href=#ai:lucide:calendar></use></svg> Wed Sep 24 2025</span><div class="flex items-center gap-1" data-astro-cid-zux26muy><svg height=1em width=1em data-icon=lucide:book-open class="h-4 w-4" viewBox="0 0 24 24" data-astro-cid-zux26muy=true><use href=#ai:lucide:book-open></use></svg> <span data-astro-cid-zux26muy>1690 words · 7 minutes</span></div><a href=https://tankimzeg.top/llm/ch4_gpt-model class="flex items-center gap-1 hover:text-primary transition-colors" data-astro-cid-zux26muy><svg height=1em width=1em data-icon=ri:links-line class="h-4 w-4" data-astro-cid-zux26muy=true><symbol id=ai:ri:links-line viewBox="0 0 24 24"><path d="m13.06 8.111l1.415 1.414a7 7 0 0 1 0 9.9l-.354.353a7 7 0 1 1-9.9-9.9l1.415 1.415a5 5 0 1 0 7.071 7.071l.354-.354a5 5 0 0 0 0-7.07l-1.415-1.415zm6.718 6.01l-1.414-1.414a5 5 0 0 0-7.071-7.07l-.354.353a5 5 0 0 0 0 7.07l1.415 1.415l-1.415 1.414l-1.414-1.414a7 7 0 0 1 0-9.9l.354-.353a7 7 0 1 1 9.9 9.9" fill=currentColor /></symbol><use href=#ai:ri:links-line></use></svg></a></div><div class=mt-4 data-astro-cid-zux26muy><div class="flex items-center flex-wrap gap-2"><a href=/blog/category/tech class="btn btn-xs btn-category"><svg height=1em width=1em data-icon=lucide:folder class="h-4 w-4" viewBox="0 0 24 24"><use href=#ai:lucide:folder></use></svg> <span>tech</span> </a><a href=/blog/tag/llm class="btn btn-xs btn-tag"><svg height=1em width=1em data-icon=lucide:tag class="h-4 w-4" viewBox="0 0 24 24"><use href=#ai:lucide:tag></use></svg> <span>llm</span></a></div><hr data-astro-cid-zux26muy class=my-4><p class="text-sm opacity-75" data-astro-cid-zux26muy></p>© TanKimzeg | <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed class="hover:text-primary transition-colors" target=_blank data-astro-cid-zux26muy rel="noopener noreferrer">CC BY-NC-SA 4.0</a></div></div><div class="flex justify-end mt-4" data-astro-cid-zux26muy><button class="btn btn-outline btn-primary" data-astro-cid-zux26muy onclick=share_modal.showModal()>Share <svg height=1em width=1em data-icon=ri:share-line class="h-5 w-5" data-astro-cid-zux26muy=true><symbol id=ai:ri:share-line viewBox="0 0 24 24"><path d="m13.12 17.023l-4.199-2.29a4 4 0 1 1 0-5.465l4.2-2.29a4 4 0 1 1 .958 1.755l-4.2 2.29a4 4 0 0 1 0 1.954l4.2 2.29a4 4 0 1 1-.959 1.755M6 14a2 2 0 1 0 0-4a2 2 0 0 0 0 4m11-6a2 2 0 1 0 0-4a2 2 0 0 0 0 4m0 12a2 2 0 1 0 0-4a2 2 0 0 0 0 4" fill=currentColor /></symbol><use href=#ai:ri:share-line></use></svg></button></div></div></div><dialog class="modal modal-bottom sm:modal-middle" id=share_modal data-astro-cid-zux26muy><div class="modal-box max-w-2xl rounded-none sm:rounded-xl" data-astro-cid-zux26muy><h3 class="mb-6 font-bold sm:text-xl text-center text-lg" data-astro-cid-zux26muy>Share this article</h3><div class="flex justify-center flex-wrap gap-4" data-astro-cid-zux26muy><a href="https://twitter.com/intent/tweet/?text=从零开始实现一个用于文本生成的GPT模型 | LLM&url=https://tankimzeg.top/llm/ch4_gpt-model" class="btn btn-circle hover:scale-110 btn-lg transition-transform bg-black hover:bg-gray-800" target=_blank data-astro-cid-zux26muy rel="noopener noreferrer" title="X (Twitter)"><span class=sr-only data-astro-cid-zux26muy>X (Twitter)</span> <svg height=1em width=1em data-icon=ri:twitter-x-line class="h-6 text-white w-6" data-astro-cid-zux26muy=true><symbol id=ai:ri:twitter-x-line viewBox="0 0 24 24"><path d="M10.488 14.651L15.25 21h7l-7.858-10.478L20.93 3h-2.65l-5.117 5.886L8.75 3h-7l7.51 10.015L2.32 21h2.65zM16.25 19L5.75 5h2l10.5 14z" fill=currentColor /></symbol><use href=#ai:ri:twitter-x-line></use></svg> </a><a href="https://telegram.me/share/url?text=从零开始实现一个用于文本生成的GPT模型 | LLM&url=https://tankimzeg.top/llm/ch4_gpt-model" class="btn btn-circle hover:scale-110 btn-lg transition-transform bg-[#26a5e4] hover:bg-[#1e96d1]" target=_blank data-astro-cid-zux26muy rel="noopener noreferrer" title=Telegram><span class=sr-only data-astro-cid-zux26muy>Telegram</span> <svg height=1em width=1em data-icon=ri:telegram-line class="h-6 text-white w-6" data-astro-cid-zux26muy=true><symbol id=ai:ri:telegram-line viewBox="0 0 24 24"><path d="M20 12a8 8 0 1 1-16 0a8 8 0 0 1 16 0m-8 10c5.523 0 10-4.477 10-10S17.523 2 12 2S2 6.477 2 12s4.477 10 10 10m.358-12.618q-1.458.607-5.831 2.513q-.711.282-.744.552c-.038.304.343.424.862.587l.218.07c.51.166 1.198.36 1.555.368q.486.01 1.084-.4q4.086-2.76 4.218-2.789c.063-.014.149-.032.207.02c.059.052.053.15.047.177c-.038.161-1.534 1.552-2.308 2.271q-.344.324-.683.653c-.474.457-.83.8.02 1.36c.861.568 1.73 1.134 2.57 1.733c.414.296.786.56 1.246.519c.267-.025.543-.276.683-1.026c.332-1.77.983-5.608 1.133-7.19a1.8 1.8 0 0 0-.017-.393a.42.42 0 0 0-.142-.27c-.12-.098-.305-.118-.387-.117c-.376.007-.953.207-3.73 1.362" fill=currentColor /></symbol><use href=#ai:ri:telegram-line></use></svg> </a><a href="https://reddit.com/submit/?url=https://tankimzeg.top/llm/ch4_gpt-model&title=从零开始实现一个用于文本生成的GPT模型 | LLM" class="btn btn-circle hover:scale-110 btn-lg transition-transform bg-[#ff4500] hover:bg-[#e63e00]" target=_blank data-astro-cid-zux26muy rel="noopener noreferrer" title=Reddit><span class=sr-only data-astro-cid-zux26muy>Reddit</span> <svg height=1em width=1em data-icon=ri:reddit-line class="h-6 text-white w-6" data-astro-cid-zux26muy=true><symbol id=ai:ri:reddit-line viewBox="0 0 24 24"><path d="m11.053 7.815l.751-3.536a2 2 0 0 1 2.372-1.54l3.196.68a2 2 0 1 1-.415 1.956l-3.197-.68l-.666 3.135c1.785.137 3.558.73 5.164 1.7A3.192 3.192 0 0 1 23 12.203v.021a3.2 3.2 0 0 1-1.207 2.55l-.008.123c0 3.998-4.45 7.03-9.799 7.03c-5.333 0-9.708-3.024-9.705-6.953l-.01-.181a3.193 3.193 0 0 1 3.454-5.35a11.45 11.45 0 0 1 5.329-1.628m9.285 5.526a1.19 1.19 0 0 0 .662-1.075a1.192 1.192 0 0 0-2.016-.806l-.585.56l-.67-.455c-1.615-1.098-3.452-1.725-5.23-1.764h-1.006c-1.875.028-3.652.6-5.237 1.675l-.664.45l-.583-.55a1.192 1.192 0 1 0-1.315 1.952l.633.29l-.053.695a4 4 0 0 0 .003.584c0 2.71 3.356 5.03 7.708 5.03c4.371 0 7.799-2.336 7.802-5.107a3 3 0 0 0 0-.507l-.052-.672zM6.951 13.5a1.5 1.5 0 1 1 3 0a1.5 1.5 0 0 1-3 0m7 0a1.5 1.5 0 1 1 3 0a1.5 1.5 0 0 1-3 0m-1.985 5.103c-1.397 0-2.766-.37-3.881-1.21a.424.424 0 0 1 .597-.597c.945.693 2.123.99 3.269.99s2.33-.275 3.284-.959a.44.44 0 0 1 .732.206a.47.47 0 0 1-.12.423c-.683.797-2.483 1.147-3.88 1.147" fill=currentColor /></symbol><use href=#ai:ri:reddit-line></use></svg> </a><a href="https://facebook.com/sharer/sharer.php?u=https://tankimzeg.top/llm/ch4_gpt-model" class="btn btn-circle hover:scale-110 btn-lg transition-transform bg-[#0866ff] hover:bg-[#0755d6]" target=_blank data-astro-cid-zux26muy rel="noopener noreferrer" title=Facebook><span class=sr-only data-astro-cid-zux26muy>Facebook</span> <svg height=1em width=1em data-icon=ri:facebook-circle-line class="h-6 text-white w-6" data-astro-cid-zux26muy=true><symbol id=ai:ri:facebook-circle-line viewBox="0 0 24 24"><path d="M13.001 19.938a8.001 8.001 0 0 0-1-15.938a8 8 0 0 0-1 15.938V14h-2v-2h2v-1.654c0-1.337.14-1.822.4-2.311A2.73 2.73 0 0 1 12.537 6.9c.382-.205.857-.328 1.687-.381q.494-.032 1.278.08v1.9h-.5c-.917 0-1.296.043-1.522.164a.73.73 0 0 0-.314.314c-.12.226-.164.45-.164 1.368V12h2.5l-.5 2h-2zm-1 2.062c-5.523 0-10-4.477-10-10s4.477-10 10-10s10 4.477 10 10s-4.477 10-10 10" fill=currentColor /></symbol><use href=#ai:ri:facebook-circle-line></use></svg> </a><a href="mailto:?subject=从零开始实现一个用于文本生成的GPT模型 | LLM&#38;body=https://tankimzeg.top/llm/ch4_gpt-model" class="btn btn-circle hover:scale-110 btn-lg transition-transform bg-gray-600 hover:bg-gray-700" target=_blank data-astro-cid-zux26muy rel="noopener noreferrer" title=Email><span class=sr-only data-astro-cid-zux26muy>Email</span> <svg height=1em width=1em data-icon=ri:mail-line class="h-6 text-white w-6" data-astro-cid-zux26muy=true><symbol id=ai:ri:mail-line viewBox="0 0 24 24"><path d="M3 3h18a1 1 0 0 1 1 1v16a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1m17 4.238l-7.928 7.1L4 7.216V19h16zM4.511 5l7.55 6.662L19.502 5z" fill=currentColor /></symbol><use href=#ai:ri:mail-line></use></svg></a></div><div class=modal-action data-astro-cid-zux26muy><form method=dialog data-astro-cid-zux26muy><button class="btn btn-ghost hover:scale-105 transition-transform" data-astro-cid-zux26muy>Close</button></form></div></div><form method=dialog class=modal-backdrop data-astro-cid-zux26muy><button data-astro-cid-zux26muy>Close</button></form></dialog></div></div></div></div></div><script type=module>document.addEventListener("astro:page-load",(()=>{const t=document.querySelectorAll(".dropdown label"),e=document.querySelectorAll(".dropdown-content");t.forEach(((t,a)=>{t.addEventListener("click",(()=>{const t=e[a];"closed"===t.getAttribute("data-state")?(t.setAttribute("data-state","open"),t.classList.add("scale-100","opacity-100"),t.classList.remove("scale-90","opacity-0")):(t.setAttribute("data-state","closed"),t.classList.add("scale-90","opacity-0"),t.classList.remove("scale-100","opacity-100"))}))}))}))</script></div><footer class="bg-base-100 shadow-lg rounded-xl footer p-10"><aside><svg height=50 width=50 class=fill-current viewBox="0 0 24 24" clip-rule=evenodd fill-rule=evenodd xmlns=http://www.w3.org/2000/svg><path d="M22.672 15.226l-2.432.811.841 2.515c.33 1.019-.209 2.127-1.23 2.456-1.15.325-2.148-.321-2.463-1.226l-.84-2.518-5.013 1.677.84 2.517c.391 1.203-.434 2.542-1.831 2.542-.88 0-1.601-.564-1.86-1.314l-.842-2.516-2.431.809c-1.135.328-2.145-.317-2.463-1.229-.329-1.018.211-2.127 1.231-2.456l2.432-.809-1.621-4.823-2.432.808c-1.355.384-2.558-.59-2.558-1.839 0-.817.509-1.582 1.327-1.846l2.433-.809-.842-2.515c-.33-1.02.211-2.129 1.232-2.458 1.02-.329 2.13.209 2.461 1.229l.842 2.515 5.011-1.677-.839-2.517c-.403-1.238.484-2.553 1.843-2.553.819 0 1.585.509 1.85 1.326l.841 2.517 2.431-.81c1.02-.33 2.131.211 2.461 1.229.332 1.018-.21 2.126-1.23 2.456l-2.433.809 1.622 4.823 2.433-.809c1.242-.401 2.557.484 2.557 1.838 0 .819-.51 1.583-1.328 1.847m-8.992-6.428l-5.01 1.675 1.619 4.828 5.011-1.674-1.62-4.829z"></path></svg><p>Powered by <a href=https://github.com/EveSunMaple/Frosti class=font-bold target=_blank>Frosti Template</a><br>Copyright © <a href=https://tankimzeg.top class=font-bold target=_blank>TanKimzeg</a> 2025 - All right reserved</p></aside><nav><span class=footer-title>Social</span><div class="gap-4 grid grid-flow-col"><div class=tooltip data-tip=Github><a href=https://github.com/TanKimzeg aria-label=Github tabindex=0><svg height=1em width=1em data-icon=ri:github-line class="md:text-xl text-2xl"><symbol id=ai:ri:github-line viewBox="0 0 24 24"><path d="M5.884 18.653c-.3-.2-.558-.455-.86-.816a51 51 0 0 1-.466-.579c-.463-.575-.755-.841-1.056-.95a1 1 0 1 1 .675-1.882c.752.27 1.261.735 1.947 1.588c-.094-.117.34.427.433.539c.19.227.33.365.44.438c.204.137.588.196 1.15.14c.024-.382.094-.753.202-1.095c-2.968-.726-4.648-2.64-4.648-6.396c0-1.24.37-2.356 1.058-3.292c-.218-.894-.185-1.975.302-3.192a1 1 0 0 1 .63-.582c.081-.024.127-.035.208-.047c.803-.124 1.937.17 3.415 1.096a11.7 11.7 0 0 1 2.687-.308c.912 0 1.819.104 2.684.308c1.477-.933 2.614-1.227 3.422-1.096q.128.02.218.05a1 1 0 0 1 .616.58c.487 1.216.52 2.296.302 3.19c.691.936 1.058 2.045 1.058 3.293c0 3.757-1.674 5.665-4.642 6.392c.125.415.19.878.19 1.38c0 .665-.002 1.299-.007 2.01c0 .19-.002.394-.005.706a1 1 0 0 1-.018 1.958c-1.14.227-1.984-.532-1.984-1.525l.002-.447l.005-.705c.005-.707.008-1.337.008-1.997c0-.697-.184-1.152-.426-1.361c-.661-.57-.326-1.654.541-1.751c2.966-.333 4.336-1.482 4.336-4.66c0-.955-.312-1.744-.913-2.404A1 1 0 0 1 17.2 6.19c.166-.414.236-.957.095-1.614l-.01.003c-.491.139-1.11.44-1.858.949a1 1 0 0 1-.833.135a9.6 9.6 0 0 0-2.592-.349c-.89 0-1.772.118-2.592.35a1 1 0 0 1-.829-.134c-.753-.507-1.374-.807-1.87-.947c-.143.653-.072 1.194.093 1.607a1 1 0 0 1-.189 1.045c-.597.655-.913 1.458-.913 2.404c0 3.172 1.371 4.328 4.322 4.66c.865.097 1.202 1.177.545 1.748c-.193.168-.43.732-.43 1.364v3.15c0 .985-.834 1.725-1.96 1.528a1 1 0 0 1-.04-1.962v-.99c-.91.061-1.661-.088-2.254-.485" fill=currentColor /></symbol><use href=#ai:ri:github-line></use></svg></a></div><div class=tooltip data-tip=Zhihu><a href=https://www.zhihu.com/people/Dalekov aria-label=Zhihu tabindex=0><svg height=1em width=1em data-icon=ri:zhihu-line class="md:text-xl text-2xl"><symbol id=ai:ri:zhihu-line viewBox="0 0 24 24"><path d="m12.345 17.963l-1.688 1.074l-2.132-3.35c-.44 1.402-1.171 2.665-2.138 3.825c-.402.483-.82.918-1.301 1.376c-.155.146-.775.716-.878.82l-1.414-1.415c.139-.139.787-.735.914-.856c.43-.408.796-.79 1.143-1.205C6.117 16.712 6.88 15.02 6.988 13H3v-2h4V7h-.868c-.689 1.266-1.558 2.222-2.618 2.858L2.486 8.143c1.396-.838 2.426-2.603 3.039-5.36l1.952.434q-.21.95-.489 1.783h4.513v2H9v4h2.5v2H9.186zm3.838-.07L17.3 17h1.702V7h-4v10h.736zM13.001 5h8v14h-3l-2.5 2l-1-2H13z" fill=currentColor /></symbol><use href=#ai:ri:zhihu-line></use></svg></a></div><div class=tooltip data-tip=BiliBili><a href=https://space.bilibili.com/3493121543375815 aria-label=BiliBili tabindex=0><svg height=1em width=1em data-icon=ri:bilibili-line class="md:text-xl text-2xl"><symbol id=ai:ri:bilibili-line viewBox="0 0 24 24"><path d="M7.172 2.757L10.414 6h3.171l3.243-3.242a1 1 0 1 1 1.415 1.415L16.414 6H18.5A3.5 3.5 0 0 1 22 9.5v8a3.5 3.5 0 0 1-3.5 3.5h-13A3.5 3.5 0 0 1 2 17.5v-8A3.5 3.5 0 0 1 5.5 6h2.085L5.757 4.171a1 1 0 0 1 1.415-1.415M18.5 8h-13a1.5 1.5 0 0 0-1.493 1.356L4 9.5v8a1.5 1.5 0 0 0 1.356 1.493L5.5 19h13a1.5 1.5 0 0 0 1.493-1.355L20 17.5v-8A1.5 1.5 0 0 0 18.5 8M8 11a1 1 0 0 1 1 1v2a1 1 0 1 1-2 0v-2a1 1 0 0 1 1-1m8 0a1 1 0 0 1 1 1v2a1 1 0 1 1-2 0v-2a1 1 0 0 1 1-1" fill=currentColor /></symbol><use href=#ai:ri:bilibili-line></use></svg></a></div><div class=tooltip data-tip="RSS Feed"><a href=/rss.xml aria-label="RSS Feed" tabindex=0><svg height=1em width=1em data-icon=ri:rss-line class="md:text-xl text-2xl"><symbol id=ai:ri:rss-line viewBox="0 0 24 24"><path d="M3 17a4 4 0 0 1 4 4H3zm0-7c6.075 0 11 4.925 11 11h-2a9 9 0 0 0-9-9zm0-7c9.941 0 18 8.059 18 18h-2c0-8.837-7.163-16-16-16z" fill=currentColor /></symbol><use href=#ai:ri:rss-line></use></svg></a></div></div></nav></footer></main><aside class="md:top-4 bg-transparent col-span-1 md:order-1 order-2"><div class="relative mb-4"><div class="w-full bg-base-100 shadow-lg rounded-xl"><div class="flex relative flex-col p-4"><div class="flex justify-center p-2"><img alt=Profile src=/profile.jpg class="mask mask-circle" decoding=async fetchpriority=auto height=250 loading=eager width=250></div><ul class="items-center bg-transparent flex-col hidden lg:items-start m-0 md:flex menu p-0 w-full"><li class="relative w-full group"><a href=/ class="flex items-center rounded-lg hover:bg-base-200 font-bold justify-center lg:justify-start lg:text-xl md:text-3xl p-4 text-center text-xl" target=_self aria-label=Home tabindex=0 id=home><svg height=1em width=1em data-icon=material-symbols:home-outline-rounded viewBox="0 0 24 24"><use href=#ai:material-symbols:home-outline-rounded></use></svg> <span class="hidden lg:inline ml-2">Home</span></a></li><li class="relative w-full group"><a href=/about class="flex items-center rounded-lg hover:bg-base-200 font-bold justify-center lg:justify-start lg:text-xl md:text-3xl p-4 text-center text-xl" target=_self aria-label=About tabindex=0 id=about><svg height=1em width=1em data-icon=material-symbols:info-outline-rounded viewBox="0 0 24 24"><use href=#ai:material-symbols:info-outline-rounded></use></svg> <span class="hidden lg:inline ml-2">About</span></a></li><li class="relative w-full group"><details open class="w-full menu-item" data-submenu-id=blog><summary class="items-center rounded-lg hover:bg-base-200 font-bold justify-center lg:justify-start lg:text-xl md:text-3xl p-4 text-center text-xl"><svg height=1em width=1em data-icon=material-symbols:book-2-outline-rounded viewBox="0 0 24 24"><use href=#ai:material-symbols:book-2-outline-rounded></use></svg> <span class="hidden lg:inline ml-2">Blogs</span></summary><ul class=rounded-lg><li class=relative><a href=/blog class="p-2 hover:bg-base-200 rounded-lg font-bold lg:text-base md:text-2xl menu-item text-base" target=_self aria-label="All blogs" tabindex=0 id=header-all><svg height=1em width=1em data-icon=material-symbols:ink-pen-outline-rounded viewBox="0 0 24 24"><use href=#ai:material-symbols:ink-pen-outline-rounded></use></svg> <span class="hidden lg:inline ml-2">All blogs</span></a></li><li class=relative><a href=/blog/category/tech class="p-2 hover:bg-base-200 rounded-lg font-bold lg:text-base md:text-2xl menu-item text-base" target=_self aria-label="Tech Blogs" tabindex=0 id=header-tech><svg height=1em width=1em data-icon=material-symbols:deployed-code-outline viewBox="0 0 24 24"><use href=#ai:material-symbols:deployed-code-outline></use></svg> <span class="hidden lg:inline ml-2">Tech Blogs</span></a></li><li class=relative><a href=/blog/category/life class="p-2 hover:bg-base-200 rounded-lg font-bold lg:text-base md:text-2xl menu-item text-base" target=_self aria-label="Life Blogs" tabindex=0 id=header-life><svg height=1em width=1em data-icon=material-symbols:earthquake-rounded viewBox="0 0 24 24"><use href=#ai:material-symbols:earthquake-rounded></use></svg> <span class="hidden lg:inline ml-2">Life Blogs</span></a></li></ul></details></li><li class="relative w-full group"><a href=/project class="flex items-center rounded-lg hover:bg-base-200 font-bold justify-center lg:justify-start lg:text-xl md:text-3xl p-4 text-center text-xl" target=_self aria-label=Project tabindex=0 id=project><svg height=1em width=1em data-icon=material-symbols:code-blocks-outline viewBox="0 0 24 24"><use href=#ai:material-symbols:code-blocks-outline></use></svg> <span class="hidden lg:inline ml-2">Project</span></a></li><li class="relative w-full group"><a href=/friend class="flex items-center rounded-lg hover:bg-base-200 font-bold justify-center lg:justify-start lg:text-xl md:text-3xl p-4 text-center text-xl" target=_self aria-label=Friend tabindex=0 id=friend><svg height=1em width=1em data-icon=material-symbols:supervisor-account-outline-rounded viewBox="0 0 24 24"><use href=#ai:material-symbols:supervisor-account-outline-rounded></use></svg> <span class="hidden lg:inline ml-2">Friend</span></a></li></ul><div class="mt-4 border-base-content/20 border-t pt-3"><div class="justify-items-center gap-2 grid grid-cols-4 lg:grid-cols-4 md:grid-cols-2"><div class="tooltip tooltip-bottom" data-tip=Github><a href=https://github.com/TanKimzeg class="btn btn-circle btn-ghost" target=_blank aria-label=Github tabindex=0><svg height=1em width=1em data-icon=ri:github-line class=text-xl viewBox="0 0 24 24"><use href=#ai:ri:github-line></use></svg></a></div><div class="tooltip tooltip-bottom" data-tip=Zhihu><a href=https://www.zhihu.com/people/Dalekov class="btn btn-circle btn-ghost" target=_blank aria-label=Zhihu tabindex=0><svg height=1em width=1em data-icon=ri:zhihu-line class=text-xl viewBox="0 0 24 24"><use href=#ai:ri:zhihu-line></use></svg></a></div><div class="tooltip tooltip-bottom" data-tip=BiliBili><a href=https://space.bilibili.com/3493121543375815 class="btn btn-circle btn-ghost" target=_blank aria-label=BiliBili tabindex=0><svg height=1em width=1em data-icon=ri:bilibili-line class=text-xl viewBox="0 0 24 24"><use href=#ai:ri:bilibili-line></use></svg></a></div><div class="tooltip tooltip-bottom" data-tip="RSS Feed"><a href=https://tankimzeg.top/rss.xml class="btn btn-circle btn-ghost" target=_blank aria-label="RSS Feed" tabindex=0><svg height=1em width=1em data-icon=ri:rss-line class=text-xl viewBox="0 0 24 24"><use href=#ai:ri:rss-line></use></svg></a></div></div></div></div></div></div><div class="relative mb-4"><div class="w-full bg-base-100 shadow-lg rounded-xl"><div class=p-4><form method=get class="relative w-full" action=/blog/search><div class="relative w-full search-container"><input type=text aria-label=Search class="w-full input input-bordered pl-10 pr-16 py-2" name=q placeholder=Search><div class="flex items-center absolute inset-y-0 left-0 pl-3 pointer-events-none"><svg height=1em width=1em data-icon=lucide:search class="h-5 w-5"><symbol id=ai:lucide:search viewBox="0 0 24 24"><g fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2><path d="m21 21l-4.34-4.34"/><circle cx=11 cy=11 r=8 /></g></symbol><use href=#ai:lucide:search></use></svg></div><button class="p-2 -translate-y-1/2 absolute right-2 top-1/2 transform" aria-label=Search type=submit><svg height=1em width=1em data-icon=lucide:arrow-right class="h-4 w-4"><symbol id=ai:lucide:arrow-right viewBox="0 0 24 24"><path d="M5 12h14m-7-7l7 7l-7 7" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 /></symbol><use href=#ai:lucide:arrow-right></use></svg></button></div></form></div></div><script type=module>document.addEventListener("keydown",(e=>{const t=e.target;if("/"===e.key&&t&&"INPUT"!==t.tagName&&"TEXTAREA"!==t.tagName){e.preventDefault();const t=document.querySelector('input[name="q"]');t&&t.focus()}}))</script></div><div class="md:top-4 md:sticky"><div class="w-full bg-base-100 shadow-lg rounded-xl"><div class="toolbar-container p-4"><div class="items-center justify-center flex-wrap gap-4 grid grid-cols-4 lg:grid-cols-4 md:grid-cols-2"><a href=/blog/tags class="btn btn-circle hover:scale-110 bg-base-100 btn-md shadow-sm border-base-content/20" aria-label=Tag title=Tag><svg height=1em width=1em data-icon=lucide:tag class="h-5 w-5"><symbol id=ai:lucide:tag viewBox="0 0 24 24"><g fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"/><circle cx=7.5 cy=7.5 r=.5 fill=currentColor /></g></symbol><use href=#ai:lucide:tag></use></svg> </a><a href=/blog/categories class="btn btn-circle hover:scale-110 bg-base-100 btn-md shadow-sm border-base-content/20" aria-label=Category title=Category><svg height=1em width=1em data-icon=lucide:folder class="h-5 w-5"><symbol id=ai:lucide:folder viewBox="0 0 24 24"><path d="M20 20a2 2 0 0 0 2-2V8a2 2 0 0 0-2-2h-7.9a2 2 0 0 1-1.69-.9L9.6 3.9A2 2 0 0 0 7.93 3H4a2 2 0 0 0-2 2v13a2 2 0 0 0 2 2Z" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 /></symbol><use href=#ai:lucide:folder></use></svg> </a><a href=/blog/archives class="btn btn-circle hover:scale-110 bg-base-100 btn-md shadow-sm border-base-content/20" aria-label=Archives title=Archives><svg height=1em width=1em data-icon=lucide:archive class="h-5 w-5"><symbol id=ai:lucide:archive viewBox="0 0 24 24"><g fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2><rect height=5 rx=1 width=20 x=2 y=3 /><path d="M4 8v11a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8m-10 4h4"/></g></symbol><use href=#ai:lucide:archive></use></svg> </a><button title="Theme Toggle" aria-label="Toggle theme" class="btn btn-circle hover:scale-110 bg-base-100 btn-md shadow-sm md:border-base-content/20 sidebar-theme" data-astro-cid-mjqc4hpp data-theme-toggle id=theme-toggle-g2jwrcswi><svg height=1em width=1em data-icon=lucide:sun class="h-5 w-5 theme-toggle-icon sun-icon" viewBox="0 0 24 24" data-astro-cid-mjqc4hpp=true><use href=#ai:lucide:sun></use></svg> <svg height=1em width=1em data-icon=lucide:moon class="h-5 w-5 theme-toggle-icon hidden moon-icon" viewBox="0 0 24 24" data-astro-cid-mjqc4hpp=true><use href=#ai:lucide:moon></use></svg></button><script>!function(){const e="winter",t="dracula",n=(e,t)=>{if(!e)return;const n=e.querySelector(".sun-icon"),d=e.querySelector(".moon-icon");n&&d&&(t?(n.classList.remove("hidden"),d.classList.add("hidden")):(n.classList.add("hidden"),d.classList.remove("hidden")))};document.addEventListener("astro:page-load",(()=>{const d=document.getElementById("theme-toggle-g2jwrcswi");if(!d)return;const o=document.documentElement.getAttribute("data-theme");n(d,o===t),d.addEventListener("click",(()=>{const o=document.documentElement.getAttribute("data-theme")===e?t:e;d.classList.add("animate-spin-once"),document.documentElement.setAttribute("data-theme",o);const c=o===t?"dark":"light";document.documentElement.setAttribute("data-theme-type",c),localStorage.setItem("theme",o);document.querySelectorAll("[data-theme-toggle]").forEach((e=>{n(e,o===t)})),setTimeout((()=>{d.classList.remove("animate-spin-once")}),300)}))}))}()</script></div></div></div><button class="btn btn-circle hover:scale-110 bg-base-100 btn-md fixed invisible opacity-0 right-6 shadow-lg transition-all z-50 bottom-6" aria-label="Scroll to top" id=scroll-to-top><svg height=1em width=1em data-icon=material-symbols:arrow-upward-rounded class="h-5 w-5"><symbol id=ai:material-symbols:arrow-upward-rounded viewBox="0 0 24 24"><path d="m11 7.825l-4.9 4.9q-.3.3-.7.288t-.7-.313q-.275-.3-.288-.7t.288-.7l6.6-6.6q.15-.15.325-.212T12 4.425t.375.063t.325.212l6.6 6.6q.275.275.275.688t-.275.712q-.3.3-.712.3t-.713-.3L13 7.825V19q0 .425-.288.713T12 20t-.712-.288T11 19z" fill=currentColor /></symbol><use href=#ai:material-symbols:arrow-upward-rounded></use></svg></button><script type=module>document.addEventListener("astro:page-load",(()=>{const i=document.getElementById("scroll-to-top");if(i){const s=()=>{window.scrollY>300?(i.classList.remove("opacity-0","invisible"),i.classList.add("opacity-100","visible")):(i.classList.remove("opacity-100","visible"),i.classList.add("opacity-0","invisible"))};s(),window.addEventListener("scroll",s),i.addEventListener("click",(()=>{window.scrollTo({top:0,behavior:"smooth"})}))}}))</script><div class="mt-4 md:max-h-[calc(100vh-2rem)] z-10" id=toc-container data-astro-cid-ydxbofl4><div class="w-full bg-base-100 shadow-lg rounded-xl"><div class=p-4 data-astro-cid-ydxbofl4><nav class="relative max-h-[calc(100vh-200px)] overflow-y-auto scrollbar-none toc-nav" data-astro-cid-ydxbofl4><div class="bg-primary/10 absolute opacity-0 pointer-events-none rounded-lg shadow-sm z-0" id=active-indicator data-astro-cid-ydxbofl4></div><ul class="relative space-y-0 z-10" data-astro-cid-ydxbofl4><li data-astro-cid-ydxbofl4><a href=#heading-0 class="flex items-center rounded-lg px-2 py-2 relative toc-link" style=padding-left:28px data-astro-cid-ydxbofl4 data-heading-depth=2 data-heading-slug=实现llm的架构 data-index=0><svg height=1em width=1em data-icon=tabler:chevron-right class="h-4 w-4 absolute duration-200 icon-indicator left-1 opacity-0 text-primary transition-all" data-astro-cid-ydxbofl4=true><symbol id=ai:tabler:chevron-right viewBox="0 0 24 24"><path d="m9 6l6 6l-6 6" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 /></symbol><use href=#ai:tabler:chevron-right></use></svg><span class="duration-200 link-text transition-transform" data-astro-cid-ydxbofl4>实现LLM的架构</span></a></li><li data-astro-cid-ydxbofl4><a href=#heading-1 class="flex items-center rounded-lg px-2 py-2 relative toc-link" style=padding-left:28px data-astro-cid-ydxbofl4 data-heading-depth=2 data-heading-slug=使用layernorm对激活值进行标准化 data-index=1><svg height=1em width=1em data-icon=tabler:chevron-right class="h-4 w-4 absolute duration-200 icon-indicator left-1 opacity-0 text-primary transition-all" viewBox="0 0 24 24" data-astro-cid-ydxbofl4=true><use href=#ai:tabler:chevron-right></use></svg><span class="duration-200 link-text transition-transform" data-astro-cid-ydxbofl4>使用LayerNorm对激活值进行标准化</span></a></li><li data-astro-cid-ydxbofl4><a href=#heading-2 class="flex items-center rounded-lg px-2 py-2 relative toc-link" style=padding-left:44px data-astro-cid-ydxbofl4 data-heading-depth=3 data-heading-slug=layernorm的工作原理 data-index=2><svg height=1em width=1em data-icon=tabler:chevron-right class="h-4 w-4 absolute duration-200 icon-indicator left-1 opacity-0 text-primary transition-all" viewBox="0 0 24 24" data-astro-cid-ydxbofl4=true><use href=#ai:tabler:chevron-right></use></svg><span class="duration-200 link-text transition-transform" data-astro-cid-ydxbofl4>LayerNorm的工作原理</span></a></li><li data-astro-cid-ydxbofl4><a href=#heading-3 class="flex items-center rounded-lg px-2 py-2 relative toc-link" style=padding-left:28px data-astro-cid-ydxbofl4 data-heading-depth=2 data-heading-slug=实现带有gelu激活函数的前馈神经网络 data-index=3><svg height=1em width=1em data-icon=tabler:chevron-right class="h-4 w-4 absolute duration-200 icon-indicator left-1 opacity-0 text-primary transition-all" viewBox="0 0 24 24" data-astro-cid-ydxbofl4=true><use href=#ai:tabler:chevron-right></use></svg><span class="duration-200 link-text transition-transform" data-astro-cid-ydxbofl4>实现带有GELU激活函数的前馈神经网络</span></a></li><li data-astro-cid-ydxbofl4><a href=#heading-4 class="flex items-center rounded-lg px-2 py-2 relative toc-link" style=padding-left:28px data-astro-cid-ydxbofl4 data-heading-depth=2 data-heading-slug=添加残差连接 data-index=4><svg height=1em width=1em data-icon=tabler:chevron-right class="h-4 w-4 absolute duration-200 icon-indicator left-1 opacity-0 text-primary transition-all" viewBox="0 0 24 24" data-astro-cid-ydxbofl4=true><use href=#ai:tabler:chevron-right></use></svg><span class="duration-200 link-text transition-transform" data-astro-cid-ydxbofl4>添加残差连接</span></a></li><li data-astro-cid-ydxbofl4><a href=#heading-5 class="flex items-center rounded-lg px-2 py-2 relative toc-link" style=padding-left:28px data-astro-cid-ydxbofl4 data-heading-depth=2 data-heading-slug=连接注意力层与线性层transformer模块 data-index=5><svg height=1em width=1em data-icon=tabler:chevron-right class="h-4 w-4 absolute duration-200 icon-indicator left-1 opacity-0 text-primary transition-all" viewBox="0 0 24 24" data-astro-cid-ydxbofl4=true><use href=#ai:tabler:chevron-right></use></svg><span class="duration-200 link-text transition-transform" data-astro-cid-ydxbofl4>连接注意力层与线性层(Transformer模块)</span></a></li><li data-astro-cid-ydxbofl4><a href=#heading-6 class="flex items-center rounded-lg px-2 py-2 relative toc-link" style=padding-left:28px data-astro-cid-ydxbofl4 data-heading-depth=2 data-heading-slug=实现gpt模型 data-index=6><svg height=1em width=1em data-icon=tabler:chevron-right class="h-4 w-4 absolute duration-200 icon-indicator left-1 opacity-0 text-primary transition-all" viewBox="0 0 24 24" data-astro-cid-ydxbofl4=true><use href=#ai:tabler:chevron-right></use></svg><span class="duration-200 link-text transition-transform" data-astro-cid-ydxbofl4>实现GPT模型</span></a></li><li data-astro-cid-ydxbofl4><a href=#heading-7 class="flex items-center rounded-lg px-2 py-2 relative toc-link" style=padding-left:44px data-astro-cid-ydxbofl4 data-heading-depth=3 data-heading-slug=分析模型规模 data-index=7><svg height=1em width=1em data-icon=tabler:chevron-right class="h-4 w-4 absolute duration-200 icon-indicator left-1 opacity-0 text-primary transition-all" viewBox="0 0 24 24" data-astro-cid-ydxbofl4=true><use href=#ai:tabler:chevron-right></use></svg><span class="duration-200 link-text transition-transform" data-astro-cid-ydxbofl4>分析模型规模</span></a></li><li data-astro-cid-ydxbofl4><a href=#heading-8 class="flex items-center rounded-lg px-2 py-2 relative toc-link" style=padding-left:60px data-astro-cid-ydxbofl4 data-heading-depth=4 data-heading-slug=参数数量 data-index=8><svg height=1em width=1em data-icon=tabler:chevron-right class="h-4 w-4 absolute duration-200 icon-indicator left-1 opacity-0 text-primary transition-all" viewBox="0 0 24 24" data-astro-cid-ydxbofl4=true><use href=#ai:tabler:chevron-right></use></svg><span class="duration-200 link-text transition-transform" data-astro-cid-ydxbofl4>参数数量</span></a></li><li data-astro-cid-ydxbofl4><a href=#heading-9 class="flex items-center rounded-lg px-2 py-2 relative toc-link" style=padding-left:60px data-astro-cid-ydxbofl4 data-heading-depth=4 data-heading-slug=参数所需内存 data-index=9><svg height=1em width=1em data-icon=tabler:chevron-right class="h-4 w-4 absolute duration-200 icon-indicator left-1 opacity-0 text-primary transition-all" viewBox="0 0 24 24" data-astro-cid-ydxbofl4=true><use href=#ai:tabler:chevron-right></use></svg><span class="duration-200 link-text transition-transform" data-astro-cid-ydxbofl4>参数所需内存</span></a></li><li data-astro-cid-ydxbofl4><a href=#heading-10 class="flex items-center rounded-lg px-2 py-2 relative toc-link" style=padding-left:28px data-astro-cid-ydxbofl4 data-heading-depth=2 data-heading-slug=生成文本 data-index=10><svg height=1em width=1em data-icon=tabler:chevron-right class="h-4 w-4 absolute duration-200 icon-indicator left-1 opacity-0 text-primary transition-all" viewBox="0 0 24 24" data-astro-cid-ydxbofl4=true><use href=#ai:tabler:chevron-right></use></svg><span class="duration-200 link-text transition-transform" data-astro-cid-ydxbofl4>生成文本</span></a></li></ul></nav></div></div></div><script type=module>document.addEventListener("astro:page-load",(()=>{const t=document.querySelector(".toc-nav"),e=document.getElementById("active-indicator"),n=Array.from(document.querySelectorAll(".toc-nav a"));if(!t||!e||0===n.length)return;const o=document.querySelectorAll("h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]");if(0===o.length)return;let i=null,r=!1,s=null;const c=new Map;function a(t,n=!0){if(!t)return;const o=parseInt(t.getAttribute("data-heading-depth")||"1");e.style.transition=n?"all 0.3s cubic-bezier(0.25, 0.1, 0.25, 1)":"opacity 0.3s ease-in-out",requestAnimationFrame((()=>{e.style.top=`${t.offsetTop}px`,e.style.height=`${t.offsetHeight}px`,e.style.opacity="1",e.style.left=16*(o-1)+"px",e.style.width=`calc(100% - ${16*(o-1)}px)`}))}function u(t,e){const n=t.getBoundingClientRect(),o=e.getBoundingClientRect();return n.top>=o.top&&n.bottom<=o.bottom}function l(e){i!==e&&(i&&i.classList.remove("active"),e.classList.add("active"),i=e,a(e),u(e,t)||function(e){if(u(e,t))return;const n=e.offsetTop,o=t.clientHeight,i=Math.max(0,n-o/2+e.offsetHeight/2);t.scrollTo({top:i,behavior:"smooth"})}(e))}o.forEach(((t,e)=>{const n=t.getAttribute("id"),o=`heading-${e}`;n&&n!==o&&(t.setAttribute("id",o),c.set(n,o),document.querySelectorAll(`a[href="#${n}"]:not(.toc-nav a)`).forEach((t=>t.setAttribute("href",`#${o}`))))})),t.addEventListener("click",(t=>{const e=t.target.closest("a");if(!e)return;t.preventDefault();const n=e.getAttribute("href")||"";if(!n||!n.startsWith("#"))return;const o=n.substring(1),i=document.getElementById(o);i&&(r=!0,l(e),i.scrollIntoView({behavior:"smooth"}),history.pushState(null,"",n),setTimeout((()=>{r=!1}),1e3))})),window.addEventListener("resize",(()=>{s&&clearTimeout(s),s=window.setTimeout((()=>{i&&a(i,!1)}),100)}),{passive:!0});const d=new IntersectionObserver((t=>{if(r)return;const e=t.filter((t=>t.isIntersecting));if(0===e.length)return;let n=e[0],o=1/0;for(const t of e){const e=Math.abs(t.boundingClientRect.top);e<o&&(o=e,n=t)}const s=n.target.getAttribute("id");if(!s)return;const c=document.querySelector(`.toc-nav a[href="#${s}"]`);c&&c!==i&&l(c)}),{rootMargin:"-50px 0px -75% 0px",threshold:[0,.25]});o.forEach((t=>d.observe(t))),setTimeout((()=>{const t=window.location.hash.substring(1),e=t?document.getElementById(t):o[0];if(e){const t=e.getAttribute("id");if(!t)return;const n=document.querySelector(`.toc-nav a[href="#${t}"]`);n&&l(n)}}),200),window.addEventListener("hashchange",(()=>{if(r)return;const t=window.location.hash.substring(1);if(t){if(r=!0,document.getElementById(t)){const e=document.querySelector(`.toc-nav a[href="#${t}"]`);e&&l(e)}setTimeout((()=>{r=!1}),1e3)}}))}))</script></div></aside></div></div><button class="btn btn-circle hover:scale-110 bg-base-100 btn-md fixed invisible opacity-0 right-6 shadow-lg transition-all z-50 bottom-20 md:hidden" aria-label="Table of Contents" id=mobile-toc-button onclick=mobile_toc_modal.showModal()><svg height=1em width=1em data-icon=lucide:list class="h-5 w-5"><symbol id=ai:lucide:list viewBox="0 0 24 24"><path d="M3 5h.01M3 12h.01M3 19h.01M8 5h13M8 12h13M8 19h13" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 /></symbol><use href=#ai:lucide:list></use></svg></button><dialog class="modal md:hidden" id=mobile_toc_modal><div class="bg-base-100 max-w-md modal-box rounded-lg shadow-xl w-10/12"><div class="flex items-center border-b border-base-200 justify-between pb-4"><h3 class=font-medium>Table of Contents</h3><form method=dialog><button class="btn btn-circle btn-ghost" aria-label="Table of Contents"><svg height=1em width=1em data-icon=lucide:x class="h-5 w-5" viewBox="0 0 24 24"><use href=#ai:lucide:x></use></svg></button></form></div><div class="max-h-[70vh] overflow-auto pt-4"><ul class="menu-sm menu"><li class=my-1><a href=#实现llm的架构 class="flex items-center rounded-lg hover:bg-base-200 mobile-toc-link transition-color" style=margin-left:12px data-mobile-heading-id=实现llm的架构><span class="text-sm truncate">实现LLM的架构</span></a></li><li class=my-1><a href=#使用layernorm对激活值进行标准化 class="flex items-center rounded-lg hover:bg-base-200 mobile-toc-link transition-color" style=margin-left:12px data-mobile-heading-id=使用layernorm对激活值进行标准化><span class="text-sm truncate">使用LayerNorm对激活值进行标准化</span></a></li><li class=my-1><a href=#layernorm的工作原理 class="flex items-center rounded-lg hover:bg-base-200 mobile-toc-link transition-color" style=margin-left:24px data-mobile-heading-id=layernorm的工作原理><span class="text-sm truncate">LayerNorm的工作原理</span></a></li><li class=my-1><a href=#实现带有gelu激活函数的前馈神经网络 class="flex items-center rounded-lg hover:bg-base-200 mobile-toc-link transition-color" style=margin-left:12px data-mobile-heading-id=实现带有gelu激活函数的前馈神经网络><span class="text-sm truncate">实现带有GELU激活函数的前馈神经网络</span></a></li><li class=my-1><a href=#添加残差连接 class="flex items-center rounded-lg hover:bg-base-200 mobile-toc-link transition-color" style=margin-left:12px data-mobile-heading-id=添加残差连接><span class="text-sm truncate">添加残差连接</span></a></li><li class=my-1><a href=#连接注意力层与线性层transformer模块 class="flex items-center rounded-lg hover:bg-base-200 mobile-toc-link transition-color" style=margin-left:12px data-mobile-heading-id=连接注意力层与线性层transformer模块><span class="text-sm truncate">连接注意力层与线性层(Transformer模块)</span></a></li><li class=my-1><a href=#实现gpt模型 class="flex items-center rounded-lg hover:bg-base-200 mobile-toc-link transition-color" style=margin-left:12px data-mobile-heading-id=实现gpt模型><span class="text-sm truncate">实现GPT模型</span></a></li><li class=my-1><a href=#分析模型规模 class="flex items-center rounded-lg hover:bg-base-200 mobile-toc-link transition-color" style=margin-left:24px data-mobile-heading-id=分析模型规模><span class="text-sm truncate">分析模型规模</span></a></li><li class=my-1><a href=#参数数量 class="flex items-center rounded-lg hover:bg-base-200 mobile-toc-link transition-color" style=margin-left:36px data-mobile-heading-id=参数数量><span class="text-sm truncate">参数数量</span></a></li><li class=my-1><a href=#参数所需内存 class="flex items-center rounded-lg hover:bg-base-200 mobile-toc-link transition-color" style=margin-left:36px data-mobile-heading-id=参数所需内存><span class="text-sm truncate">参数所需内存</span></a></li><li class=my-1><a href=#生成文本 class="flex items-center rounded-lg hover:bg-base-200 mobile-toc-link transition-color" style=margin-left:12px data-mobile-heading-id=生成文本><span class="text-sm truncate">生成文本</span></a></li></ul></div></div><form method=dialog class=modal-backdrop><button>close</button></form></dialog><script type=module>document.addEventListener("astro:page-load",(()=>{const e=document.getElementById("mobile-toc-button");if(!e)return;const t=document.querySelectorAll(".mobile-toc-link"),i=document.querySelectorAll("h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]");let o=null;const l=()=>{o||(o=setTimeout((()=>{window.scrollY>300?(e.classList.remove("opacity-0","invisible"),e.classList.add("opacity-100","visible")):(e.classList.remove("opacity-100","visible"),e.classList.add("opacity-0","invisible")),t.length>0&&i.length>0&&s(),o=null}),100))},s=()=>{let e=null;for(let t=i.length-1;t>=0;t--){const o=i[t];if(o.getBoundingClientRect().top<=100){e=o.id;break}}t.forEach((t=>{t.getAttribute("data-mobile-heading-id")===e?t.classList.add("bg-primary/10","font-medium"):t.classList.remove("bg-primary/10","font-medium")}))};window.addEventListener("scroll",l,{passive:!0}),l(),document.addEventListener("astro:before-swap",(()=>{window.removeEventListener("scroll",l),o&&clearTimeout(o)}))}))</script><script>!function(){const t="dracula";document.addEventListener("astro:after-swap",(()=>{const e=localStorage.getItem("theme");if(e){document.documentElement.setAttribute("data-theme",e);const n=e===t?"dark":"light";document.documentElement.setAttribute("data-theme-type",n)}}))}()</script><script>document.addEventListener("astro:page-load",(()=>{document.querySelectorAll(".btn-copy").forEach((e=>{e.addEventListener("click",(async()=>{const o=e.closest(".frosti-code").querySelector("code").textContent,c=e.querySelector(".frosti-code-toolbar-copy-icon"),s=e.querySelector(".frosti-code-toolbar-copy-success");try{await navigator.clipboard.writeText(o),c.classList.add("hidden"),s.classList.remove("hidden"),e.classList.add("copy-success"),setTimeout((()=>{c.classList.remove("hidden"),s.classList.add("hidden"),e.classList.remove("copy-success")}),2e3)}catch(e){console.error("Failed to copy:",e)}}))}))}))</script><style>.btn-copy{position:relative;overflow:hidden}.copy-success{animation:pulse .5s ease-in-out}.frosti-code-toolbar-copy-success svg{color:#10b981}@keyframes pulse{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}</style></body></html>